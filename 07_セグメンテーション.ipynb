{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# セグメンテーション\n",
    "\n",
    "画像の1ピクセルごとの領域が、どんな物体に関連する領域かをラベル付けする。\n",
    "\n",
    "手法としては、Semantic Segmentation（SegNet)と呼ばれるアルゴリズムを使用する。\n",
    "\n",
    "その他にも、U-netと呼ばれるアルゴリズムも存在する。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 実際にやってみる\n",
    "\n",
    "https://github.com/alexgkendall/SegNet-Tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from keras.applications import imagenet_utils\n",
    "\n",
    "class Dataset:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def normalized(self, rgb):\n",
    "        #return rgb/255.0\n",
    "        norm=np.zeros((rgb.shape[0], rgb.shape[1], 3),np.float32)\n",
    "\n",
    "        b=rgb[:,:,0]\n",
    "        g=rgb[:,:,1]\n",
    "        r=rgb[:,:,2]\n",
    "\n",
    "        norm[:,:,0]=cv2.equalizeHist(b)\n",
    "        norm[:,:,1]=cv2.equalizeHist(g)\n",
    "        norm[:,:,2]=cv2.equalizeHist(r)\n",
    "\n",
    "        return norm\n",
    "\n",
    "    def one_hot_it(self, labels):\n",
    "        x = np.zeros([360,480,12])\n",
    "        for i in range(360):\n",
    "            for j in range(480):\n",
    "                x[i,j,labels[i][j]] = 1\n",
    "        return x\n",
    "\n",
    "    def load_data(self, mode='train'):\n",
    "        # 画像データと正解ラベルの取得\n",
    "        data = []\n",
    "        label = []\n",
    "        \n",
    "        # 画像データのパスが記載されているファイルを読み込む\n",
    "        if mode=='train':\n",
    "            filelist_path=r'./data/SegNet-Tutorial/CamVid/train.txt'\n",
    "        elif mode=='test':\n",
    "            filelist_path=r'./data/SegNet-Tutorial/CamVid/test.txt'\n",
    "        else:\n",
    "            raise ValueError('mode is invalid')\n",
    "        with open(filelist_path) as f:\n",
    "            txt = f.readlines()\n",
    "            txt = [line.split(' ') for line in txt]\n",
    "        \n",
    "        # 取得したファイルパスのデータを読み込む\n",
    "        #for i in range(len(txt)):\n",
    "        for i in range(10):\n",
    "            if mode=='train':\n",
    "                data.append(self.normalized(cv2.imread(filelist_path[:-17] + txt[i][0][7:])))\n",
    "                label.append(self.one_hot_it(cv2.imread(filelist_path[:-17] + txt[i][1][7:][:-1])[:,:,0]))\n",
    "            else:\n",
    "                data.append(self.normalized(cv2.imread(filelist_path[:-16] + txt[i][0][7:])))\n",
    "                label.append(self.one_hot_it(cv2.imread(filelist_path[:-16] + txt[i][1][7:][:-1])[:,:,0]))\n",
    "        return np.array(data), np.array(label)\n",
    "\n",
    "\n",
    "    def preprocess_inputs(self, X):\n",
    "        return imagenet_utils.preprocess_input(X)\n",
    "\n",
    "    def reshape_labels(self, y):\n",
    "        return np.reshape(y, (len(y),360*480, 12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input\n",
    "from keras.layers.core import Activation, Flatten, Reshape\n",
    "from keras.layers.convolutional import Convolution2D, Conv2D, MaxPooling2D, UpSampling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.models import Model\n",
    "from keras.utils import np_utils\n",
    "\n",
    "def SegNet(input_shape=(360, 480, 3), classes=12):\n",
    "    ### @ https://github.com/alexgkendall/SegNet-Tutorial/blob/master/Example_Models/bayesian_segnet_camvid.prototxt\n",
    "    img_input = Input(shape=input_shape)\n",
    "    x = img_input\n",
    "    # Encoder\n",
    "    x = Conv2D(64, (3, 3), padding=\"same\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "    x = Conv2D(128, (3, 3), padding=\"same\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "    x = Conv2D(256, (3, 3), padding=\"same\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "    x = Conv2D(512, (3, 3), padding=\"same\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "\n",
    "    # Decoder\n",
    "    x = Conv2D(512, (3, 3), padding=\"same\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "\n",
    "    x = UpSampling2D(size=(2, 2))(x)\n",
    "    x = Conv2D(256, (3, 3), padding=\"same\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "\n",
    "    x = UpSampling2D(size=(2, 2))(x)\n",
    "    x = Conv2D(128, (3, 3), padding=\"same\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "\n",
    "    x = UpSampling2D(size=(2, 2))(x)\n",
    "    x = Conv2D(64, (3, 3), padding=\"same\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "\n",
    "    x = Conv2D(classes, (1, 1), padding=\"valid\")(x)\n",
    "    x = Reshape((input_shape[0] * input_shape[1], classes))(x)\n",
    "    x = Activation(\"softmax\")(x)\n",
    "    model = Model(img_input, x)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import keras\n",
    "\n",
    "input_shape = (360, 480, 3)\n",
    "classes = 12\n",
    "epochs = 2\n",
    "batch_size = 32\n",
    "log_filepath='./logs/'\n",
    "\n",
    "data_shape = 360*480\n",
    "\n",
    "class_weighting = [0.2595, 0.1826, 4.5640, 0.1417, 0.5051, 0.3826, 9.6446, 1.8418, 6.6823, 6.2478, 3.0, 7.3614]\n",
    "\n",
    "## set gpu usage\n",
    "import tensorflow as tf\n",
    "config = tf.ConfigProto(gpu_options=tf.GPUOptions(allow_growth=True, per_process_gpu_memory_fraction = 0.8))\n",
    "session = tf.Session(config=config)\n",
    "keras.backend.tensorflow_backend.set_session(session)\n",
    "\n",
    "def main():\n",
    "    print(\"loading data...\")\n",
    "    ds = Dataset()\n",
    "    train_X, train_y = ds.load_data() # need to implement, y shape is (None, 360, 480, classes)\n",
    "\n",
    "    train_X = ds.preprocess_inputs(train_X)\n",
    "    train_Y = ds.reshape_labels(train_y)\n",
    "    print(\"input data shape...\", train_X.shape)\n",
    "    print(\"input label shape...\", train_Y.shape)\n",
    "\n",
    "    test_X, test_y = ds.load_data('test') # need to implement, y shape is (None, 360, 480, classes)\n",
    "    test_X = ds.preprocess_inputs(test_X)\n",
    "    test_Y = ds.reshape_labels(test_y)\n",
    "\n",
    "    tb_cb = keras.callbacks.TensorBoard(log_dir=log_filepath, histogram_freq=1, write_graph=True, write_images=True)\n",
    "    print(\"creating model...\")\n",
    "    model = SegNet(input_shape=input_shape, classes=classes)\n",
    "    model.compile(loss=\"categorical_crossentropy\", optimizer='adadelta', metrics=[\"accuracy\"])\n",
    "\n",
    "    model.fit(train_X, train_Y, batch_size=batch_size, epochs=epochs,\n",
    "              verbose=1, class_weight=class_weighting , validation_data=(test_X, test_Y), shuffle=True\n",
    "              , callbacks=[tb_cb])\n",
    "\n",
    "    model.save('seg.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data...\n",
      "input data shape... (10, 360, 480, 3)\n",
      "input label shape... (10, 172800, 12)\n",
      "creating model...\n",
      "WARNING:tensorflow:From c:\\users\\mio\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From c:\\users\\mio\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From c:\\users\\mio\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n",
      "Train on 10 samples, validate on 10 samples\n",
      "Epoch 1/2\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor with shape[10,128,360,480] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node conv2d_8/convolution}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[{{node Mean}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-263240bbee7e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-3-8ba04dd2438b>\u001b[0m in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     41\u001b[0m     model.fit(train_X, train_Y, batch_size=batch_size, epochs=epochs,\n\u001b[0;32m     42\u001b[0m               \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclass_weighting\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_X\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_Y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 43\u001b[1;33m               , callbacks=[tb_cb])\n\u001b[0m\u001b[0;32m     44\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'seg.h5'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\mio\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m   1237\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1238\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1239\u001b[1;33m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[0;32m   1240\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1241\u001b[0m     def evaluate(self,\n",
      "\u001b[1;32mc:\\users\\mio\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[0;32m    194\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    195\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 196\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    197\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\mio\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   3074\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3075\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[1;32m-> 3076\u001b[1;33m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[0;32m   3077\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3078\u001b[0m     return nest.pack_sequence_as(self._outputs_structure,\n",
      "\u001b[1;32mc:\\users\\mio\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[0;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1439\u001b[1;33m               run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1440\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\mio\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[1;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[0;32m    526\u001b[0m             \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    527\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 528\u001b[1;33m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[0;32m    529\u001b[0m     \u001b[1;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    530\u001b[0m     \u001b[1;31m# as there is a reference to status from this from the traceback due to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[10,128,360,480] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node conv2d_8/convolution}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[{{node Mean}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "from PIL import Image\n",
    "\n",
    "from model import SegNet\n",
    "\n",
    "import dataset\n",
    "\n",
    "height = 360\n",
    "width = 480\n",
    "classes = 12\n",
    "epochs = 100\n",
    "batch_size = 1\n",
    "log_filepath='./logs_100/'\n",
    "\n",
    "data_shape = 360*480\n",
    "\n",
    "def writeImage(image, filename):\n",
    "    \"\"\" label data to colored image \"\"\"\n",
    "    Sky = [128,128,128]\n",
    "    Building = [128,0,0]\n",
    "    Pole = [192,192,128]\n",
    "    Road_marking = [255,69,0]\n",
    "    Road = [128,64,128]\n",
    "    Pavement = [60,40,222]\n",
    "    Tree = [128,128,0]\n",
    "    SignSymbol = [192,128,128]\n",
    "    Fence = [64,64,128]\n",
    "    Car = [64,0,128]\n",
    "    Pedestrian = [64,64,0]\n",
    "    Bicyclist = [0,128,192]\n",
    "    Unlabelled = [0,0,0]\n",
    "    r = image.copy()\n",
    "    g = image.copy()\n",
    "    b = image.copy()\n",
    "    label_colours = np.array([Sky, Building, Pole, Road_marking, Road, Pavement, Tree, SignSymbol, Fence, Car, Pedestrian, Bicyclist, Unlabelled])\n",
    "    for l in range(0,12):\n",
    "        r[image==l] = label_colours[l,0]\n",
    "        g[image==l] = label_colours[l,1]\n",
    "        b[image==l] = label_colours[l,2]\n",
    "    rgb = np.zeros((image.shape[0], image.shape[1], 3))\n",
    "    rgb[:,:,0] = r/1.0\n",
    "    rgb[:,:,1] = g/1.0\n",
    "    rgb[:,:,2] = b/1.0\n",
    "    im = Image.fromarray(np.uint8(rgb))\n",
    "    im.save(filename)\n",
    "\n",
    "def predict(test):\n",
    "    model = keras.models.load_model('seg_100.h5')\n",
    "    probs = model.predict(test, batch_size=1)\n",
    "\n",
    "    prob = probs[0].reshape((height, width, classes)).argmax(axis=2)\n",
    "    return prob\n",
    "\n",
    "def main():\n",
    "    print(\"loading data...\")\n",
    "    ds = dataset.Dataset(test_file='val.txt', classes=classes)\n",
    "    test_X, test_y = ds.load_data('test') # need to implement, y shape is (None, 360, 480, classes)\n",
    "    test_X = ds.preprocess_inputs(test_X)\n",
    "    test_Y = ds.reshape_labels(test_y)\n",
    "\n",
    "    prob = predict(test_X)\n",
    "    writeImage(prob, 'val.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
