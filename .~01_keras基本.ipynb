{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# keras\n",
    "\n",
    "Kerasは，Pythonで書かれた，TensorFlowまたはCNTK，Theano上で実行可能な高水準のニューラルネットワークライブラリです。\n",
    "\n",
    "### 特徴\n",
    "+ 容易に素早くプロトタイプの作成が可能（ユーザーフレンドリー，モジュール性，および拡張性による）\n",
    "+ CNNとRNNの両方，およびこれらの2つの組み合わせをサポート\n",
    "+ CPUとGPU上でシームレスな動作\n",
    "\n",
    "**公式引用：**https://keras.io/ja/\n",
    "\n",
    "## 下記で通常のディープラーニングを行ってみる"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# データ生成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 連続値データの読み込み\n",
    "from sklearn.datasets import load_boston\n",
    "boston = load_boston()\n",
    "\n",
    "# 訓練データとテストデータに分ける\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(boston['data'], boston['target'], test_size=0.3,  random_state=0)\n",
    "\n",
    "\"\"\"\n",
    "# 標準化（Standardization）\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train_s = scaler.fit_transform(X_train)\n",
    "X_test_s = scaler.transform(X_test) \n",
    "scaler = StandardScaler()\n",
    "y_train_s = scaler.fit_transform(y_train.reshape(len(y_train),1))\n",
    "y_test_s = scaler.transform(y_test.reshape(len(y_test),1)) \n",
    "\"\"\"\n",
    "\n",
    "# 正規化（Normarization）\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler_x = MinMaxScaler()\n",
    "X_train_n = scaler_x.fit_transform(X_train)\n",
    "X_test_n = scaler_x.transform(X_test) \n",
    "scaler_y = MinMaxScaler()\n",
    "y_train_n = scaler_y.fit_transform(y_train.reshape(len(y_train),1))\n",
    "y_test_n = scaler_y.transform(y_test.reshape(len(y_test),1)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 基本的なモデルの作成と学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# 基本モデル生成\n",
    "from keras.models import Sequential\n",
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 層の追加\n",
    "from keras.layers import Dense\n",
    "# 中間層\n",
    "model.add(\n",
    "    Dense(\n",
    "        128, \n",
    "        activation='relu' # 活性化関数\n",
    "    )\n",
    ")\n",
    "\n",
    "# 出力層\n",
    "model.add(\n",
    "    Dense(\n",
    "        1, \n",
    "        activation='linear' # 活性化関数\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# モデルの学習設定\n",
    "from keras import losses\n",
    "from keras import optimizers\n",
    "model.compile(\n",
    "    loss=losses.mean_squared_error,# 平均二乗誤差\n",
    "    optimizer=optimizers.SGD(lr=0.01),# 確率的勾配降下法\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "354/354 [==============================] - 0s 972us/step - loss: 0.0358\n",
      "Epoch 2/100\n",
      "354/354 [==============================] - 0s 127us/step - loss: 0.0351\n",
      "Epoch 3/100\n",
      "354/354 [==============================] - 0s 116us/step - loss: 0.0356\n",
      "Epoch 4/100\n",
      "354/354 [==============================] - 0s 122us/step - loss: 0.0337\n",
      "Epoch 5/100\n",
      "354/354 [==============================] - 0s 124us/step - loss: 0.0345\n",
      "Epoch 6/100\n",
      "354/354 [==============================] - 0s 121us/step - loss: 0.0331\n",
      "Epoch 7/100\n",
      "354/354 [==============================] - 0s 119us/step - loss: 0.0329\n",
      "Epoch 8/100\n",
      "354/354 [==============================] - 0s 119us/step - loss: 0.0337\n",
      "Epoch 9/100\n",
      "354/354 [==============================] - 0s 119us/step - loss: 0.0319\n",
      "Epoch 10/100\n",
      "354/354 [==============================] - 0s 119us/step - loss: 0.0322\n",
      "Epoch 11/100\n",
      "354/354 [==============================] - 0s 124us/step - loss: 0.0346\n",
      "Epoch 12/100\n",
      "354/354 [==============================] - 0s 116us/step - loss: 0.0322\n",
      "Epoch 13/100\n",
      "354/354 [==============================] - 0s 119us/step - loss: 0.0326\n",
      "Epoch 14/100\n",
      "354/354 [==============================] - 0s 121us/step - loss: 0.0329\n",
      "Epoch 15/100\n",
      "354/354 [==============================] - 0s 119us/step - loss: 0.0333\n",
      "Epoch 16/100\n",
      "354/354 [==============================] - 0s 127us/step - loss: 0.0328\n",
      "Epoch 17/100\n",
      "354/354 [==============================] - 0s 121us/step - loss: 0.0319\n",
      "Epoch 18/100\n",
      "354/354 [==============================] - 0s 127us/step - loss: 0.0321\n",
      "Epoch 19/100\n",
      "354/354 [==============================] - 0s 119us/step - loss: 0.0318\n",
      "Epoch 20/100\n",
      "354/354 [==============================] - 0s 119us/step - loss: 0.0310\n",
      "Epoch 21/100\n",
      "354/354 [==============================] - 0s 127us/step - loss: 0.0318\n",
      "Epoch 22/100\n",
      "354/354 [==============================] - 0s 127us/step - loss: 0.0312\n",
      "Epoch 23/100\n",
      "354/354 [==============================] - 0s 130us/step - loss: 0.0305\n",
      "Epoch 24/100\n",
      "354/354 [==============================] - 0s 124us/step - loss: 0.0306\n",
      "Epoch 25/100\n",
      "354/354 [==============================] - 0s 121us/step - loss: 0.0305\n",
      "Epoch 26/100\n",
      "354/354 [==============================] - 0s 116us/step - loss: 0.0294\n",
      "Epoch 27/100\n",
      "354/354 [==============================] - 0s 119us/step - loss: 0.0294\n",
      "Epoch 28/100\n",
      "354/354 [==============================] - 0s 119us/step - loss: 0.0387\n",
      "Epoch 29/100\n",
      "354/354 [==============================] - 0s 116us/step - loss: 0.0360\n",
      "Epoch 30/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 0.0334\n",
      "Epoch 31/100\n",
      "354/354 [==============================] - 0s 119us/step - loss: 0.0370\n",
      "Epoch 32/100\n",
      "354/354 [==============================] - 0s 119us/step - loss: 0.0337\n",
      "Epoch 33/100\n",
      "354/354 [==============================] - 0s 116us/step - loss: 0.0341\n",
      "Epoch 34/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 0.0341\n",
      "Epoch 35/100\n",
      "354/354 [==============================] - 0s 121us/step - loss: 0.0336\n",
      "Epoch 36/100\n",
      "354/354 [==============================] - 0s 119us/step - loss: 0.0334\n",
      "Epoch 37/100\n",
      "354/354 [==============================] - 0s 119us/step - loss: 0.0336\n",
      "Epoch 38/100\n",
      "354/354 [==============================] - 0s 124us/step - loss: 0.0321\n",
      "Epoch 39/100\n",
      "354/354 [==============================] - 0s 124us/step - loss: 0.0317\n",
      "Epoch 40/100\n",
      "354/354 [==============================] - 0s 122us/step - loss: 0.0341\n",
      "Epoch 41/100\n",
      "354/354 [==============================] - 0s 127us/step - loss: 0.0328\n",
      "Epoch 42/100\n",
      "354/354 [==============================] - 0s 130us/step - loss: 0.0311\n",
      "Epoch 43/100\n",
      "354/354 [==============================] - 0s 130us/step - loss: 0.0318\n",
      "Epoch 44/100\n",
      "354/354 [==============================] - 0s 130us/step - loss: 0.0352\n",
      "Epoch 45/100\n",
      "354/354 [==============================] - 0s 124us/step - loss: 0.0328\n",
      "Epoch 46/100\n",
      "354/354 [==============================] - 0s 116us/step - loss: 0.0341\n",
      "Epoch 47/100\n",
      "354/354 [==============================] - 0s 121us/step - loss: 0.0335\n",
      "Epoch 48/100\n",
      "354/354 [==============================] - 0s 119us/step - loss: 0.0327\n",
      "Epoch 49/100\n",
      "354/354 [==============================] - 0s 116us/step - loss: 0.0327\n",
      "Epoch 50/100\n",
      "354/354 [==============================] - 0s 110us/step - loss: 0.0330\n",
      "Epoch 51/100\n",
      "354/354 [==============================] - 0s 119us/step - loss: 0.0306\n",
      "Epoch 52/100\n",
      "354/354 [==============================] - 0s 124us/step - loss: 0.0317\n",
      "Epoch 53/100\n",
      "354/354 [==============================] - 0s 116us/step - loss: 0.0308\n",
      "Epoch 54/100\n",
      "354/354 [==============================] - 0s 116us/step - loss: 0.0306\n",
      "Epoch 55/100\n",
      "354/354 [==============================] - 0s 116us/step - loss: 0.0318\n",
      "Epoch 56/100\n",
      "354/354 [==============================] - 0s 121us/step - loss: 0.0304\n",
      "Epoch 57/100\n",
      "354/354 [==============================] - 0s 116us/step - loss: 0.0298\n",
      "Epoch 58/100\n",
      "354/354 [==============================] - 0s 116us/step - loss: 0.0307\n",
      "Epoch 59/100\n",
      "354/354 [==============================] - 0s 119us/step - loss: 0.0308\n",
      "Epoch 60/100\n",
      "354/354 [==============================] - 0s 127us/step - loss: 0.0298\n",
      "Epoch 61/100\n",
      "354/354 [==============================] - 0s 119us/step - loss: 0.0310\n",
      "Epoch 62/100\n",
      "354/354 [==============================] - 0s 116us/step - loss: 0.0328\n",
      "Epoch 63/100\n",
      "354/354 [==============================] - 0s 127us/step - loss: 0.0325\n",
      "Epoch 64/100\n",
      "354/354 [==============================] - 0s 121us/step - loss: 0.0322\n",
      "Epoch 65/100\n",
      "354/354 [==============================] - 0s 121us/step - loss: 0.0304\n",
      "Epoch 66/100\n",
      "354/354 [==============================] - 0s 121us/step - loss: 0.0284\n",
      "Epoch 67/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 0.0294\n",
      "Epoch 68/100\n",
      "354/354 [==============================] - 0s 119us/step - loss: 0.0293\n",
      "Epoch 69/100\n",
      "354/354 [==============================] - 0s 116us/step - loss: 0.0272\n",
      "Epoch 70/100\n",
      "354/354 [==============================] - 0s 119us/step - loss: 0.0273\n",
      "Epoch 71/100\n",
      "354/354 [==============================] - 0s 116us/step - loss: 0.0291\n",
      "Epoch 72/100\n",
      "354/354 [==============================] - 0s 116us/step - loss: 0.0285\n",
      "Epoch 73/100\n",
      "354/354 [==============================] - 0s 116us/step - loss: 0.0269\n",
      "Epoch 74/100\n",
      "354/354 [==============================] - 0s 119us/step - loss: 0.0317\n",
      "Epoch 75/100\n",
      "354/354 [==============================] - 0s 124us/step - loss: 0.0298\n",
      "Epoch 76/100\n",
      "354/354 [==============================] - 0s 127us/step - loss: 0.0293\n",
      "Epoch 77/100\n",
      "354/354 [==============================] - 0s 121us/step - loss: 0.0268\n",
      "Epoch 78/100\n",
      "354/354 [==============================] - 0s 124us/step - loss: 0.0279\n",
      "Epoch 79/100\n",
      "354/354 [==============================] - 0s 130us/step - loss: 0.0252\n",
      "Epoch 80/100\n",
      "354/354 [==============================] - 0s 127us/step - loss: 0.0256\n",
      "Epoch 81/100\n",
      "354/354 [==============================] - 0s 124us/step - loss: 0.0256\n",
      "Epoch 82/100\n",
      "354/354 [==============================] - 0s 121us/step - loss: 0.0274\n",
      "Epoch 83/100\n",
      "354/354 [==============================] - 0s 119us/step - loss: 0.0272\n",
      "Epoch 84/100\n",
      "354/354 [==============================] - 0s 116us/step - loss: 0.0324\n",
      "Epoch 85/100\n",
      "354/354 [==============================] - 0s 116us/step - loss: 0.0254\n",
      "Epoch 86/100\n",
      "354/354 [==============================] - 0s 119us/step - loss: 0.0270\n",
      "Epoch 87/100\n",
      "354/354 [==============================] - 0s 119us/step - loss: 0.0259\n",
      "Epoch 88/100\n",
      "354/354 [==============================] - 0s 119us/step - loss: 0.0253\n",
      "Epoch 89/100\n",
      "354/354 [==============================] - 0s 116us/step - loss: 0.0257\n",
      "Epoch 90/100\n",
      "354/354 [==============================] - 0s 121us/step - loss: 0.0244\n",
      "Epoch 91/100\n",
      "354/354 [==============================] - 0s 124us/step - loss: 0.0243\n",
      "Epoch 92/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 0.0244\n",
      "Epoch 93/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 0.0249\n",
      "Epoch 94/100\n",
      "354/354 [==============================] - 0s 116us/step - loss: 0.0246\n",
      "Epoch 95/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 0.0241\n",
      "Epoch 96/100\n",
      "354/354 [==============================] - 0s 116us/step - loss: 0.0227\n",
      "Epoch 97/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "354/354 [==============================] - 0s 113us/step - loss: 0.0239\n",
      "Epoch 98/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 0.0229\n",
      "Epoch 99/100\n",
      "354/354 [==============================] - 0s 116us/step - loss: 0.0228\n",
      "Epoch 100/100\n",
      "354/354 [==============================] - 0s 121us/step - loss: 0.0237\n"
     ]
    }
   ],
   "source": [
    "# モデルの学習\n",
    "result = model.fit(\n",
    "    X_train_n,\n",
    "    y_train_n,\n",
    "    epochs=100\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[22.832443 ]\n",
      " [22.113834 ]\n",
      " [32.344658 ]\n",
      " [15.139012 ]\n",
      " [21.61918  ]\n",
      " [20.125938 ]\n",
      " [20.50848  ]\n",
      " [22.688438 ]\n",
      " [17.39839  ]\n",
      " [13.924937 ]\n",
      " [15.848195 ]\n",
      " [13.881222 ]\n",
      " [16.76115  ]\n",
      " [ 9.562428 ]\n",
      " [40.01504  ]\n",
      " [31.257786 ]\n",
      " [21.534176 ]\n",
      " [37.615704 ]\n",
      " [28.254135 ]\n",
      " [22.0731   ]\n",
      " [24.838379 ]\n",
      " [25.046762 ]\n",
      " [17.77019  ]\n",
      " [29.644592 ]\n",
      " [23.653948 ]\n",
      " [13.31817  ]\n",
      " [19.054905 ]\n",
      " [17.719675 ]\n",
      " [35.14008  ]\n",
      " [18.97379  ]\n",
      " [17.483727 ]\n",
      " [19.047697 ]\n",
      " [25.160727 ]\n",
      " [27.611757 ]\n",
      " [27.93707  ]\n",
      " [21.860847 ]\n",
      " [12.799241 ]\n",
      " [25.888727 ]\n",
      " [15.303271 ]\n",
      " [13.2893305]\n",
      " [27.787125 ]\n",
      " [21.971737 ]\n",
      " [21.50145  ]\n",
      " [15.623918 ]\n",
      " [25.140646 ]\n",
      " [28.255379 ]\n",
      " [24.003353 ]\n",
      " [23.877481 ]\n",
      " [12.044733 ]\n",
      " [22.035076 ]\n",
      " [18.538298 ]\n",
      " [16.613106 ]\n",
      " [22.731586 ]\n",
      " [29.06557  ]\n",
      " [13.113113 ]\n",
      " [24.082142 ]\n",
      " [23.171144 ]\n",
      " [18.640009 ]\n",
      " [18.654654 ]\n",
      " [25.971397 ]\n",
      " [22.96969  ]\n",
      " [22.261915 ]\n",
      " [31.468428 ]\n",
      " [27.906054 ]\n",
      " [18.93254  ]\n",
      " [31.409079 ]\n",
      " [18.052681 ]\n",
      " [25.738617 ]\n",
      " [15.978709 ]\n",
      " [22.955406 ]\n",
      " [21.936302 ]\n",
      " [23.275845 ]\n",
      " [30.544184 ]\n",
      " [29.473902 ]\n",
      " [24.510803 ]\n",
      " [ 8.651665 ]\n",
      " [35.26748  ]\n",
      " [24.110172 ]\n",
      " [26.577248 ]\n",
      " [18.451744 ]\n",
      " [29.543188 ]\n",
      " [20.168013 ]\n",
      " [18.700401 ]\n",
      " [35.694244 ]\n",
      " [37.20296  ]\n",
      " [24.079306 ]\n",
      " [24.660452 ]\n",
      " [15.248858 ]\n",
      " [27.938858 ]\n",
      " [16.593142 ]\n",
      " [20.151842 ]\n",
      " [13.038934 ]\n",
      " [29.040874 ]\n",
      " [34.261536 ]\n",
      " [23.029728 ]\n",
      " [22.804909 ]\n",
      " [ 5.115191 ]\n",
      " [29.60887  ]\n",
      " [15.029397 ]\n",
      " [21.429005 ]\n",
      " [24.624113 ]\n",
      " [20.25275  ]\n",
      " [32.074028 ]\n",
      " [21.819384 ]\n",
      " [29.806131 ]\n",
      " [26.66022  ]\n",
      " [ 9.9450245]\n",
      " [16.131708 ]\n",
      " [22.632925 ]\n",
      " [28.506203 ]\n",
      " [32.586384 ]\n",
      " [11.277542 ]\n",
      " [25.783775 ]\n",
      " [16.946424 ]\n",
      " [18.435434 ]\n",
      " [24.718374 ]\n",
      " [ 6.4121714]\n",
      " [21.399115 ]\n",
      " [11.375363 ]\n",
      " [41.756    ]\n",
      " [31.41124  ]\n",
      " [13.053461 ]\n",
      " [21.595627 ]\n",
      " [19.572823 ]\n",
      " [23.761185 ]\n",
      " [22.628721 ]\n",
      " [34.160103 ]\n",
      " [18.77602  ]\n",
      " [23.094118 ]\n",
      " [36.080616 ]\n",
      " [18.662004 ]\n",
      " [11.5811205]\n",
      " [17.687359 ]\n",
      " [21.686234 ]\n",
      " [13.389327 ]\n",
      " [32.15852  ]\n",
      " [23.163713 ]\n",
      " [17.095768 ]\n",
      " [25.075956 ]\n",
      " [ 9.655259 ]\n",
      " [15.429588 ]\n",
      " [19.2853   ]\n",
      " [31.491476 ]\n",
      " [29.197283 ]\n",
      " [24.706795 ]\n",
      " [17.577866 ]\n",
      " [30.751083 ]\n",
      " [30.328714 ]\n",
      " [13.0610895]\n",
      " [ 9.333203 ]\n",
      " [28.938007 ]\n",
      " [28.120874 ]]\n"
     ]
    }
   ],
   "source": [
    "# 予測値の算出\n",
    "y_predict_n = model.predict(X_test_n)\n",
    "y_predict = scaler_y.inverse_transform(y_predict_n)\n",
    "print(y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.19553882788576468"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 乖離度の算出\n",
    "import numpy as np\n",
    "np.mean(\n",
    "    np.abs(y_test-y_predict.flatten())\n",
    "    /y_test\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 層を増やしたモデル\n",
    "\n",
    "ディープラーニングといわれるように、一般的に中間層を増やすと、精度が向上することがわかっている"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 基本モデル生成\n",
    "from keras.models import Sequential\n",
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 層の追加\n",
    "from keras.layers import Dense\n",
    "# 中間層\n",
    "model.add(\n",
    "    Dense(\n",
    "        128, \n",
    "        activation='relu'\n",
    "    )\n",
    ")\n",
    "model.add(\n",
    "    Dense(\n",
    "        128, \n",
    "        activation='relu'\n",
    "    )\n",
    ")\n",
    "model.add(\n",
    "    Dense(\n",
    "        128, \n",
    "        activation='relu'\n",
    "    )\n",
    ")\n",
    "# 出力層\n",
    "model.add(\n",
    "    Dense(\n",
    "        1, \n",
    "        activation='linear'\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# モデルの学習設定\n",
    "from keras import losses\n",
    "from keras import optimizers\n",
    "model.compile(\n",
    "    loss=losses.mean_squared_error,\n",
    "    optimizer=optimizers.SGD(lr=0.01),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "354/354 [==============================] - 0s 285us/step - loss: 0.1286\n",
      "Epoch 2/300\n",
      "354/354 [==============================] - 0s 68us/step - loss: 0.0496\n",
      "Epoch 3/300\n",
      "354/354 [==============================] - 0s 68us/step - loss: 0.0392\n",
      "Epoch 4/300\n",
      "354/354 [==============================] - 0s 62us/step - loss: 0.0353\n",
      "Epoch 5/300\n",
      "354/354 [==============================] - 0s 62us/step - loss: 0.0326\n",
      "Epoch 6/300\n",
      "354/354 [==============================] - 0s 62us/step - loss: 0.0306\n",
      "Epoch 7/300\n",
      "354/354 [==============================] - 0s 59us/step - loss: 0.0291\n",
      "Epoch 8/300\n",
      "354/354 [==============================] - 0s 65us/step - loss: 0.0275\n",
      "Epoch 9/300\n",
      "354/354 [==============================] - 0s 59us/step - loss: 0.0260\n",
      "Epoch 10/300\n",
      "354/354 [==============================] - 0s 65us/step - loss: 0.0249\n",
      "Epoch 11/300\n",
      "354/354 [==============================] - 0s 62us/step - loss: 0.0240\n",
      "Epoch 12/300\n",
      "354/354 [==============================] - 0s 62us/step - loss: 0.0232\n",
      "Epoch 13/300\n",
      "354/354 [==============================] - 0s 59us/step - loss: 0.0225\n",
      "Epoch 14/300\n",
      "354/354 [==============================] - 0s 57us/step - loss: 0.0219\n",
      "Epoch 15/300\n",
      "354/354 [==============================] - 0s 71us/step - loss: 0.0213\n",
      "Epoch 16/300\n",
      "354/354 [==============================] - 0s 68us/step - loss: 0.0205\n",
      "Epoch 17/300\n",
      "354/354 [==============================] - 0s 62us/step - loss: 0.0200\n",
      "Epoch 18/300\n",
      "354/354 [==============================] - 0s 57us/step - loss: 0.0196\n",
      "Epoch 19/300\n",
      "354/354 [==============================] - 0s 59us/step - loss: 0.0191\n",
      "Epoch 20/300\n",
      "354/354 [==============================] - 0s 62us/step - loss: 0.0186\n",
      "Epoch 21/300\n",
      "354/354 [==============================] - 0s 62us/step - loss: 0.0182\n",
      "Epoch 22/300\n",
      "354/354 [==============================] - 0s 65us/step - loss: 0.0178\n",
      "Epoch 23/300\n",
      "354/354 [==============================] - 0s 65us/step - loss: 0.0174\n",
      "Epoch 24/300\n",
      "354/354 [==============================] - 0s 62us/step - loss: 0.0171\n",
      "Epoch 25/300\n",
      "354/354 [==============================] - 0s 65us/step - loss: 0.0168\n",
      "Epoch 26/300\n",
      "354/354 [==============================] - 0s 65us/step - loss: 0.0164\n",
      "Epoch 27/300\n",
      "354/354 [==============================] - 0s 62us/step - loss: 0.0161\n",
      "Epoch 28/300\n",
      "354/354 [==============================] - 0s 62us/step - loss: 0.0158\n",
      "Epoch 29/300\n",
      "354/354 [==============================] - 0s 68us/step - loss: 0.0155\n",
      "Epoch 30/300\n",
      "354/354 [==============================] - 0s 62us/step - loss: 0.0153\n",
      "Epoch 31/300\n",
      "354/354 [==============================] - 0s 68us/step - loss: 0.0150\n",
      "Epoch 32/300\n",
      "354/354 [==============================] - 0s 71us/step - loss: 0.0147\n",
      "Epoch 33/300\n",
      "354/354 [==============================] - 0s 71us/step - loss: 0.0145\n",
      "Epoch 34/300\n",
      "354/354 [==============================] - 0s 65us/step - loss: 0.0144\n",
      "Epoch 35/300\n",
      "354/354 [==============================] - 0s 68us/step - loss: 0.0141\n",
      "Epoch 36/300\n",
      "354/354 [==============================] - 0s 59us/step - loss: 0.0138\n",
      "Epoch 37/300\n",
      "354/354 [==============================] - 0s 62us/step - loss: 0.0137\n",
      "Epoch 38/300\n",
      "354/354 [==============================] - 0s 65us/step - loss: 0.0134\n",
      "Epoch 39/300\n",
      "354/354 [==============================] - 0s 59us/step - loss: 0.0132\n",
      "Epoch 40/300\n",
      "354/354 [==============================] - 0s 65us/step - loss: 0.0130\n",
      "Epoch 41/300\n",
      "354/354 [==============================] - 0s 68us/step - loss: 0.0129\n",
      "Epoch 42/300\n",
      "354/354 [==============================] - 0s 76us/step - loss: 0.0126\n",
      "Epoch 43/300\n",
      "354/354 [==============================] - 0s 62us/step - loss: 0.0125\n",
      "Epoch 44/300\n",
      "354/354 [==============================] - 0s 65us/step - loss: 0.0123\n",
      "Epoch 45/300\n",
      "354/354 [==============================] - 0s 65us/step - loss: 0.0121\n",
      "Epoch 46/300\n",
      "354/354 [==============================] - 0s 59us/step - loss: 0.0120\n",
      "Epoch 47/300\n",
      "354/354 [==============================] - 0s 62us/step - loss: 0.0118\n",
      "Epoch 48/300\n",
      "354/354 [==============================] - 0s 62us/step - loss: 0.0117\n",
      "Epoch 49/300\n",
      "354/354 [==============================] - 0s 59us/step - loss: 0.0116\n",
      "Epoch 50/300\n",
      "354/354 [==============================] - 0s 68us/step - loss: 0.0115\n",
      "Epoch 51/300\n",
      "354/354 [==============================] - 0s 76us/step - loss: 0.0113\n",
      "Epoch 52/300\n",
      "354/354 [==============================] - 0s 65us/step - loss: 0.0112\n",
      "Epoch 53/300\n",
      "354/354 [==============================] - 0s 65us/step - loss: 0.0111\n",
      "Epoch 54/300\n",
      "354/354 [==============================] - 0s 65us/step - loss: 0.0110\n",
      "Epoch 55/300\n",
      "354/354 [==============================] - 0s 62us/step - loss: 0.0109\n",
      "Epoch 56/300\n",
      "354/354 [==============================] - 0s 68us/step - loss: 0.0107\n",
      "Epoch 57/300\n",
      "354/354 [==============================] - 0s 68us/step - loss: 0.0106\n",
      "Epoch 58/300\n",
      "354/354 [==============================] - 0s 68us/step - loss: 0.0106\n",
      "Epoch 59/300\n",
      "354/354 [==============================] - 0s 59us/step - loss: 0.0105\n",
      "Epoch 60/300\n",
      "354/354 [==============================] - 0s 59us/step - loss: 0.0112\n",
      "Epoch 61/300\n",
      "354/354 [==============================] - 0s 62us/step - loss: 0.0102\n",
      "Epoch 62/300\n",
      "354/354 [==============================] - 0s 62us/step - loss: 0.0102\n",
      "Epoch 63/300\n",
      "354/354 [==============================] - 0s 68us/step - loss: 0.0101\n",
      "Epoch 64/300\n",
      "354/354 [==============================] - 0s 73us/step - loss: 0.0101\n",
      "Epoch 65/300\n",
      "354/354 [==============================] - 0s 71us/step - loss: 0.0099\n",
      "Epoch 66/300\n",
      "354/354 [==============================] - 0s 65us/step - loss: 0.0098\n",
      "Epoch 67/300\n",
      "354/354 [==============================] - 0s 73us/step - loss: 0.0098\n",
      "Epoch 68/300\n",
      "354/354 [==============================] - 0s 71us/step - loss: 0.0097\n",
      "Epoch 69/300\n",
      "354/354 [==============================] - 0s 68us/step - loss: 0.0097\n",
      "Epoch 70/300\n",
      "354/354 [==============================] - 0s 71us/step - loss: 0.0095\n",
      "Epoch 71/300\n",
      "354/354 [==============================] - 0s 71us/step - loss: 0.0094\n",
      "Epoch 72/300\n",
      "354/354 [==============================] - 0s 71us/step - loss: 0.0094\n",
      "Epoch 73/300\n",
      "354/354 [==============================] - 0s 65us/step - loss: 0.0094\n",
      "Epoch 74/300\n",
      "354/354 [==============================] - 0s 68us/step - loss: 0.0093\n",
      "Epoch 75/300\n",
      "354/354 [==============================] - 0s 62us/step - loss: 0.0092\n",
      "Epoch 76/300\n",
      "354/354 [==============================] - 0s 65us/step - loss: 0.0091\n",
      "Epoch 77/300\n",
      "354/354 [==============================] - 0s 65us/step - loss: 0.0091\n",
      "Epoch 78/300\n",
      "354/354 [==============================] - 0s 62us/step - loss: 0.0090\n",
      "Epoch 79/300\n",
      "354/354 [==============================] - 0s 65us/step - loss: 0.0089\n",
      "Epoch 80/300\n",
      "354/354 [==============================] - 0s 62us/step - loss: 0.0089\n",
      "Epoch 81/300\n",
      "354/354 [==============================] - 0s 65us/step - loss: 0.0089\n",
      "Epoch 82/300\n",
      "354/354 [==============================] - 0s 62us/step - loss: 0.0088\n",
      "Epoch 83/300\n",
      "354/354 [==============================] - 0s 59us/step - loss: 0.0087\n",
      "Epoch 84/300\n",
      "354/354 [==============================] - 0s 62us/step - loss: 0.0087\n",
      "Epoch 85/300\n",
      "354/354 [==============================] - 0s 56us/step - loss: 0.0086\n",
      "Epoch 86/300\n",
      "354/354 [==============================] - 0s 62us/step - loss: 0.0086\n",
      "Epoch 87/300\n",
      "354/354 [==============================] - 0s 54us/step - loss: 0.0086\n",
      "Epoch 88/300\n",
      "354/354 [==============================] - 0s 68us/step - loss: 0.0085\n",
      "Epoch 89/300\n",
      "354/354 [==============================] - 0s 71us/step - loss: 0.0085\n",
      "Epoch 90/300\n",
      "354/354 [==============================] - 0s 65us/step - loss: 0.0084\n",
      "Epoch 91/300\n",
      "354/354 [==============================] - 0s 68us/step - loss: 0.0084\n",
      "Epoch 92/300\n",
      "354/354 [==============================] - 0s 68us/step - loss: 0.0083\n",
      "Epoch 93/300\n",
      "354/354 [==============================] - 0s 68us/step - loss: 0.0083\n",
      "Epoch 94/300\n",
      "354/354 [==============================] - 0s 68us/step - loss: 0.0083\n",
      "Epoch 95/300\n",
      "354/354 [==============================] - 0s 68us/step - loss: 0.0083\n",
      "Epoch 96/300\n",
      "354/354 [==============================] - 0s 68us/step - loss: 0.0082\n",
      "Epoch 97/300\n",
      "354/354 [==============================] - 0s 79us/step - loss: 0.0082\n",
      "Epoch 98/300\n",
      "354/354 [==============================] - 0s 82us/step - loss: 0.0081\n",
      "Epoch 99/300\n",
      "354/354 [==============================] - 0s 85us/step - loss: 0.0081\n",
      "Epoch 100/300\n",
      "354/354 [==============================] - 0s 82us/step - loss: 0.0081\n",
      "Epoch 101/300\n",
      "354/354 [==============================] - 0s 88us/step - loss: 0.0079\n",
      "Epoch 102/300\n",
      "354/354 [==============================] - 0s 79us/step - loss: 0.0080\n",
      "Epoch 103/300\n",
      "354/354 [==============================] - 0s 76us/step - loss: 0.0079\n",
      "Epoch 104/300\n",
      "354/354 [==============================] - 0s 76us/step - loss: 0.0078\n",
      "Epoch 105/300\n",
      "354/354 [==============================] - 0s 79us/step - loss: 0.0078\n",
      "Epoch 106/300\n",
      "354/354 [==============================] - 0s 79us/step - loss: 0.0078\n",
      "Epoch 107/300\n",
      "354/354 [==============================] - 0s 79us/step - loss: 0.0077\n",
      "Epoch 108/300\n",
      "354/354 [==============================] - 0s 76us/step - loss: 0.0077\n",
      "Epoch 109/300\n",
      "354/354 [==============================] - 0s 82us/step - loss: 0.0077\n",
      "Epoch 110/300\n",
      "354/354 [==============================] - 0s 85us/step - loss: 0.0077\n",
      "Epoch 111/300\n",
      "354/354 [==============================] - 0s 79us/step - loss: 0.0076\n",
      "Epoch 112/300\n",
      "354/354 [==============================] - 0s 71us/step - loss: 0.0076\n",
      "Epoch 113/300\n",
      "354/354 [==============================] - 0s 73us/step - loss: 0.0076\n",
      "Epoch 114/300\n",
      "354/354 [==============================] - 0s 73us/step - loss: 0.0076\n",
      "Epoch 115/300\n",
      "354/354 [==============================] - 0s 68us/step - loss: 0.0075\n",
      "Epoch 116/300\n",
      "354/354 [==============================] - 0s 76us/step - loss: 0.0075\n",
      "Epoch 117/300\n",
      "354/354 [==============================] - 0s 76us/step - loss: 0.0075\n",
      "Epoch 118/300\n",
      "354/354 [==============================] - 0s 76us/step - loss: 0.0075\n",
      "Epoch 119/300\n",
      "354/354 [==============================] - 0s 73us/step - loss: 0.0074\n",
      "Epoch 120/300\n",
      "354/354 [==============================] - 0s 76us/step - loss: 0.0076\n",
      "Epoch 121/300\n",
      "354/354 [==============================] - 0s 90us/step - loss: 0.0074\n",
      "Epoch 122/300\n",
      "354/354 [==============================] - 0s 76us/step - loss: 0.0074\n",
      "Epoch 123/300\n",
      "354/354 [==============================] - 0s 73us/step - loss: 0.0073\n",
      "Epoch 124/300\n",
      "354/354 [==============================] - 0s 73us/step - loss: 0.0074\n",
      "Epoch 125/300\n",
      "354/354 [==============================] - 0s 71us/step - loss: 0.0073\n",
      "Epoch 126/300\n",
      "354/354 [==============================] - 0s 62us/step - loss: 0.0073\n",
      "Epoch 127/300\n",
      "354/354 [==============================] - 0s 65us/step - loss: 0.0072\n",
      "Epoch 128/300\n",
      "354/354 [==============================] - 0s 68us/step - loss: 0.0072\n",
      "Epoch 129/300\n",
      "354/354 [==============================] - 0s 68us/step - loss: 0.0072\n",
      "Epoch 130/300\n",
      "354/354 [==============================] - 0s 59us/step - loss: 0.0072\n",
      "Epoch 131/300\n",
      "354/354 [==============================] - 0s 59us/step - loss: 0.0072\n",
      "Epoch 132/300\n",
      "354/354 [==============================] - 0s 62us/step - loss: 0.0072\n",
      "Epoch 133/300\n",
      "354/354 [==============================] - 0s 65us/step - loss: 0.0071\n",
      "Epoch 134/300\n",
      "354/354 [==============================] - 0s 68us/step - loss: 0.0071\n",
      "Epoch 135/300\n",
      "354/354 [==============================] - 0s 62us/step - loss: 0.0071\n",
      "Epoch 136/300\n",
      "354/354 [==============================] - 0s 68us/step - loss: 0.0071\n",
      "Epoch 137/300\n",
      "354/354 [==============================] - 0s 68us/step - loss: 0.0071\n",
      "Epoch 138/300\n",
      "354/354 [==============================] - 0s 68us/step - loss: 0.0071\n",
      "Epoch 139/300\n",
      "354/354 [==============================] - 0s 68us/step - loss: 0.0071\n",
      "Epoch 140/300\n",
      "354/354 [==============================] - 0s 65us/step - loss: 0.0070\n",
      "Epoch 141/300\n",
      "354/354 [==============================] - 0s 65us/step - loss: 0.0070\n",
      "Epoch 142/300\n",
      "354/354 [==============================] - 0s 65us/step - loss: 0.0070\n",
      "Epoch 143/300\n",
      "354/354 [==============================] - 0s 65us/step - loss: 0.0070\n",
      "Epoch 144/300\n",
      "354/354 [==============================] - 0s 73us/step - loss: 0.0070\n",
      "Epoch 145/300\n",
      "354/354 [==============================] - 0s 71us/step - loss: 0.0069\n",
      "Epoch 146/300\n",
      "354/354 [==============================] - 0s 71us/step - loss: 0.0069\n",
      "Epoch 147/300\n",
      "354/354 [==============================] - 0s 68us/step - loss: 0.0069\n",
      "Epoch 148/300\n",
      "354/354 [==============================] - 0s 71us/step - loss: 0.0069\n",
      "Epoch 149/300\n",
      "354/354 [==============================] - 0s 65us/step - loss: 0.0069\n",
      "Epoch 150/300\n",
      "354/354 [==============================] - 0s 71us/step - loss: 0.0069\n",
      "Epoch 151/300\n",
      "354/354 [==============================] - 0s 76us/step - loss: 0.0068\n",
      "Epoch 152/300\n",
      "354/354 [==============================] - 0s 71us/step - loss: 0.0069\n",
      "Epoch 153/300\n",
      "354/354 [==============================] - 0s 76us/step - loss: 0.0068\n",
      "Epoch 154/300\n",
      "354/354 [==============================] - ETA: 0s - loss: 0.007 - 0s 73us/step - loss: 0.0072\n",
      "Epoch 155/300\n",
      "354/354 [==============================] - 0s 68us/step - loss: 0.0067\n",
      "Epoch 156/300\n",
      "354/354 [==============================] - 0s 65us/step - loss: 0.0067\n",
      "Epoch 157/300\n",
      "354/354 [==============================] - 0s 68us/step - loss: 0.0067\n",
      "Epoch 158/300\n",
      "354/354 [==============================] - 0s 71us/step - loss: 0.0067\n",
      "Epoch 159/300\n",
      "354/354 [==============================] - 0s 68us/step - loss: 0.0067\n",
      "Epoch 160/300\n",
      "354/354 [==============================] - 0s 73us/step - loss: 0.0067\n",
      "Epoch 161/300\n",
      "354/354 [==============================] - 0s 65us/step - loss: 0.0067\n",
      "Epoch 162/300\n",
      "354/354 [==============================] - 0s 76us/step - loss: 0.0066\n",
      "Epoch 163/300\n",
      "354/354 [==============================] - 0s 71us/step - loss: 0.0066\n",
      "Epoch 164/300\n",
      "354/354 [==============================] - 0s 62us/step - loss: 0.0066\n",
      "Epoch 165/300\n",
      "354/354 [==============================] - 0s 65us/step - loss: 0.0066\n",
      "Epoch 166/300\n",
      "354/354 [==============================] - 0s 59us/step - loss: 0.0066\n",
      "Epoch 167/300\n",
      "354/354 [==============================] - 0s 68us/step - loss: 0.0066\n",
      "Epoch 168/300\n",
      "354/354 [==============================] - 0s 62us/step - loss: 0.0066\n",
      "Epoch 169/300\n",
      "354/354 [==============================] - 0s 65us/step - loss: 0.0066\n",
      "Epoch 170/300\n",
      "354/354 [==============================] - 0s 68us/step - loss: 0.0065\n",
      "Epoch 171/300\n",
      "354/354 [==============================] - 0s 71us/step - loss: 0.0066\n",
      "Epoch 172/300\n",
      "354/354 [==============================] - 0s 71us/step - loss: 0.0065\n",
      "Epoch 173/300\n",
      "354/354 [==============================] - 0s 79us/step - loss: 0.0065\n",
      "Epoch 174/300\n",
      "354/354 [==============================] - 0s 68us/step - loss: 0.0065\n",
      "Epoch 175/300\n",
      "354/354 [==============================] - 0s 65us/step - loss: 0.0065\n",
      "Epoch 176/300\n",
      "354/354 [==============================] - 0s 68us/step - loss: 0.0065\n",
      "Epoch 177/300\n",
      "354/354 [==============================] - 0s 79us/step - loss: 0.0065\n",
      "Epoch 178/300\n",
      "354/354 [==============================] - 0s 71us/step - loss: 0.0064\n",
      "Epoch 179/300\n",
      "354/354 [==============================] - 0s 73us/step - loss: 0.0065\n",
      "Epoch 180/300\n",
      "354/354 [==============================] - 0s 68us/step - loss: 0.0064\n",
      "Epoch 181/300\n",
      "354/354 [==============================] - 0s 71us/step - loss: 0.0064\n",
      "Epoch 182/300\n",
      "354/354 [==============================] - 0s 65us/step - loss: 0.0064\n",
      "Epoch 183/300\n",
      "354/354 [==============================] - 0s 56us/step - loss: 0.0063\n",
      "Epoch 184/300\n",
      "354/354 [==============================] - 0s 56us/step - loss: 0.0064\n",
      "Epoch 185/300\n",
      "354/354 [==============================] - 0s 59us/step - loss: 0.0063\n",
      "Epoch 186/300\n",
      "354/354 [==============================] - 0s 56us/step - loss: 0.0064\n",
      "Epoch 187/300\n",
      "354/354 [==============================] - 0s 56us/step - loss: 0.0063\n",
      "Epoch 188/300\n",
      "354/354 [==============================] - 0s 62us/step - loss: 0.0063\n",
      "Epoch 189/300\n",
      "354/354 [==============================] - 0s 73us/step - loss: 0.0063\n",
      "Epoch 190/300\n",
      "354/354 [==============================] - 0s 56us/step - loss: 0.0064\n",
      "Epoch 191/300\n",
      "354/354 [==============================] - 0s 59us/step - loss: 0.0064\n",
      "Epoch 192/300\n",
      "354/354 [==============================] - 0s 56us/step - loss: 0.0063\n",
      "Epoch 193/300\n",
      "354/354 [==============================] - 0s 73us/step - loss: 0.0062\n",
      "Epoch 194/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "354/354 [==============================] - 0s 68us/step - loss: 0.0062\n",
      "Epoch 195/300\n",
      "354/354 [==============================] - 0s 76us/step - loss: 0.0062\n",
      "Epoch 196/300\n",
      "354/354 [==============================] - 0s 62us/step - loss: 0.0063\n",
      "Epoch 197/300\n",
      "354/354 [==============================] - 0s 56us/step - loss: 0.0062\n",
      "Epoch 198/300\n",
      "354/354 [==============================] - 0s 51us/step - loss: 0.0062\n",
      "Epoch 199/300\n",
      "354/354 [==============================] - ETA: 0s - loss: 0.006 - 0s 51us/step - loss: 0.0062\n",
      "Epoch 200/300\n",
      "354/354 [==============================] - 0s 51us/step - loss: 0.0062\n",
      "Epoch 201/300\n",
      "354/354 [==============================] - 0s 93us/step - loss: 0.0062\n",
      "Epoch 202/300\n",
      "354/354 [==============================] - 0s 76us/step - loss: 0.0061\n",
      "Epoch 203/300\n",
      "354/354 [==============================] - 0s 79us/step - loss: 0.0062\n",
      "Epoch 204/300\n",
      "354/354 [==============================] - 0s 76us/step - loss: 0.0061\n",
      "Epoch 205/300\n",
      "354/354 [==============================] - 0s 90us/step - loss: 0.0061\n",
      "Epoch 206/300\n",
      "354/354 [==============================] - 0s 82us/step - loss: 0.0062\n",
      "Epoch 207/300\n",
      "354/354 [==============================] - 0s 73us/step - loss: 0.0061\n",
      "Epoch 208/300\n",
      "354/354 [==============================] - 0s 71us/step - loss: 0.0061\n",
      "Epoch 209/300\n",
      "354/354 [==============================] - 0s 65us/step - loss: 0.0065\n",
      "Epoch 210/300\n",
      "354/354 [==============================] - 0s 59us/step - loss: 0.0061\n",
      "Epoch 211/300\n",
      "354/354 [==============================] - 0s 56us/step - loss: 0.0061\n",
      "Epoch 212/300\n",
      "354/354 [==============================] - 0s 59us/step - loss: 0.0060\n",
      "Epoch 213/300\n",
      "354/354 [==============================] - 0s 56us/step - loss: 0.0061\n",
      "Epoch 214/300\n",
      "354/354 [==============================] - 0s 65us/step - loss: 0.0060\n",
      "Epoch 215/300\n",
      "354/354 [==============================] - 0s 62us/step - loss: 0.0061\n",
      "Epoch 216/300\n",
      "354/354 [==============================] - 0s 65us/step - loss: 0.0064\n",
      "Epoch 217/300\n",
      "354/354 [==============================] - 0s 62us/step - loss: 0.0061\n",
      "Epoch 218/300\n",
      "354/354 [==============================] - 0s 68us/step - loss: 0.0060\n",
      "Epoch 219/300\n",
      "354/354 [==============================] - 0s 65us/step - loss: 0.0060\n",
      "Epoch 220/300\n",
      "354/354 [==============================] - 0s 65us/step - loss: 0.0060\n",
      "Epoch 221/300\n",
      "354/354 [==============================] - 0s 62us/step - loss: 0.0060\n",
      "Epoch 222/300\n",
      "354/354 [==============================] - 0s 62us/step - loss: 0.0060\n",
      "Epoch 223/300\n",
      "354/354 [==============================] - 0s 56us/step - loss: 0.0060\n",
      "Epoch 224/300\n",
      "354/354 [==============================] - 0s 59us/step - loss: 0.0059\n",
      "Epoch 225/300\n",
      "354/354 [==============================] - 0s 62us/step - loss: 0.0059\n",
      "Epoch 226/300\n",
      "354/354 [==============================] - 0s 65us/step - loss: 0.0059\n",
      "Epoch 227/300\n",
      "354/354 [==============================] - 0s 59us/step - loss: 0.0059\n",
      "Epoch 228/300\n",
      "354/354 [==============================] - 0s 62us/step - loss: 0.0059\n",
      "Epoch 229/300\n",
      "354/354 [==============================] - 0s 65us/step - loss: 0.0069\n",
      "Epoch 230/300\n",
      "354/354 [==============================] - 0s 62us/step - loss: 0.0059\n",
      "Epoch 231/300\n",
      "354/354 [==============================] - 0s 62us/step - loss: 0.0059\n",
      "Epoch 232/300\n",
      "354/354 [==============================] - 0s 71us/step - loss: 0.0059\n",
      "Epoch 233/300\n",
      "354/354 [==============================] - 0s 65us/step - loss: 0.0058\n",
      "Epoch 234/300\n",
      "354/354 [==============================] - 0s 51us/step - loss: 0.0059\n",
      "Epoch 235/300\n",
      "354/354 [==============================] - 0s 51us/step - loss: 0.0058\n",
      "Epoch 236/300\n",
      "354/354 [==============================] - 0s 48us/step - loss: 0.0059\n",
      "Epoch 237/300\n",
      "354/354 [==============================] - 0s 62us/step - loss: 0.0058\n",
      "Epoch 238/300\n",
      "354/354 [==============================] - 0s 56us/step - loss: 0.0058\n",
      "Epoch 239/300\n",
      "354/354 [==============================] - 0s 68us/step - loss: 0.0058\n",
      "Epoch 240/300\n",
      "354/354 [==============================] - 0s 68us/step - loss: 0.0058\n",
      "Epoch 241/300\n",
      "354/354 [==============================] - 0s 68us/step - loss: 0.0058\n",
      "Epoch 242/300\n",
      "354/354 [==============================] - 0s 65us/step - loss: 0.0059\n",
      "Epoch 243/300\n",
      "354/354 [==============================] - 0s 65us/step - loss: 0.0058\n",
      "Epoch 244/300\n",
      "354/354 [==============================] - 0s 71us/step - loss: 0.0057\n",
      "Epoch 245/300\n",
      "354/354 [==============================] - 0s 76us/step - loss: 0.0058\n",
      "Epoch 246/300\n",
      "354/354 [==============================] - 0s 59us/step - loss: 0.0058\n",
      "Epoch 247/300\n",
      "354/354 [==============================] - 0s 57us/step - loss: 0.0057\n",
      "Epoch 248/300\n",
      "354/354 [==============================] - 0s 59us/step - loss: 0.0057\n",
      "Epoch 249/300\n",
      "354/354 [==============================] - 0s 59us/step - loss: 0.0057\n",
      "Epoch 250/300\n",
      "354/354 [==============================] - 0s 56us/step - loss: 0.0057\n",
      "Epoch 251/300\n",
      "354/354 [==============================] - 0s 57us/step - loss: 0.0057\n",
      "Epoch 252/300\n",
      "354/354 [==============================] - 0s 62us/step - loss: 0.0057\n",
      "Epoch 253/300\n",
      "354/354 [==============================] - 0s 57us/step - loss: 0.0058\n",
      "Epoch 254/300\n",
      "354/354 [==============================] - 0s 65us/step - loss: 0.0057\n",
      "Epoch 255/300\n",
      "354/354 [==============================] - 0s 71us/step - loss: 0.0058\n",
      "Epoch 256/300\n",
      "354/354 [==============================] - 0s 68us/step - loss: 0.0057\n",
      "Epoch 257/300\n",
      "354/354 [==============================] - 0s 59us/step - loss: 0.0056\n",
      "Epoch 258/300\n",
      "354/354 [==============================] - 0s 62us/step - loss: 0.0056\n",
      "Epoch 259/300\n",
      "354/354 [==============================] - 0s 59us/step - loss: 0.0065\n",
      "Epoch 260/300\n",
      "354/354 [==============================] - 0s 56us/step - loss: 0.0056\n",
      "Epoch 261/300\n",
      "354/354 [==============================] - 0s 59us/step - loss: 0.0056\n",
      "Epoch 262/300\n",
      "354/354 [==============================] - 0s 59us/step - loss: 0.0056\n",
      "Epoch 263/300\n",
      "354/354 [==============================] - 0s 68us/step - loss: 0.0056\n",
      "Epoch 264/300\n",
      "354/354 [==============================] - 0s 82us/step - loss: 0.0056\n",
      "Epoch 265/300\n",
      "354/354 [==============================] - 0s 73us/step - loss: 0.0056\n",
      "Epoch 266/300\n",
      "354/354 [==============================] - 0s 73us/step - loss: 0.0056\n",
      "Epoch 267/300\n",
      "354/354 [==============================] - 0s 65us/step - loss: 0.0056\n",
      "Epoch 268/300\n",
      "354/354 [==============================] - 0s 65us/step - loss: 0.0055\n",
      "Epoch 269/300\n",
      "354/354 [==============================] - 0s 68us/step - loss: 0.0056\n",
      "Epoch 270/300\n",
      "354/354 [==============================] - 0s 62us/step - loss: 0.0055\n",
      "Epoch 271/300\n",
      "354/354 [==============================] - 0s 65us/step - loss: 0.0056\n",
      "Epoch 272/300\n",
      "354/354 [==============================] - 0s 59us/step - loss: 0.0055\n",
      "Epoch 273/300\n",
      "354/354 [==============================] - 0s 65us/step - loss: 0.0055\n",
      "Epoch 274/300\n",
      "354/354 [==============================] - 0s 62us/step - loss: 0.0055\n",
      "Epoch 275/300\n",
      "354/354 [==============================] - 0s 62us/step - loss: 0.0055\n",
      "Epoch 276/300\n",
      "354/354 [==============================] - 0s 71us/step - loss: 0.0056\n",
      "Epoch 277/300\n",
      "354/354 [==============================] - 0s 68us/step - loss: 0.0055\n",
      "Epoch 278/300\n",
      "354/354 [==============================] - 0s 62us/step - loss: 0.0055\n",
      "Epoch 279/300\n",
      "354/354 [==============================] - 0s 62us/step - loss: 0.0055\n",
      "Epoch 280/300\n",
      "354/354 [==============================] - 0s 59us/step - loss: 0.0055\n",
      "Epoch 281/300\n",
      "354/354 [==============================] - 0s 65us/step - loss: 0.0055\n",
      "Epoch 282/300\n",
      "354/354 [==============================] - 0s 59us/step - loss: 0.0055\n",
      "Epoch 283/300\n",
      "354/354 [==============================] - 0s 54us/step - loss: 0.0054\n",
      "Epoch 284/300\n",
      "354/354 [==============================] - 0s 56us/step - loss: 0.0054\n",
      "Epoch 285/300\n",
      "354/354 [==============================] - 0s 56us/step - loss: 0.0054\n",
      "Epoch 286/300\n",
      "354/354 [==============================] - 0s 65us/step - loss: 0.0054\n",
      "Epoch 287/300\n",
      "354/354 [==============================] - 0s 68us/step - loss: 0.0054\n",
      "Epoch 288/300\n",
      "354/354 [==============================] - 0s 76us/step - loss: 0.0055\n",
      "Epoch 289/300\n",
      "354/354 [==============================] - 0s 65us/step - loss: 0.0054\n",
      "Epoch 290/300\n",
      "354/354 [==============================] - 0s 62us/step - loss: 0.0054\n",
      "Epoch 291/300\n",
      "354/354 [==============================] - 0s 68us/step - loss: 0.0055\n",
      "Epoch 292/300\n",
      "354/354 [==============================] - 0s 105us/step - loss: 0.0054\n",
      "Epoch 293/300\n",
      "354/354 [==============================] - 0s 90us/step - loss: 0.0054\n",
      "Epoch 294/300\n",
      "354/354 [==============================] - 0s 99us/step - loss: 0.0054\n",
      "Epoch 295/300\n",
      "354/354 [==============================] - 0s 88us/step - loss: 0.0053\n",
      "Epoch 296/300\n",
      "354/354 [==============================] - 0s 96us/step - loss: 0.0054\n",
      "Epoch 297/300\n",
      "354/354 [==============================] - 0s 76us/step - loss: 0.0053\n",
      "Epoch 298/300\n",
      "354/354 [==============================] - 0s 73us/step - loss: 0.0053\n",
      "Epoch 299/300\n",
      "354/354 [==============================] - 0s 71us/step - loss: 0.0054\n",
      "Epoch 300/300\n",
      "354/354 [==============================] - 0s 62us/step - loss: 0.0053\n"
     ]
    }
   ],
   "source": [
    "# モデルの学習\n",
    "result = model.fit(\n",
    "    X_train_n,\n",
    "    y_train_n,\n",
    "    epochs=300\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[23.516571 ]\n",
      " [23.275265 ]\n",
      " [29.553665 ]\n",
      " [11.205933 ]\n",
      " [20.423077 ]\n",
      " [19.58408  ]\n",
      " [22.850918 ]\n",
      " [20.455257 ]\n",
      " [15.582905 ]\n",
      " [17.131882 ]\n",
      " [ 7.6023026]\n",
      " [14.563764 ]\n",
      " [14.479419 ]\n",
      " [ 7.754903 ]\n",
      " [42.978916 ]\n",
      " [31.11142  ]\n",
      " [24.635157 ]\n",
      " [37.974403 ]\n",
      " [30.946049 ]\n",
      " [21.326563 ]\n",
      " [23.876421 ]\n",
      " [22.350622 ]\n",
      " [19.330849 ]\n",
      " [28.483955 ]\n",
      " [20.31265  ]\n",
      " [14.7535095]\n",
      " [17.462189 ]\n",
      " [16.697252 ]\n",
      " [39.026054 ]\n",
      " [18.163013 ]\n",
      " [16.692198 ]\n",
      " [17.603313 ]\n",
      " [19.301044 ]\n",
      " [20.54428  ]\n",
      " [27.373796 ]\n",
      " [20.756414 ]\n",
      " [ 9.555328 ]\n",
      " [27.095047 ]\n",
      " [15.670668 ]\n",
      " [14.486982 ]\n",
      " [24.550331 ]\n",
      " [19.018995 ]\n",
      " [20.857632 ]\n",
      " [16.70911  ]\n",
      " [23.21438  ]\n",
      " [24.262459 ]\n",
      " [19.599155 ]\n",
      " [19.341185 ]\n",
      " [12.253459 ]\n",
      " [22.978493 ]\n",
      " [17.163998 ]\n",
      " [16.19139  ]\n",
      " [20.73099  ]\n",
      " [35.13566  ]\n",
      " [14.6647005]\n",
      " [18.835314 ]\n",
      " [17.817354 ]\n",
      " [15.757171 ]\n",
      " [13.116844 ]\n",
      " [23.404675 ]\n",
      " [18.188145 ]\n",
      " [19.586258 ]\n",
      " [31.766281 ]\n",
      " [30.099857 ]\n",
      " [19.173506 ]\n",
      " [31.095064 ]\n",
      " [16.05069  ]\n",
      " [17.588612 ]\n",
      " [15.63273  ]\n",
      " [21.179949 ]\n",
      " [20.620295 ]\n",
      " [22.805828 ]\n",
      " [28.413836 ]\n",
      " [28.378069 ]\n",
      " [27.82862  ]\n",
      " [ 7.160701 ]\n",
      " [39.7806   ]\n",
      " [21.868773 ]\n",
      " [25.912851 ]\n",
      " [17.6491   ]\n",
      " [26.531315 ]\n",
      " [19.332743 ]\n",
      " [18.386312 ]\n",
      " [40.514023 ]\n",
      " [42.801945 ]\n",
      " [24.336573 ]\n",
      " [22.83427  ]\n",
      " [14.346511 ]\n",
      " [25.84439  ]\n",
      " [15.098613 ]\n",
      " [15.1851225]\n",
      " [11.508796 ]\n",
      " [23.516546 ]\n",
      " [30.423025 ]\n",
      " [21.38101  ]\n",
      " [19.899487 ]\n",
      " [ 5.968129 ]\n",
      " [25.251198 ]\n",
      " [13.546063 ]\n",
      " [16.210672 ]\n",
      " [23.665615 ]\n",
      " [21.000565 ]\n",
      " [30.324783 ]\n",
      " [21.648594 ]\n",
      " [25.892572 ]\n",
      " [20.970913 ]\n",
      " [ 8.996254 ]\n",
      " [16.104097 ]\n",
      " [21.294397 ]\n",
      " [25.554161 ]\n",
      " [34.201797 ]\n",
      " [13.26135  ]\n",
      " [18.02124  ]\n",
      " [17.206392 ]\n",
      " [11.519085 ]\n",
      " [23.130585 ]\n",
      " [ 7.338667 ]\n",
      " [20.183844 ]\n",
      " [10.607775 ]\n",
      " [43.64796  ]\n",
      " [29.73608  ]\n",
      " [11.959076 ]\n",
      " [16.680197 ]\n",
      " [19.549934 ]\n",
      " [20.888186 ]\n",
      " [20.609426 ]\n",
      " [35.95638  ]\n",
      " [12.727097 ]\n",
      " [19.629566 ]\n",
      " [34.85944  ]\n",
      " [16.647131 ]\n",
      " [11.703368 ]\n",
      " [15.559163 ]\n",
      " [20.27248  ]\n",
      " [11.476708 ]\n",
      " [31.472025 ]\n",
      " [21.63869  ]\n",
      " [12.838791 ]\n",
      " [25.260805 ]\n",
      " [10.210799 ]\n",
      " [11.708976 ]\n",
      " [19.471165 ]\n",
      " [34.418888 ]\n",
      " [27.387884 ]\n",
      " [25.26627  ]\n",
      " [15.871514 ]\n",
      " [31.120516 ]\n",
      " [30.138659 ]\n",
      " [12.369845 ]\n",
      " [ 8.759501 ]\n",
      " [27.631102 ]\n",
      " [25.615957 ]]\n"
     ]
    }
   ],
   "source": [
    "# 予測値の算出\n",
    "y_predict_n = model.predict(X_test_n)\n",
    "y_predict = scaler_y.inverse_transform(y_predict_n)\n",
    "print(y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.14298849903667044"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 乖離度の算出\n",
    "import numpy as np\n",
    "np.mean(\n",
    "    np.abs(y_test-y_predict.flatten())\n",
    "    /y_test\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 分類問題を解いてみる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 連続値データの読み込み\n",
    "from sklearn.datasets import load_iris\n",
    "iris = load_iris()\n",
    "\n",
    "# 訓練データとテストデータに分ける\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(iris['data'], iris['target'], test_size=0.3,  random_state=0)\n",
    "\n",
    "\"\"\"\n",
    "# 標準化（Standardization）\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train_s = scaler.fit_transform(X_train)\n",
    "X_test_s = scaler.transform(X_test) \n",
    "scaler = StandardScaler()\n",
    "y_train_s = scaler.fit_transform(y_train.reshape(len(y_train),1))\n",
    "y_test_s = scaler.transform(y_test.reshape(len(y_test),1)) \n",
    "\"\"\"\n",
    "\n",
    "# 正規化（Normarization）\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler_x = MinMaxScaler()\n",
    "X_train_n = scaler_x.fit_transform(X_train)\n",
    "X_test_n = scaler_x.transform(X_test) \n",
    "\n",
    "# one-hotベクトル化\n",
    "import keras\n",
    "y_train = keras.utils.to_categorical(y_train,3)\n",
    "y_test = keras.utils.to_categorical(y_test,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 基本モデル生成\n",
    "from keras.models import Sequential\n",
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 層の追加\n",
    "from keras.layers import Dense\n",
    "# 中間層\n",
    "model.add(\n",
    "    Dense(\n",
    "        128, \n",
    "        activation='relu'\n",
    "    )\n",
    ")\n",
    "model.add(\n",
    "    Dense(\n",
    "        128, \n",
    "        activation='relu'\n",
    "    )\n",
    ")\n",
    "model.add(\n",
    "    Dense(\n",
    "        128, \n",
    "        activation='relu'\n",
    "    )\n",
    ")\n",
    "# 出力層\n",
    "model.add(\n",
    "    Dense(\n",
    "        3, \n",
    "        activation='linear'\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# モデルの学習設定\n",
    "from keras import losses\n",
    "from keras import optimizers\n",
    "model.compile(\n",
    "    loss=losses.mean_squared_error,\n",
    "    optimizer=optimizers.SGD(lr=0.01),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.3717\n",
      "Epoch 2/100\n",
      "105/105 [==============================] - 0s 76us/step - loss: 0.3460\n",
      "Epoch 3/100\n",
      "105/105 [==============================] - 0s 95us/step - loss: 0.3246\n",
      "Epoch 4/100\n",
      "105/105 [==============================] - 0s 67us/step - loss: 0.3072\n",
      "Epoch 5/100\n",
      "105/105 [==============================] - 0s 86us/step - loss: 0.2926\n",
      "Epoch 6/100\n",
      "105/105 [==============================] - 0s 66us/step - loss: 0.2795\n",
      "Epoch 7/100\n",
      "105/105 [==============================] - 0s 76us/step - loss: 0.2681\n",
      "Epoch 8/100\n",
      "105/105 [==============================] - 0s 66us/step - loss: 0.2579\n",
      "Epoch 9/100\n",
      "105/105 [==============================] - 0s 67us/step - loss: 0.2490\n",
      "Epoch 10/100\n",
      "105/105 [==============================] - 0s 76us/step - loss: 0.2405\n",
      "Epoch 11/100\n",
      "105/105 [==============================] - 0s 76us/step - loss: 0.2336\n",
      "Epoch 12/100\n",
      "105/105 [==============================] - 0s 76us/step - loss: 0.2272\n",
      "Epoch 13/100\n",
      "105/105 [==============================] - 0s 86us/step - loss: 0.2215\n",
      "Epoch 14/100\n",
      "105/105 [==============================] - 0s 67us/step - loss: 0.2166\n",
      "Epoch 15/100\n",
      "105/105 [==============================] - 0s 76us/step - loss: 0.2121\n",
      "Epoch 16/100\n",
      "105/105 [==============================] - 0s 86us/step - loss: 0.2081\n",
      "Epoch 17/100\n",
      "105/105 [==============================] - 0s 86us/step - loss: 0.2042\n",
      "Epoch 18/100\n",
      "105/105 [==============================] - 0s 86us/step - loss: 0.2007\n",
      "Epoch 19/100\n",
      "105/105 [==============================] - 0s 66us/step - loss: 0.1975\n",
      "Epoch 20/100\n",
      "105/105 [==============================] - 0s 76us/step - loss: 0.1946\n",
      "Epoch 21/100\n",
      "105/105 [==============================] - 0s 76us/step - loss: 0.1919\n",
      "Epoch 22/100\n",
      "105/105 [==============================] - 0s 86us/step - loss: 0.1893\n",
      "Epoch 23/100\n",
      "105/105 [==============================] - 0s 76us/step - loss: 0.1869\n",
      "Epoch 24/100\n",
      "105/105 [==============================] - 0s 76us/step - loss: 0.1846\n",
      "Epoch 25/100\n",
      "105/105 [==============================] - 0s 76us/step - loss: 0.1824\n",
      "Epoch 26/100\n",
      "105/105 [==============================] - 0s 76us/step - loss: 0.1801\n",
      "Epoch 27/100\n",
      "105/105 [==============================] - 0s 76us/step - loss: 0.1781\n",
      "Epoch 28/100\n",
      "105/105 [==============================] - 0s 67us/step - loss: 0.1763\n",
      "Epoch 29/100\n",
      "105/105 [==============================] - 0s 66us/step - loss: 0.1743\n",
      "Epoch 30/100\n",
      "105/105 [==============================] - 0s 76us/step - loss: 0.1726\n",
      "Epoch 31/100\n",
      "105/105 [==============================] - 0s 76us/step - loss: 0.1709\n",
      "Epoch 32/100\n",
      "105/105 [==============================] - 0s 76us/step - loss: 0.1693\n",
      "Epoch 33/100\n",
      "105/105 [==============================] - 0s 76us/step - loss: 0.1676\n",
      "Epoch 34/100\n",
      "105/105 [==============================] - 0s 67us/step - loss: 0.1661\n",
      "Epoch 35/100\n",
      "105/105 [==============================] - 0s 66us/step - loss: 0.1645\n",
      "Epoch 36/100\n",
      "105/105 [==============================] - 0s 86us/step - loss: 0.1630\n",
      "Epoch 37/100\n",
      "105/105 [==============================] - 0s 76us/step - loss: 0.1616\n",
      "Epoch 38/100\n",
      "105/105 [==============================] - 0s 85us/step - loss: 0.1603\n",
      "Epoch 39/100\n",
      "105/105 [==============================] - 0s 76us/step - loss: 0.1588\n",
      "Epoch 40/100\n",
      "105/105 [==============================] - 0s 86us/step - loss: 0.1575\n",
      "Epoch 41/100\n",
      "105/105 [==============================] - 0s 67us/step - loss: 0.1561\n",
      "Epoch 42/100\n",
      "105/105 [==============================] - 0s 67us/step - loss: 0.1547\n",
      "Epoch 43/100\n",
      "105/105 [==============================] - 0s 76us/step - loss: 0.1533\n",
      "Epoch 44/100\n",
      "105/105 [==============================] - 0s 76us/step - loss: 0.1521\n",
      "Epoch 45/100\n",
      "105/105 [==============================] - 0s 76us/step - loss: 0.1509\n",
      "Epoch 46/100\n",
      "105/105 [==============================] - 0s 76us/step - loss: 0.1497\n",
      "Epoch 47/100\n",
      "105/105 [==============================] - 0s 76us/step - loss: 0.1485\n",
      "Epoch 48/100\n",
      "105/105 [==============================] - 0s 67us/step - loss: 0.1473\n",
      "Epoch 49/100\n",
      "105/105 [==============================] - 0s 76us/step - loss: 0.1461\n",
      "Epoch 50/100\n",
      "105/105 [==============================] - 0s 76us/step - loss: 0.1448\n",
      "Epoch 51/100\n",
      "105/105 [==============================] - 0s 76us/step - loss: 0.1437\n",
      "Epoch 52/100\n",
      "105/105 [==============================] - 0s 76us/step - loss: 0.1426\n",
      "Epoch 53/100\n",
      "105/105 [==============================] - 0s 76us/step - loss: 0.1414\n",
      "Epoch 54/100\n",
      "105/105 [==============================] - 0s 76us/step - loss: 0.1403\n",
      "Epoch 55/100\n",
      "105/105 [==============================] - 0s 76us/step - loss: 0.1393\n",
      "Epoch 56/100\n",
      "105/105 [==============================] - 0s 67us/step - loss: 0.1383\n",
      "Epoch 57/100\n",
      "105/105 [==============================] - 0s 76us/step - loss: 0.1373\n",
      "Epoch 58/100\n",
      "105/105 [==============================] - 0s 76us/step - loss: 0.1364\n",
      "Epoch 59/100\n",
      "105/105 [==============================] - 0s 76us/step - loss: 0.1353\n",
      "Epoch 60/100\n",
      "105/105 [==============================] - 0s 76us/step - loss: 0.1344\n",
      "Epoch 61/100\n",
      "105/105 [==============================] - 0s 76us/step - loss: 0.1335\n",
      "Epoch 62/100\n",
      "105/105 [==============================] - 0s 66us/step - loss: 0.1324\n",
      "Epoch 63/100\n",
      "105/105 [==============================] - 0s 86us/step - loss: 0.1315\n",
      "Epoch 64/100\n",
      "105/105 [==============================] - 0s 67us/step - loss: 0.1305\n",
      "Epoch 65/100\n",
      "105/105 [==============================] - 0s 66us/step - loss: 0.1298\n",
      "Epoch 66/100\n",
      "105/105 [==============================] - 0s 66us/step - loss: 0.1289\n",
      "Epoch 67/100\n",
      "105/105 [==============================] - 0s 76us/step - loss: 0.1280\n",
      "Epoch 68/100\n",
      "105/105 [==============================] - 0s 67us/step - loss: 0.1272\n",
      "Epoch 69/100\n",
      "105/105 [==============================] - 0s 76us/step - loss: 0.1263\n",
      "Epoch 70/100\n",
      "105/105 [==============================] - 0s 76us/step - loss: 0.1256\n",
      "Epoch 71/100\n",
      "105/105 [==============================] - 0s 86us/step - loss: 0.1248\n",
      "Epoch 72/100\n",
      "105/105 [==============================] - 0s 66us/step - loss: 0.1241\n",
      "Epoch 73/100\n",
      "105/105 [==============================] - 0s 76us/step - loss: 0.1233\n",
      "Epoch 74/100\n",
      "105/105 [==============================] - 0s 66us/step - loss: 0.1224\n",
      "Epoch 75/100\n",
      "105/105 [==============================] - 0s 76us/step - loss: 0.1216\n",
      "Epoch 76/100\n",
      "105/105 [==============================] - 0s 67us/step - loss: 0.1210\n",
      "Epoch 77/100\n",
      "105/105 [==============================] - 0s 76us/step - loss: 0.1203\n",
      "Epoch 78/100\n",
      "105/105 [==============================] - 0s 57us/step - loss: 0.1197\n",
      "Epoch 79/100\n",
      "105/105 [==============================] - 0s 76us/step - loss: 0.1191\n",
      "Epoch 80/100\n",
      "105/105 [==============================] - 0s 67us/step - loss: 0.1183\n",
      "Epoch 81/100\n",
      "105/105 [==============================] - 0s 76us/step - loss: 0.1176\n",
      "Epoch 82/100\n",
      "105/105 [==============================] - 0s 66us/step - loss: 0.1170\n",
      "Epoch 83/100\n",
      "105/105 [==============================] - 0s 76us/step - loss: 0.1163\n",
      "Epoch 84/100\n",
      "105/105 [==============================] - 0s 67us/step - loss: 0.1158\n",
      "Epoch 85/100\n",
      "105/105 [==============================] - 0s 76us/step - loss: 0.1151\n",
      "Epoch 86/100\n",
      "105/105 [==============================] - 0s 86us/step - loss: 0.1145\n",
      "Epoch 87/100\n",
      "105/105 [==============================] - 0s 76us/step - loss: 0.1140\n",
      "Epoch 88/100\n",
      "105/105 [==============================] - 0s 76us/step - loss: 0.1136\n",
      "Epoch 89/100\n",
      "105/105 [==============================] - 0s 76us/step - loss: 0.1129\n",
      "Epoch 90/100\n",
      "105/105 [==============================] - 0s 76us/step - loss: 0.1123\n",
      "Epoch 91/100\n",
      "105/105 [==============================] - 0s 76us/step - loss: 0.1118\n",
      "Epoch 92/100\n",
      "105/105 [==============================] - 0s 76us/step - loss: 0.1113\n",
      "Epoch 93/100\n",
      "105/105 [==============================] - 0s 76us/step - loss: 0.1108\n",
      "Epoch 94/100\n",
      "105/105 [==============================] - 0s 66us/step - loss: 0.1102\n",
      "Epoch 95/100\n",
      "105/105 [==============================] - 0s 66us/step - loss: 0.1097\n",
      "Epoch 96/100\n",
      "105/105 [==============================] - 0s 76us/step - loss: 0.1093\n",
      "Epoch 97/100\n",
      "105/105 [==============================] - 0s 67us/step - loss: 0.1090\n",
      "Epoch 98/100\n",
      "105/105 [==============================] - 0s 67us/step - loss: 0.1084\n",
      "Epoch 99/100\n",
      "105/105 [==============================] - 0s 67us/step - loss: 0.1079\n",
      "Epoch 100/100\n",
      "105/105 [==============================] - 0s 86us/step - loss: 0.1075\n"
     ]
    }
   ],
   "source": [
    "# モデルの学習\n",
    "result = model.fit(\n",
    "    X_train_n,\n",
    "    y_train,\n",
    "    epochs=100\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 2 0 2 0 2 0 2 2 2 2 2 2 2 2 0 2 2 0 0 2 2 0 0 2 0 0 2 2 0 2 2 0 2 2 2 0\n",
      " 2 2 2 2 0 2 0 0]\n"
     ]
    }
   ],
   "source": [
    "# 予測値の算出\n",
    "y_predict = np.argmax(model.predict(X_test_n),axis=1)\n",
    "print(y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 正答率の算出\n",
    "np.sum(\n",
    "    np.array(y_predict)\n",
    "    ==\n",
    "    np.argmax(np.array(y_test),axis=1)\n",
    ")/len(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 様々な精度向上テクニック\n",
    "\n",
    "+ **ミニバッチ学習**：ニューラルネットは、データが増えれば増えるほど、1epoch毎の計算時間が多くなるため、全てのデータを使って、勾配(重み)を更新していては、非効率的である。そのため、全データから、ランダムに任意の個数のデータを抽出し、学習させると、扱うデータ量が減り、計算速度が向上し、限られたリソースで、多くの勾配(重み)を更新できる。\n",
    "+ **重み更新法の変更**：上記で使用していたSGDは確率的勾配降下法と呼ばれるもので、その他にも、「Adam」「RMSprop」「Adagrad」「Adamax」「Nadam」などがある。\n",
    "+ **活性化関数の変更**：上記で使用してきた「relu」「linear(恒等関数)」で、その他にも、「elu」「selu」「relu」「softmax」「softplus」「spftsign」「tanh」「sigmoid」「hard_sigmoid」などがある。\n",
    "中間層には、原則として、「linear」以外のすべての活性化関数が用いれる。\n",
    "    + 出力層\n",
    "        + 回帰問題：「linear」を用いるのが一般的であるが、目的変数の取りうる値(値域)が-1~1とわかっているなどの場合は、tanhを利用することができる。目的変数の値域と一致する活性化関数を選択する。\n",
    "        + 分類問題：\n",
    "            + 2項分類：sigmoidを用いるのが一般的\n",
    "            + 多項分類：softmaxを用いるのが一般的。\n",
    "+ **ドロップアウト**：一定の確率でランダムにニューロンを無視して学習を進める\n",
    "+ **Batch Normalization**：バッチ正規化と呼ばれ、基本的には、勾配消失・勾配爆発を防ぐための手法であり、これまでは、活性化関数の変更・学習係数を下げる・DropOut層の追加などで対応してきたが、Batch Normalizationは、ミニバッチの各出力を正規化させ、学習過程の安定と学習速度の向上を実現した。\n",
    "+ **勾配(重み)やバイアスの初期値**\n",
    "    + Heの初期値：中間層の活性化関数がReluの時に、有効で、勾配(重み)やバイアスに対し、特定の法則に則って算出した、初期値を与えてやることで、中間層からの出力を偏りのないものにすることで、勾配消失問題と表現力の低下を解決する\n",
    "    + Xavierの初期値：中間層の活性化関数がsigmoid/tanhの時に、有効で、勾配(重み)やバイアスに対し、特定の法則に則って算出した、初期値を与えてやることで、中間層からの出力を偏りのないものにすることで、勾配消失問題と表現力の低下を解決する\n",
    "+ **正則化項**：過学習防止のために、勾配(重み)が大きくなりすぎると、ペナルティを与える\n",
    "    + l1正則化：大きな次元の入力データに対して有効で、意味のないベクトルをそぎ落としてくれる\n",
    "    + l2正則化：特定の変数について、重要視したモデルを作成することを防ぐ\n",
    "    + l1_l2正則化：上記2つの合体版"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 連続値データの読み込み\n",
    "from sklearn.datasets import load_boston\n",
    "boston = load_boston()\n",
    "\n",
    "# 訓練データとテストデータに分ける\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(boston['data'], boston['target'], test_size=0.3,  random_state=0)\n",
    "\n",
    "\"\"\"\n",
    "# 標準化（Standardization）\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train_s = scaler.fit_transform(X_train)\n",
    "X_test_s = scaler.transform(X_test) \n",
    "scaler = StandardScaler()\n",
    "y_train_s = scaler.fit_transform(y_train.reshape(len(y_train),1))\n",
    "y_test_s = scaler.transform(y_test.reshape(len(y_test),1)) \n",
    "\"\"\"\n",
    "\n",
    "# 正規化（Normarization）\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler_x = MinMaxScaler()\n",
    "X_train_n = scaler_x.fit_transform(X_train)\n",
    "X_test_n = scaler_x.transform(X_test) \n",
    "scaler_y = MinMaxScaler()\n",
    "y_train_n = scaler_y.fit_transform(y_train.reshape(len(y_train),1))\n",
    "y_test_n = scaler_y.transform(y_test.reshape(len(y_test),1)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 基本モデル生成\n",
    "from keras.models import Sequential\n",
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 層の追加\n",
    "from keras.layers import Dense,Dropout\n",
    "from keras.layers import normalization\n",
    "from keras import regularizers\n",
    "\n",
    "# 中間層\n",
    "model.add(\n",
    "    Dense(\n",
    "        128, \n",
    "        activation='relu',\n",
    "        kernel_initializer='he_normal',                  # 勾配(重み)の初期値\n",
    "        bias_initializer='he_normal',                    # バイアス項の初期値\n",
    "        kernel_regularizer=regularizers.l1_l2(0.001),    # 勾配(重み)の正則化項\n",
    "        bias_regularizer=regularizers.l1_l2(0.001)       # バイアス項の正則化項\n",
    "    )\n",
    ")\n",
    "model.add(Dropout(0.1))                      # ドロップアウト層\n",
    "model.add(normalization.BatchNormalization())# バッチ正規化\n",
    "model.add(Dense(128, activation='selu'))\n",
    "model.add(Dropout(0.1))                      # ドロップアウト層\n",
    "model.add(normalization.BatchNormalization())# バッチ正規化\n",
    "model.add(Dense(64, activation='softmax'))\n",
    "\n",
    "# 出力層\n",
    "model.add(Dense(1, activation='linear'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# モデルの学習設定\n",
    "from keras import losses\n",
    "from keras import optimizers\n",
    "model.compile(\n",
    "    loss=losses.mean_squared_error,\n",
    "    optimizer=optimizers.Adam(),             # 勾配(重み)更新法の変更\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 3.4691\n",
      "Epoch 2/100\n",
      "354/354 [==============================] - 0s 130us/step - loss: 3.2564\n",
      "Epoch 3/100\n",
      "354/354 [==============================] - 0s 127us/step - loss: 3.0699\n",
      "Epoch 4/100\n",
      "354/354 [==============================] - 0s 136us/step - loss: 2.9076\n",
      "Epoch 5/100\n",
      "354/354 [==============================] - 0s 136us/step - loss: 2.7655\n",
      "Epoch 6/100\n",
      "354/354 [==============================] - 0s 121us/step - loss: 2.6309\n",
      "Epoch 7/100\n",
      "354/354 [==============================] - ETA: 0s - loss: 2.544 - 0s 121us/step - loss: 2.5037\n",
      "Epoch 8/100\n",
      "354/354 [==============================] - 0s 130us/step - loss: 2.3860\n",
      "Epoch 9/100\n",
      "354/354 [==============================] - 0s 234us/step - loss: 2.2736\n",
      "Epoch 10/100\n",
      "354/354 [==============================] - 0s 127us/step - loss: 2.1658\n",
      "Epoch 11/100\n",
      "354/354 [==============================] - 0s 130us/step - loss: 2.0631\n",
      "Epoch 12/100\n",
      "354/354 [==============================] - 0s 138us/step - loss: 1.9672\n",
      "Epoch 13/100\n",
      "354/354 [==============================] - 0s 127us/step - loss: 1.8749\n",
      "Epoch 14/100\n",
      "354/354 [==============================] - 0s 133us/step - loss: 1.7875\n",
      "Epoch 15/100\n",
      "354/354 [==============================] - 0s 133us/step - loss: 1.7047\n",
      "Epoch 16/100\n",
      "354/354 [==============================] - 0s 121us/step - loss: 1.6258\n",
      "Epoch 17/100\n",
      "354/354 [==============================] - 0s 124us/step - loss: 1.5492\n",
      "Epoch 18/100\n",
      "354/354 [==============================] - 0s 127us/step - loss: 1.4771\n",
      "Epoch 19/100\n",
      "354/354 [==============================] - 0s 127us/step - loss: 1.4088\n",
      "Epoch 20/100\n",
      "354/354 [==============================] - 0s 121us/step - loss: 1.3431\n",
      "Epoch 21/100\n",
      "354/354 [==============================] - 0s 127us/step - loss: 1.2812\n",
      "Epoch 22/100\n",
      "354/354 [==============================] - 0s 121us/step - loss: 1.2211\n",
      "Epoch 23/100\n",
      "354/354 [==============================] - 0s 119us/step - loss: 1.1646\n",
      "Epoch 24/100\n",
      "354/354 [==============================] - 0s 119us/step - loss: 1.1095\n",
      "Epoch 25/100\n",
      "354/354 [==============================] - 0s 130us/step - loss: 1.0567\n",
      "Epoch 26/100\n",
      "354/354 [==============================] - 0s 121us/step - loss: 1.0073\n",
      "Epoch 27/100\n",
      "354/354 [==============================] - 0s 124us/step - loss: 0.9594\n",
      "Epoch 28/100\n",
      "354/354 [==============================] - 0s 133us/step - loss: 0.9146\n",
      "Epoch 29/100\n",
      "354/354 [==============================] - 0s 136us/step - loss: 0.8720\n",
      "Epoch 30/100\n",
      "354/354 [==============================] - 0s 133us/step - loss: 0.8305\n",
      "Epoch 31/100\n",
      "354/354 [==============================] - 0s 127us/step - loss: 0.7905\n",
      "Epoch 32/100\n",
      "354/354 [==============================] - 0s 127us/step - loss: 0.7528\n",
      "Epoch 33/100\n",
      "354/354 [==============================] - 0s 138us/step - loss: 0.7171\n",
      "Epoch 34/100\n",
      "354/354 [==============================] - 0s 127us/step - loss: 0.6841\n",
      "Epoch 35/100\n",
      "354/354 [==============================] - 0s 127us/step - loss: 0.6503\n",
      "Epoch 36/100\n",
      "354/354 [==============================] - 0s 133us/step - loss: 0.6197\n",
      "Epoch 37/100\n",
      "354/354 [==============================] - 0s 133us/step - loss: 0.5893\n",
      "Epoch 38/100\n",
      "354/354 [==============================] - 0s 147us/step - loss: 0.5603\n",
      "Epoch 39/100\n",
      "354/354 [==============================] - 0s 119us/step - loss: 0.5330\n",
      "Epoch 40/100\n",
      "354/354 [==============================] - 0s 136us/step - loss: 0.5071\n",
      "Epoch 41/100\n",
      "354/354 [==============================] - 0s 136us/step - loss: 0.4820\n",
      "Epoch 42/100\n",
      "354/354 [==============================] - 0s 124us/step - loss: 0.4585\n",
      "Epoch 43/100\n",
      "354/354 [==============================] - 0s 136us/step - loss: 0.4361\n",
      "Epoch 44/100\n",
      "354/354 [==============================] - 0s 127us/step - loss: 0.4142\n",
      "Epoch 45/100\n",
      "354/354 [==============================] - 0s 124us/step - loss: 0.3937\n",
      "Epoch 46/100\n",
      "354/354 [==============================] - 0s 121us/step - loss: 0.3740\n",
      "Epoch 47/100\n",
      "354/354 [==============================] - 0s 127us/step - loss: 0.3550\n",
      "Epoch 48/100\n",
      "354/354 [==============================] - 0s 116us/step - loss: 0.3372\n",
      "Epoch 49/100\n",
      "354/354 [==============================] - 0s 130us/step - loss: 0.3207\n",
      "Epoch 50/100\n",
      "354/354 [==============================] - 0s 130us/step - loss: 0.3055\n",
      "Epoch 51/100\n",
      "354/354 [==============================] - 0s 121us/step - loss: 0.2906\n",
      "Epoch 52/100\n",
      "354/354 [==============================] - 0s 116us/step - loss: 0.2795\n",
      "Epoch 53/100\n",
      "354/354 [==============================] - 0s 127us/step - loss: 0.2668\n",
      "Epoch 54/100\n",
      "354/354 [==============================] - 0s 133us/step - loss: 0.2536\n",
      "Epoch 55/100\n",
      "354/354 [==============================] - 0s 130us/step - loss: 0.2405\n",
      "Epoch 56/100\n",
      "354/354 [==============================] - 0s 127us/step - loss: 0.2281\n",
      "Epoch 57/100\n",
      "354/354 [==============================] - 0s 130us/step - loss: 0.2169\n",
      "Epoch 58/100\n",
      "354/354 [==============================] - 0s 133us/step - loss: 0.2068\n",
      "Epoch 59/100\n",
      "354/354 [==============================] - 0s 121us/step - loss: 0.1968\n",
      "Epoch 60/100\n",
      "354/354 [==============================] - 0s 127us/step - loss: 0.1870\n",
      "Epoch 61/100\n",
      "354/354 [==============================] - 0s 130us/step - loss: 0.1776\n",
      "Epoch 62/100\n",
      "354/354 [==============================] - 0s 124us/step - loss: 0.1692\n",
      "Epoch 63/100\n",
      "354/354 [==============================] - 0s 155us/step - loss: 0.1624\n",
      "Epoch 64/100\n",
      "354/354 [==============================] - 0s 138us/step - loss: 0.1562\n",
      "Epoch 65/100\n",
      "354/354 [==============================] - 0s 119us/step - loss: 0.1468\n",
      "Epoch 66/100\n",
      "354/354 [==============================] - 0s 150us/step - loss: 0.1413\n",
      "Epoch 67/100\n",
      "354/354 [==============================] - 0s 158us/step - loss: 0.1337\n",
      "Epoch 68/100\n",
      "354/354 [==============================] - 0s 133us/step - loss: 0.1277\n",
      "Epoch 69/100\n",
      "354/354 [==============================] - 0s 127us/step - loss: 0.1222\n",
      "Epoch 70/100\n",
      "354/354 [==============================] - 0s 133us/step - loss: 0.1161\n",
      "Epoch 71/100\n",
      "354/354 [==============================] - 0s 144us/step - loss: 0.1096\n",
      "Epoch 72/100\n",
      "354/354 [==============================] - 0s 130us/step - loss: 0.1047\n",
      "Epoch 73/100\n",
      "354/354 [==============================] - 0s 127us/step - loss: 0.0995\n",
      "Epoch 74/100\n",
      "354/354 [==============================] - 0s 133us/step - loss: 0.0951\n",
      "Epoch 75/100\n",
      "354/354 [==============================] - 0s 127us/step - loss: 0.0904\n",
      "Epoch 76/100\n",
      "354/354 [==============================] - 0s 130us/step - loss: 0.0886\n",
      "Epoch 77/100\n",
      "354/354 [==============================] - 0s 127us/step - loss: 0.0824\n",
      "Epoch 78/100\n",
      "354/354 [==============================] - ETA: 0s - loss: 0.078 - 0s 119us/step - loss: 0.0786\n",
      "Epoch 79/100\n",
      "354/354 [==============================] - 0s 121us/step - loss: 0.0760\n",
      "Epoch 80/100\n",
      "354/354 [==============================] - 0s 127us/step - loss: 0.0735\n",
      "Epoch 81/100\n",
      "354/354 [==============================] - 0s 127us/step - loss: 0.0691\n",
      "Epoch 82/100\n",
      "354/354 [==============================] - 0s 124us/step - loss: 0.0643\n",
      "Epoch 83/100\n",
      "354/354 [==============================] - 0s 124us/step - loss: 0.0617\n",
      "Epoch 84/100\n",
      "354/354 [==============================] - 0s 133us/step - loss: 0.0577\n",
      "Epoch 85/100\n",
      "354/354 [==============================] - 0s 130us/step - loss: 0.0547\n",
      "Epoch 86/100\n",
      "354/354 [==============================] - 0s 127us/step - loss: 0.0524\n",
      "Epoch 87/100\n",
      "354/354 [==============================] - 0s 127us/step - loss: 0.0533\n",
      "Epoch 88/100\n",
      "354/354 [==============================] - 0s 119us/step - loss: 0.0515\n",
      "Epoch 89/100\n",
      "354/354 [==============================] - 0s 130us/step - loss: 0.0523\n",
      "Epoch 90/100\n",
      "354/354 [==============================] - 0s 155us/step - loss: 0.0487\n",
      "Epoch 91/100\n",
      "354/354 [==============================] - 0s 117us/step - loss: 0.0455\n",
      "Epoch 92/100\n",
      "354/354 [==============================] - 0s 133us/step - loss: 0.0451\n",
      "Epoch 93/100\n",
      "354/354 [==============================] - 0s 119us/step - loss: 0.0423\n",
      "Epoch 94/100\n",
      "354/354 [==============================] - 0s 124us/step - loss: 0.0415\n",
      "Epoch 95/100\n",
      "354/354 [==============================] - 0s 130us/step - loss: 0.0388\n",
      "Epoch 96/100\n",
      "354/354 [==============================] - 0s 133us/step - loss: 0.0377\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 97/100\n",
      "354/354 [==============================] - 0s 130us/step - loss: 0.0386\n",
      "Epoch 98/100\n",
      "354/354 [==============================] - 0s 119us/step - loss: 0.0367\n",
      "Epoch 99/100\n",
      "354/354 [==============================] - 0s 124us/step - loss: 0.0375\n",
      "Epoch 100/100\n",
      "354/354 [==============================] - 0s 136us/step - loss: 0.0362\n"
     ]
    }
   ],
   "source": [
    "# モデルの学習\n",
    "result = model.fit(\n",
    "    X_train_n,\n",
    "    y_train_n,\n",
    "    batch_size=32,                          # ミニバッチ処理\n",
    "    epochs=100\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[25.293936 ]\n",
      " [18.036297 ]\n",
      " [25.731928 ]\n",
      " [14.515099 ]\n",
      " [24.300957 ]\n",
      " [25.269136 ]\n",
      " [22.95715  ]\n",
      " [25.860542 ]\n",
      " [24.225956 ]\n",
      " [15.081624 ]\n",
      " [12.983545 ]\n",
      " [12.980988 ]\n",
      " [13.587301 ]\n",
      " [13.363232 ]\n",
      " [43.81423  ]\n",
      " [42.881664 ]\n",
      " [23.134737 ]\n",
      " [43.81491  ]\n",
      " [31.48197  ]\n",
      " [25.740835 ]\n",
      " [27.054289 ]\n",
      " [25.706863 ]\n",
      " [24.427584 ]\n",
      " [32.197365 ]\n",
      " [24.950247 ]\n",
      " [13.571225 ]\n",
      " [23.992735 ]\n",
      " [15.363878 ]\n",
      " [43.812325 ]\n",
      " [22.923813 ]\n",
      " [14.896801 ]\n",
      " [16.695963 ]\n",
      " [23.277723 ]\n",
      " [25.213047 ]\n",
      " [28.31991  ]\n",
      " [16.38848  ]\n",
      " [13.4539175]\n",
      " [21.164856 ]\n",
      " [13.08446  ]\n",
      " [13.419397 ]\n",
      " [25.986946 ]\n",
      " [24.310612 ]\n",
      " [24.217182 ]\n",
      " [14.75458  ]\n",
      " [25.455858 ]\n",
      " [27.361303 ]\n",
      " [23.627058 ]\n",
      " [18.718143 ]\n",
      " [14.842133 ]\n",
      " [27.081211 ]\n",
      " [15.653412 ]\n",
      " [24.064667 ]\n",
      " [25.398726 ]\n",
      " [43.68649  ]\n",
      " [18.093107 ]\n",
      " [24.18274  ]\n",
      " [24.159443 ]\n",
      " [22.58975  ]\n",
      " [13.013158 ]\n",
      " [23.050577 ]\n",
      " [23.330278 ]\n",
      " [25.06804  ]\n",
      " [41.984917 ]\n",
      " [31.532955 ]\n",
      " [22.155405 ]\n",
      " [39.57324  ]\n",
      " [13.855883 ]\n",
      " [21.612864 ]\n",
      " [13.072704 ]\n",
      " [25.372425 ]\n",
      " [24.27166  ]\n",
      " [25.127035 ]\n",
      " [36.53616  ]\n",
      " [40.921833 ]\n",
      " [23.498583 ]\n",
      " [13.399694 ]\n",
      " [43.885    ]\n",
      " [25.756153 ]\n",
      " [27.698956 ]\n",
      " [23.937622 ]\n",
      " [31.467974 ]\n",
      " [22.950914 ]\n",
      " [15.105296 ]\n",
      " [43.88578  ]\n",
      " [43.919415 ]\n",
      " [26.233356 ]\n",
      " [26.474026 ]\n",
      " [14.044347 ]\n",
      " [29.553455 ]\n",
      " [15.294886 ]\n",
      " [23.137936 ]\n",
      " [13.008961 ]\n",
      " [27.344015 ]\n",
      " [40.91379  ]\n",
      " [26.808702 ]\n",
      " [24.079924 ]\n",
      " [13.081838 ]\n",
      " [32.21491  ]\n",
      " [13.025039 ]\n",
      " [22.79764  ]\n",
      " [26.077179 ]\n",
      " [25.925865 ]\n",
      " [27.101845 ]\n",
      " [24.940676 ]\n",
      " [30.900745 ]\n",
      " [25.264357 ]\n",
      " [13.104992 ]\n",
      " [14.4680395]\n",
      " [26.660141 ]\n",
      " [29.479433 ]\n",
      " [41.668148 ]\n",
      " [13.328543 ]\n",
      " [22.438316 ]\n",
      " [23.300116 ]\n",
      " [18.941021 ]\n",
      " [23.65147  ]\n",
      " [12.987382 ]\n",
      " [24.017805 ]\n",
      " [13.540034 ]\n",
      " [43.926    ]\n",
      " [40.21765  ]\n",
      " [13.509203 ]\n",
      " [23.136238 ]\n",
      " [24.69407  ]\n",
      " [26.30896  ]\n",
      " [25.10542  ]\n",
      " [43.215874 ]\n",
      " [21.06483  ]\n",
      " [24.837301 ]\n",
      " [41.62512  ]\n",
      " [14.528484 ]\n",
      " [12.981324 ]\n",
      " [19.59424  ]\n",
      " [22.708973 ]\n",
      " [13.03828  ]\n",
      " [43.58021  ]\n",
      " [25.713987 ]\n",
      " [15.55667  ]\n",
      " [29.546211 ]\n",
      " [12.978261 ]\n",
      " [13.994235 ]\n",
      " [24.563284 ]\n",
      " [39.306313 ]\n",
      " [31.434082 ]\n",
      " [25.794249 ]\n",
      " [22.601055 ]\n",
      " [43.38462  ]\n",
      " [39.87067  ]\n",
      " [13.2305355]\n",
      " [13.253114 ]\n",
      " [30.143488 ]\n",
      " [28.369009 ]]\n"
     ]
    }
   ],
   "source": [
    "# 予測値の算出\n",
    "y_predict_n = model.predict(X_test_n)\n",
    "y_predict = scaler_y.inverse_transform(y_predict_n)\n",
    "print(y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.24444470224155304"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 乖離度の算出\n",
    "import numpy as np\n",
    "np.mean(np.abs(y_test-y_predict.flatten())/y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
