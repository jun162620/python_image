{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 畳み込みニューラルネット\n",
    "\n",
    "## 概要\n",
    "\n",
    "\n",
    "Convolutional Neural Network(畳み込みニューラルネット)は略してCNNと呼ばれる。\n",
    "\n",
    "CNNは一般的な順伝播型のニューラルネットワークとは違い、全結合層だけでなく畳み込み層(Convolution Layer)とプーリング層(Pooling Layer)から構成される\n",
    "\n",
    "## 処理の流れ\n",
    "+ **入力層**：入力ベクトル(画像など)を入力する\n",
    "+ **特徴抽出**：入力ベクトルから、そのベクトルを象徴するようなベクトルに変換する\n",
    "    + **畳み込み層**\n",
    "    + **プーリング層**\n",
    "+ **フラット層**：高次元ベクトルを1次元ベクトルに変更する\n",
    "+ **全結合層**（中間層）：通常のニューラルネット\n",
    "+ **出力層**：分類結果を出力する"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/CNN_sample.jpg\">\n",
    "\n",
    "引用：https://kenyu-life.com/2019/03/07/convolutional_neural_network/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 畳み込み層\n",
    "\n",
    "### 1次元(グレースケール)\n",
    "<img src=\"./images/CNN_conv.gif\">\n",
    "引用：https://kenyu-life.com/2019/03/07/convolutional_neural_network/\n",
    "\n",
    "### 3次元(RGB)\n",
    "<img src=\"./images/CNN_conv_3D.gif\">\n",
    "引用：https://kenyu-life.com/2019/03/07/convolutional_neural_network/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### プーリング層\n",
    "\n",
    "<img src=\"./images/CNN_pooling.gif\">\n",
    "引用：https://kenyu-life.com/2019/03/07/convolutional_neural_network/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNNで扱う問題\n",
    "\n",
    "+ 分類：\n",
    "+ 検出：\n",
    "+ セグメンテーション："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 分類\n",
    "\n",
    "画像に何が書かれているのかを判別する。\n",
    "\n",
    "MNISTという手書き文字の画像を使用していく。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 学習データの生成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 画像データの読み込み\n",
    "from keras.datasets import mnist\n",
    "import numpy as np\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28) (60000,) (10000, 28, 28) (10000,)\n"
     ]
    }
   ],
   "source": [
    "# データの形式\n",
    "print(\n",
    "    X_train.shape,\n",
    "    y_train.shape,\n",
    "    X_test.shape,\n",
    "    y_test.shape\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# データ確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   3,\n",
       "         18,  18,  18, 126, 136, 175,  26, 166, 255, 247, 127,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  30,  36,  94, 154, 170,\n",
       "        253, 253, 253, 253, 253, 225, 172, 253, 242, 195,  64,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  49, 238, 253, 253, 253, 253,\n",
       "        253, 253, 253, 253, 251,  93,  82,  82,  56,  39,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  18, 219, 253, 253, 253, 253,\n",
       "        253, 198, 182, 247, 241,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  80, 156, 107, 253, 253,\n",
       "        205,  11,   0,  43, 154,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,  14,   1, 154, 253,\n",
       "         90,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 139, 253,\n",
       "        190,   2,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  11, 190,\n",
       "        253,  70,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  35,\n",
       "        241, 225, 160, 108,   1,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         81, 240, 253, 253, 119,  25,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,  45, 186, 253, 253, 150,  27,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,  16,  93, 252, 253, 187,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0, 249, 253, 249,  64,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,  46, 130, 183, 253, 253, 207,   2,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  39,\n",
       "        148, 229, 253, 253, 253, 250, 182,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  24, 114, 221,\n",
       "        253, 253, 253, 253, 201,  78,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  23,  66, 213, 253, 253,\n",
       "        253, 253, 198,  81,   2,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,  18, 171, 219, 253, 253, 253, 253,\n",
       "        195,  80,   9,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,  55, 172, 226, 253, 253, 253, 253, 244, 133,\n",
       "         11,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0, 136, 253, 253, 253, 212, 135, 132,  16,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0]], dtype=uint8)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 画像データ\n",
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x19ec81c78d0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.imshow(X_train[0],cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 正解ラベル\n",
    "y_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# データが大きいので少なくする"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 計算に時間がかかるため、データ量を制限する\n",
    "X_train = X_train[:15000]/255\n",
    "X_test = X_test[:2500]/255\n",
    "y_train = y_train[:15000]\n",
    "y_test = y_test[:2500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNNに使用するためにデータを変形(グレースケール)\n",
    "X_train = X_train.reshape(X_train.shape[0], 28, 28, 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], 28, 28, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ベクトルからone hotに変換する\n",
    "import keras\n",
    "y_train = keras.utils.to_categorical(y_train,10)\n",
    "y_test = keras.utils.to_categorical(y_test,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# モデル作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 必要なライブラリのインポート\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 基本モデル作成\n",
    "model = Sequential()\n",
    "\n",
    "# 3×3の畳み込み層の追加\n",
    "model.add(\n",
    "    Conv2D(\n",
    "        filters=32,\n",
    "        kernel_size=(3, 3),\n",
    "        activation='relu',\n",
    "    )\n",
    ")\n",
    "\n",
    "# 2×2のmaxプーリング層追加\n",
    "model.add(\n",
    "    MaxPooling2D(\n",
    "        pool_size=(2, 2)\n",
    "    )\n",
    ")\n",
    "\n",
    "# ドロップアウト層の追加\n",
    "model.add(\n",
    "    Dropout(0.2)\n",
    ")\n",
    "\n",
    "# フラット層の追加\n",
    "model.add(\n",
    "    Flatten()\n",
    ")\n",
    "\n",
    "# 全結合層の追加\n",
    "model.add(\n",
    "    Dense(\n",
    "        128, \n",
    "        activation='relu'\n",
    "    )\n",
    ")\n",
    "\n",
    "# ドロップアウト層の追加\n",
    "model.add(\n",
    "    Dropout(0.2)\n",
    ")\n",
    "\n",
    "# 出力層\n",
    "model.add(\n",
    "    Dense(\n",
    "        10, \n",
    "        activation='softmax'\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# モデルの学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデルの学習設定\n",
    "model.compile(\n",
    "    loss=keras.losses.categorical_crossentropy,\n",
    "    optimizer=optimizers.SGD(lr=0.01),\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "15000/15000 [==============================] - 6s 381us/step - loss: 2.2506 - accuracy: 0.2127\n",
      "Epoch 2/10\n",
      "15000/15000 [==============================] - 6s 373us/step - loss: 1.9962 - accuracy: 0.5121\n",
      "Epoch 3/10\n",
      "15000/15000 [==============================] - 6s 374us/step - loss: 1.4453 - accuracy: 0.6709\n",
      "Epoch 4/10\n",
      "15000/15000 [==============================] - 6s 375us/step - loss: 0.9557 - accuracy: 0.7531\n",
      "Epoch 5/10\n",
      "15000/15000 [==============================] - 6s 375us/step - loss: 0.7376 - accuracy: 0.7921\n",
      "Epoch 6/10\n",
      "15000/15000 [==============================] - 6s 374us/step - loss: 0.6237 - accuracy: 0.8165\n",
      "Epoch 7/10\n",
      "15000/15000 [==============================] - 6s 381us/step - loss: 0.5554 - accuracy: 0.8365\n",
      "Epoch 8/10\n",
      "15000/15000 [==============================] - 6s 377us/step - loss: 0.5155 - accuracy: 0.8483\n",
      "Epoch 9/10\n",
      "15000/15000 [==============================] - 6s 393us/step - loss: 0.4849 - accuracy: 0.8566\n",
      "Epoch 10/10\n",
      "15000/15000 [==============================] - 6s 389us/step - loss: 0.4636 - accuracy: 0.8602\n"
     ]
    }
   ],
   "source": [
    "# モデルの学習\n",
    "result = model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    batch_size=256,\n",
    "    epochs=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.4656474244117737, 0.868399977684021]\n"
     ]
    }
   ],
   "source": [
    "# モデル結果の出力\n",
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 学習済みモデルの適用（転移学習）\n",
    "\n",
    "kerasには、すでに学習が済んでいるニューラルネットワークモデルを流用することができる。転移学習といいます。\n",
    "\n",
    "同じような手法に、fine tuningというものがありますが、こちらは、学習済みモデルの重みを初期値にして、重みのみ再学習するという手法を取ります。\n",
    "\n",
    "転移学習は、学習済みモデルに、層を追加して、その層について学習します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 32, 32, 3) (50000, 1) (10000, 32, 32, 3) (10000, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x191f4520da0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from keras.datasets import cifar10\n",
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
    "\n",
    "# データの形式\n",
    "print(\n",
    "    X_train.shape,\n",
    "    y_train.shape,\n",
    "    X_test.shape,\n",
    "    y_test.shape\n",
    ")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.imshow(X_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 計算に時間がかかるため、データ量を制限する\n",
    "X_train = X_train[:25000]\n",
    "X_test = X_test[:2500]\n",
    "y_train = y_train[:25000]\n",
    "y_test = y_test[:2500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ベクトルからone hotに変換する\n",
    "y_train = keras.utils.to_categorical(y_train,10)\n",
    "y_test = keras.utils.to_categorical(y_test,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "25000/25000 [==============================] - 669s 27ms/step - loss: 4.2740 - accuracy: 0.1043\n",
      "Epoch 2/100\n",
      "25000/25000 [==============================] - 655s 26ms/step - loss: 2.3013 - accuracy: 0.1063\n",
      "Epoch 3/100\n",
      "25000/25000 [==============================] - 656s 26ms/step - loss: 2.3001 - accuracy: 0.1042\n",
      "Epoch 4/100\n",
      "25000/25000 [==============================] - 657s 26ms/step - loss: 2.3022 - accuracy: 0.1006\n",
      "Epoch 5/100\n",
      "25000/25000 [==============================] - 648s 26ms/step - loss: 2.3017 - accuracy: 0.1047\n",
      "Epoch 6/100\n",
      "25000/25000 [==============================] - 657s 26ms/step - loss: 2.2988 - accuracy: 0.1088\n",
      "Epoch 7/100\n",
      "25000/25000 [==============================] - 657s 26ms/step - loss: 2.3000 - accuracy: 0.1064\n",
      "Epoch 8/100\n",
      "25000/25000 [==============================] - 656s 26ms/step - loss: 2.2971 - accuracy: 0.1102\n",
      "Epoch 9/100\n",
      "25000/25000 [==============================] - 657s 26ms/step - loss: 2.2907 - accuracy: 0.1192\n",
      "Epoch 10/100\n",
      "25000/25000 [==============================] - 655s 26ms/step - loss: 2.2855 - accuracy: 0.1224\n",
      "Epoch 11/100\n",
      "25000/25000 [==============================] - 656s 26ms/step - loss: 2.2624 - accuracy: 0.1470\n",
      "Epoch 12/100\n",
      "25000/25000 [==============================] - 657s 26ms/step - loss: 2.2526 - accuracy: 0.1594\n",
      "Epoch 13/100\n",
      "25000/25000 [==============================] - 658s 26ms/step - loss: 2.2074 - accuracy: 0.2070\n",
      "Epoch 14/100\n",
      "25000/25000 [==============================] - 658s 26ms/step - loss: 2.1113 - accuracy: 0.2678\n",
      "Epoch 15/100\n",
      "25000/25000 [==============================] - 653s 26ms/step - loss: 1.9641 - accuracy: 0.3468\n",
      "Epoch 16/100\n",
      "25000/25000 [==============================] - 659s 26ms/step - loss: 1.7415 - accuracy: 0.4582\n",
      "Epoch 17/100\n",
      "25000/25000 [==============================] - 657s 26ms/step - loss: 1.5740 - accuracy: 0.5236\n",
      "Epoch 18/100\n",
      "25000/25000 [==============================] - 664s 27ms/step - loss: 1.4457 - accuracy: 0.5668\n",
      "Epoch 19/100\n",
      "25000/25000 [==============================] - 657s 26ms/step - loss: 1.3503 - accuracy: 0.6015\n",
      "Epoch 20/100\n",
      "25000/25000 [==============================] - 659s 26ms/step - loss: 1.2733 - accuracy: 0.6254\n",
      "Epoch 21/100\n",
      "25000/25000 [==============================] - 659s 26ms/step - loss: 1.1920 - accuracy: 0.6517\n",
      "Epoch 22/100\n",
      "25000/25000 [==============================] - 659s 26ms/step - loss: 1.1058 - accuracy: 0.6782\n",
      "Epoch 23/100\n",
      "25000/25000 [==============================] - 657s 26ms/step - loss: 1.0777 - accuracy: 0.6826\n",
      "Epoch 24/100\n",
      "25000/25000 [==============================] - 658s 26ms/step - loss: 1.0278 - accuracy: 0.7058\n",
      "Epoch 25/100\n",
      "25000/25000 [==============================] - 659s 26ms/step - loss: 0.9729 - accuracy: 0.7177\n",
      "Epoch 26/100\n",
      "25000/25000 [==============================] - 658s 26ms/step - loss: 0.9122 - accuracy: 0.7376\n",
      "Epoch 27/100\n",
      "25000/25000 [==============================] - 657s 26ms/step - loss: 0.8734 - accuracy: 0.7492\n",
      "Epoch 28/100\n",
      "25000/25000 [==============================] - 660s 26ms/step - loss: 0.8519 - accuracy: 0.7556\n",
      "Epoch 29/100\n",
      "25000/25000 [==============================] - 660s 26ms/step - loss: 0.8034 - accuracy: 0.7694\n",
      "Epoch 30/100\n",
      "25000/25000 [==============================] - 661s 26ms/step - loss: 0.7794 - accuracy: 0.7746\n",
      "Epoch 31/100\n",
      "25000/25000 [==============================] - 660s 26ms/step - loss: 0.7581 - accuracy: 0.7814\n",
      "Epoch 32/100\n",
      "25000/25000 [==============================] - 660s 26ms/step - loss: 0.6990 - accuracy: 0.7872\n",
      "Epoch 33/100\n",
      "25000/25000 [==============================] - 661s 26ms/step - loss: 0.6483 - accuracy: 0.7947\n",
      "Epoch 34/100\n",
      "25000/25000 [==============================] - 660s 26ms/step - loss: 0.5676 - accuracy: 0.8215\n",
      "Epoch 35/100\n",
      "25000/25000 [==============================] - 660s 26ms/step - loss: 0.5250 - accuracy: 0.8326\n",
      "Epoch 36/100\n",
      "25000/25000 [==============================] - 666s 27ms/step - loss: 0.4850 - accuracy: 0.8470\n",
      "Epoch 37/100\n",
      "25000/25000 [==============================] - 661s 26ms/step - loss: 0.4425 - accuracy: 0.8594\n",
      "Epoch 38/100\n",
      "25000/25000 [==============================] - 660s 26ms/step - loss: 0.4326 - accuracy: 0.8637\n",
      "Epoch 39/100\n",
      "25000/25000 [==============================] - 660s 26ms/step - loss: 0.3797 - accuracy: 0.8833\n",
      "Epoch 40/100\n",
      "25000/25000 [==============================] - 661s 26ms/step - loss: 0.3663 - accuracy: 0.8846\n",
      "Epoch 41/100\n",
      "25000/25000 [==============================] - 660s 26ms/step - loss: 0.3682 - accuracy: 0.8826\n",
      "Epoch 42/100\n",
      "25000/25000 [==============================] - 661s 26ms/step - loss: 0.3068 - accuracy: 0.9047\n",
      "Epoch 43/100\n",
      "25000/25000 [==============================] - 659s 26ms/step - loss: 0.2945 - accuracy: 0.9099\n",
      "Epoch 44/100\n",
      "25000/25000 [==============================] - 659s 26ms/step - loss: 0.3753 - accuracy: 0.8879\n",
      "Epoch 45/100\n",
      "25000/25000 [==============================] - 663s 27ms/step - loss: 0.2664 - accuracy: 0.9172\n",
      "Epoch 46/100\n",
      "25000/25000 [==============================] - 661s 26ms/step - loss: 0.2325 - accuracy: 0.9292\n",
      "Epoch 47/100\n",
      "25000/25000 [==============================] - 659s 26ms/step - loss: 0.2163 - accuracy: 0.9346\n",
      "Epoch 48/100\n",
      "25000/25000 [==============================] - 663s 27ms/step - loss: 0.1898 - accuracy: 0.9438\n",
      "Epoch 49/100\n",
      "25000/25000 [==============================] - 660s 26ms/step - loss: 0.1726 - accuracy: 0.9480\n",
      "Epoch 50/100\n",
      "25000/25000 [==============================] - 659s 26ms/step - loss: 0.1613 - accuracy: 0.9512\n",
      "Epoch 51/100\n",
      "25000/25000 [==============================] - 663s 27ms/step - loss: 0.1704 - accuracy: 0.9496\n",
      "Epoch 52/100\n",
      "25000/25000 [==============================] - 654s 26ms/step - loss: 0.2353 - accuracy: 0.9309\n",
      "Epoch 53/100\n",
      "25000/25000 [==============================] - 651s 26ms/step - loss: 0.1256 - accuracy: 0.9641\n",
      "Epoch 54/100\n",
      "25000/25000 [==============================] - 654s 26ms/step - loss: 0.1149 - accuracy: 0.9659\n",
      "Epoch 55/100\n",
      "25000/25000 [==============================] - 653s 26ms/step - loss: 0.1044 - accuracy: 0.9707\n",
      "Epoch 56/100\n",
      "25000/25000 [==============================] - 654s 26ms/step - loss: 0.0987 - accuracy: 0.9722\n",
      "Epoch 57/100\n",
      "25000/25000 [==============================] - 653s 26ms/step - loss: 0.0926 - accuracy: 0.9733\n",
      "Epoch 58/100\n",
      "25000/25000 [==============================] - 653s 26ms/step - loss: 0.0895 - accuracy: 0.9730\n",
      "Epoch 59/100\n",
      "25000/25000 [==============================] - 652s 26ms/step - loss: 0.0850 - accuracy: 0.9762\n",
      "Epoch 60/100\n",
      "25000/25000 [==============================] - 652s 26ms/step - loss: 0.0783 - accuracy: 0.9768\n",
      "Epoch 61/100\n",
      "25000/25000 [==============================] - 653s 26ms/step - loss: 0.0748 - accuracy: 0.9782\n",
      "Epoch 62/100\n",
      "25000/25000 [==============================] - 654s 26ms/step - loss: 0.0735 - accuracy: 0.9782\n",
      "Epoch 63/100\n",
      "25000/25000 [==============================] - 657s 26ms/step - loss: 0.0711 - accuracy: 0.9788\n",
      "Epoch 64/100\n",
      "25000/25000 [==============================] - 724s 29ms/step - loss: 2.0828 - accuracy: 0.4625\n",
      "Epoch 65/100\n",
      "25000/25000 [==============================] - 649s 26ms/step - loss: 0.8714 - accuracy: 0.7306\n",
      "Epoch 66/100\n",
      "25000/25000 [==============================] - 659s 26ms/step - loss: 0.6073 - accuracy: 0.8211\n",
      "Epoch 67/100\n",
      "25000/25000 [==============================] - 643s 26ms/step - loss: 0.4117 - accuracy: 0.8729\n",
      "Epoch 68/100\n",
      "25000/25000 [==============================] - 642s 26ms/step - loss: 0.2892 - accuracy: 0.9095\n",
      "Epoch 69/100\n",
      "25000/25000 [==============================] - 643s 26ms/step - loss: 0.1963 - accuracy: 0.9431\n",
      "Epoch 70/100\n",
      "25000/25000 [==============================] - 645s 26ms/step - loss: 0.1739 - accuracy: 0.9482\n",
      "Epoch 71/100\n",
      "25000/25000 [==============================] - 642s 26ms/step - loss: 0.1887 - accuracy: 0.9468\n",
      "Epoch 72/100\n",
      "25000/25000 [==============================] - 644s 26ms/step - loss: 0.1242 - accuracy: 0.9646\n",
      "Epoch 73/100\n",
      "25000/25000 [==============================] - 649s 26ms/step - loss: 0.1049 - accuracy: 0.9716\n",
      "Epoch 74/100\n",
      "25000/25000 [==============================] - 649s 26ms/step - loss: 0.0909 - accuracy: 0.9758\n",
      "Epoch 75/100\n",
      "25000/25000 [==============================] - 647s 26ms/step - loss: 0.0831 - accuracy: 0.9769\n",
      "Epoch 76/100\n",
      "25000/25000 [==============================] - 648s 26ms/step - loss: 0.0759 - accuracy: 0.9780\n",
      "Epoch 77/100\n",
      "25000/25000 [==============================] - 664s 27ms/step - loss: 0.0707 - accuracy: 0.9800\n",
      "Epoch 78/100\n",
      "25000/25000 [==============================] - 668s 27ms/step - loss: 0.0675 - accuracy: 0.9812\n",
      "Epoch 79/100\n",
      "25000/25000 [==============================] - 668s 27ms/step - loss: 0.0630 - accuracy: 0.9822\n",
      "Epoch 80/100\n",
      "25000/25000 [==============================] - 668s 27ms/step - loss: 0.0588 - accuracy: 0.9822\n",
      "Epoch 81/100\n",
      "25000/25000 [==============================] - 671s 27ms/step - loss: 0.0558 - accuracy: 0.9837\n",
      "Epoch 82/100\n",
      "25000/25000 [==============================] - 669s 27ms/step - loss: 0.0539 - accuracy: 0.9841\n",
      "Epoch 83/100\n",
      "25000/25000 [==============================] - 668s 27ms/step - loss: 0.0509 - accuracy: 0.9851\n",
      "Epoch 84/100\n",
      "25000/25000 [==============================] - 670s 27ms/step - loss: 0.0493 - accuracy: 0.9853\n",
      "Epoch 85/100\n",
      "25000/25000 [==============================] - 667s 27ms/step - loss: 0.0478 - accuracy: 0.9855\n",
      "Epoch 86/100\n",
      "25000/25000 [==============================] - 669s 27ms/step - loss: 0.0464 - accuracy: 0.9859\n",
      "Epoch 87/100\n",
      "25000/25000 [==============================] - 669s 27ms/step - loss: 0.0453 - accuracy: 0.9863\n",
      "Epoch 88/100\n",
      "25000/25000 [==============================] - 669s 27ms/step - loss: 0.0441 - accuracy: 0.9864\n",
      "Epoch 89/100\n",
      "25000/25000 [==============================] - 670s 27ms/step - loss: 0.0436 - accuracy: 0.9867\n",
      "Epoch 90/100\n",
      "25000/25000 [==============================] - 670s 27ms/step - loss: 0.0420 - accuracy: 0.9871\n",
      "Epoch 91/100\n",
      "25000/25000 [==============================] - 669s 27ms/step - loss: 0.0408 - accuracy: 0.9875\n",
      "Epoch 92/100\n",
      "25000/25000 [==============================] - 668s 27ms/step - loss: 0.0404 - accuracy: 0.9872\n",
      "Epoch 93/100\n",
      "25000/25000 [==============================] - 667s 27ms/step - loss: 0.0389 - accuracy: 0.9880\n",
      "Epoch 94/100\n",
      "25000/25000 [==============================] - 668s 27ms/step - loss: 0.0391 - accuracy: 0.9880\n",
      "Epoch 95/100\n",
      "25000/25000 [==============================] - 653s 26ms/step - loss: 0.0375 - accuracy: 0.9885\n",
      "Epoch 96/100\n",
      "25000/25000 [==============================] - 646s 26ms/step - loss: 0.0369 - accuracy: 0.9886\n",
      "Epoch 97/100\n",
      "25000/25000 [==============================] - 645s 26ms/step - loss: 0.0359 - accuracy: 0.9892\n",
      "Epoch 98/100\n",
      "25000/25000 [==============================] - 644s 26ms/step - loss: 0.0350 - accuracy: 0.9890\n",
      "Epoch 99/100\n",
      "25000/25000 [==============================] - 645s 26ms/step - loss: 0.0367 - accuracy: 0.9884\n",
      "Epoch 100/100\n",
      "25000/25000 [==============================] - 644s 26ms/step - loss: 0.0353 - accuracy: 0.9890\n"
     ]
    }
   ],
   "source": [
    "from keras.applications.vgg16 import VGG16\n",
    "from keras import models\n",
    "from keras import layers\n",
    "\n",
    "# VGG16モデル\n",
    "img_rows = 32\n",
    "img_cols = 32\n",
    "input_tensor = layers.Input(shape=(img_rows, img_cols, 3))\n",
    "vgg16 = VGG16(include_top=False, weights='imagenet', input_tensor=input_tensor)\n",
    "\n",
    "# 全結合層は自己学習モデル\n",
    "model_ = Sequential()\n",
    "model_.add(Flatten(input_shape=vgg16.output_shape[1:]))\n",
    "model_.add(Dense(256, activation='relu'))\n",
    "model_.add(Dropout(0.5))\n",
    "model_.add(Dense(10, activation='softmax'))\n",
    "\n",
    "# VGG16モデルと自己学習モデルの結合\n",
    "model = models.Model(inputs=vgg16.input, outputs=model_(vgg16.output))\n",
    "\n",
    "# modelの14層目までのモデル重み\n",
    "for layer in model.layers[:15]:\n",
    "    layer.trainable = False\n",
    "\n",
    "# モデルの学習設定\n",
    "model.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer=optimizers.SGD(lr=0.005),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "0\n",
    "# モデルの学習\n",
    "result = model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    batch_size=512,\n",
    "    epochs=100,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデルの保存\n",
    "model.save('./model/model_cnn.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# テストデータへの適用\n",
    "import numpy as np\n",
    "y_predict = np.argmax(model.predict(X_test),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7228\n"
     ]
    }
   ],
   "source": [
    "# 正答率の算出\n",
    "y_test = np.argmax(y_test,axis=1)\n",
    "acc=np.sum(y_test==y_predict)/len(y_test)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 転移学習を行わなかった場合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データ読み込み\n",
    "from keras.datasets import cifar10\n",
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
    "\n",
    "# 計算に時間がかかるため、データ量を制限する\n",
    "X_train = X_train[:25000]\n",
    "X_test = X_test[:2500]\n",
    "y_train = y_train[:25000]\n",
    "y_test = y_test[:2500]\n",
    "\n",
    "# ベクトルからone hotに変換する\n",
    "y_train = keras.utils.to_categorical(y_train,10)\n",
    "y_test = keras.utils.to_categorical(y_test,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 基本モデル作成\n",
    "model = Sequential()\n",
    "\n",
    "# 3×3の畳み込み層の追加\n",
    "model.add(\n",
    "    Conv2D(\n",
    "        filters=32,\n",
    "        kernel_size=(3, 3),\n",
    "        activation='relu',\n",
    "    )\n",
    ")\n",
    "\n",
    "# 2×2のmaxプーリング層追加\n",
    "model.add(\n",
    "    MaxPooling2D(\n",
    "        pool_size=(2, 2)\n",
    "    )\n",
    ")\n",
    "\n",
    "# ドロップアウト層の追加\n",
    "model.add(\n",
    "    Dropout(0.2)\n",
    ")\n",
    "\n",
    "# フラット層の追加\n",
    "model.add(\n",
    "    Flatten()\n",
    ")\n",
    "\n",
    "# 全結合層の追加\n",
    "model.add(\n",
    "    Dense(\n",
    "        128, \n",
    "        activation='relu'\n",
    "    )\n",
    ")\n",
    "\n",
    "# ドロップアウト層の追加\n",
    "model.add(\n",
    "    Dropout(0.2)\n",
    ")\n",
    "\n",
    "# 出力層\n",
    "model.add(\n",
    "    Dense(\n",
    "        10, \n",
    "        activation='softmax'\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデルの学習設定\n",
    "model.compile(\n",
    "    loss=keras.losses.categorical_crossentropy,\n",
    "    optimizer=optimizers.SGD(lr=0.01),\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "25000/25000 [==============================] - 15s 592us/step - loss: 2.3053 - accuracy: 0.1013\n",
      "Epoch 2/100\n",
      "25000/25000 [==============================] - 14s 557us/step - loss: 2.3029 - accuracy: 0.0973\n",
      "Epoch 3/100\n",
      "25000/25000 [==============================] - 13s 523us/step - loss: 2.3028 - accuracy: 0.1001\n",
      "Epoch 4/100\n",
      "25000/25000 [==============================] - 13s 531us/step - loss: 2.3027 - accuracy: 0.1002\n",
      "Epoch 5/100\n",
      "25000/25000 [==============================] - 13s 532us/step - loss: 2.3024 - accuracy: 0.1013\n",
      "Epoch 6/100\n",
      "25000/25000 [==============================] - 14s 564us/step - loss: 2.3024 - accuracy: 0.1012\n",
      "Epoch 7/100\n",
      "25000/25000 [==============================] - 13s 529us/step - loss: 2.3021 - accuracy: 0.1019\n",
      "Epoch 8/100\n",
      "25000/25000 [==============================] - 13s 531us/step - loss: 2.3021 - accuracy: 0.1018\n",
      "Epoch 9/100\n",
      "25000/25000 [==============================] - 13s 533us/step - loss: 2.3020 - accuracy: 0.1020\n",
      "Epoch 10/100\n",
      "25000/25000 [==============================] - 13s 530us/step - loss: 2.3022 - accuracy: 0.1013\n",
      "Epoch 11/100\n",
      "25000/25000 [==============================] - 13s 530us/step - loss: 2.3019 - accuracy: 0.1000\n",
      "Epoch 12/100\n",
      "25000/25000 [==============================] - 13s 531us/step - loss: 2.3019 - accuracy: 0.1034\n",
      "Epoch 13/100\n",
      "25000/25000 [==============================] - 14s 575us/step - loss: 2.3019 - accuracy: 0.1029\n",
      "Epoch 14/100\n",
      "25000/25000 [==============================] - 13s 515us/step - loss: 2.3013 - accuracy: 0.1018\n",
      "Epoch 15/100\n",
      "25000/25000 [==============================] - 17s 665us/step - loss: 2.3011 - accuracy: 0.1033\n",
      "Epoch 16/100\n",
      "25000/25000 [==============================] - 15s 602us/step - loss: 2.3007 - accuracy: 0.1054\n",
      "Epoch 17/100\n",
      "25000/25000 [==============================] - 16s 635us/step - loss: 2.3004 - accuracy: 0.1033\n",
      "Epoch 18/100\n",
      "25000/25000 [==============================] - 16s 636us/step - loss: 2.2994 - accuracy: 0.1072\n",
      "Epoch 19/100\n",
      "25000/25000 [==============================] - 16s 638us/step - loss: 2.2975 - accuracy: 0.1072\n",
      "Epoch 20/100\n",
      "25000/25000 [==============================] - 17s 667us/step - loss: 2.2948 - accuracy: 0.1119\n",
      "Epoch 21/100\n",
      "25000/25000 [==============================] - 14s 563us/step - loss: 2.3026 - accuracy: 0.1039\n",
      "Epoch 22/100\n",
      "25000/25000 [==============================] - 18s 706us/step - loss: 2.3020 - accuracy: 0.1034\n",
      "Epoch 23/100\n",
      "25000/25000 [==============================] - 15s 593us/step - loss: 2.3019 - accuracy: 0.1006\n",
      "Epoch 24/100\n",
      "25000/25000 [==============================] - 13s 507us/step - loss: 2.3011 - accuracy: 0.1038\n",
      "Epoch 25/100\n",
      "25000/25000 [==============================] - 13s 510us/step - loss: 2.2966 - accuracy: 0.1106\n",
      "Epoch 26/100\n",
      "25000/25000 [==============================] - 13s 514us/step - loss: 2.2895 - accuracy: 0.1194\n",
      "Epoch 27/100\n",
      "25000/25000 [==============================] - 13s 506us/step - loss: 2.2849 - accuracy: 0.1186\n",
      "Epoch 28/100\n",
      "25000/25000 [==============================] - 13s 507us/step - loss: 2.2823 - accuracy: 0.1218\n",
      "Epoch 29/100\n",
      "25000/25000 [==============================] - 15s 587us/step - loss: 2.3015 - accuracy: 0.1038\n",
      "Epoch 30/100\n",
      "25000/25000 [==============================] - 15s 593us/step - loss: 2.3017 - accuracy: 0.1018\n",
      "Epoch 31/100\n",
      "25000/25000 [==============================] - 14s 565us/step - loss: 2.3014 - accuracy: 0.1029\n",
      "Epoch 32/100\n",
      "25000/25000 [==============================] - 13s 507us/step - loss: 2.3013 - accuracy: 0.1035\n",
      "Epoch 33/100\n",
      "25000/25000 [==============================] - 13s 515us/step - loss: 2.3014 - accuracy: 0.1039\n",
      "Epoch 34/100\n",
      "25000/25000 [==============================] - 16s 648us/step - loss: 2.3012 - accuracy: 0.1049\n",
      "Epoch 35/100\n",
      "25000/25000 [==============================] - 17s 663us/step - loss: 2.3014 - accuracy: 0.1048\n",
      "Epoch 36/100\n",
      "25000/25000 [==============================] - 14s 576us/step - loss: 2.3008 - accuracy: 0.1052\n",
      "Epoch 37/100\n",
      "25000/25000 [==============================] - 13s 535us/step - loss: 2.3003 - accuracy: 0.1056\n",
      "Epoch 38/100\n",
      "25000/25000 [==============================] - 13s 535us/step - loss: 2.2887 - accuracy: 0.1157\n",
      "Epoch 39/100\n",
      "25000/25000 [==============================] - 13s 535us/step - loss: 2.2777 - accuracy: 0.1224\n",
      "Epoch 40/100\n",
      "25000/25000 [==============================] - 13s 534us/step - loss: 2.2757 - accuracy: 0.1250\n",
      "Epoch 41/100\n",
      "25000/25000 [==============================] - 13s 534us/step - loss: 2.2765 - accuracy: 0.1228\n",
      "Epoch 42/100\n",
      "25000/25000 [==============================] - 13s 535us/step - loss: 2.2747 - accuracy: 0.1226\n",
      "Epoch 43/100\n",
      "25000/25000 [==============================] - 14s 542us/step - loss: 2.2775 - accuracy: 0.1205\n",
      "Epoch 44/100\n",
      "25000/25000 [==============================] - 13s 534us/step - loss: 2.2752 - accuracy: 0.1243\n",
      "Epoch 45/100\n",
      "25000/25000 [==============================] - 13s 534us/step - loss: 2.3001 - accuracy: 0.1068\n",
      "Epoch 46/100\n",
      "25000/25000 [==============================] - 13s 536us/step - loss: 2.2989 - accuracy: 0.1084\n",
      "Epoch 47/100\n",
      "25000/25000 [==============================] - 13s 535us/step - loss: 2.2916 - accuracy: 0.1138\n",
      "Epoch 48/100\n",
      "25000/25000 [==============================] - 13s 534us/step - loss: 2.2605 - accuracy: 0.1361\n",
      "Epoch 49/100\n",
      "25000/25000 [==============================] - 15s 581us/step - loss: 2.2683 - accuracy: 0.1297\n",
      "Epoch 50/100\n",
      "25000/25000 [==============================] - 17s 673us/step - loss: 2.2878 - accuracy: 0.1099\n",
      "Epoch 51/100\n",
      "25000/25000 [==============================] - 15s 583us/step - loss: 2.2517 - accuracy: 0.1358\n",
      "Epoch 52/100\n",
      "25000/25000 [==============================] - 17s 666us/step - loss: 2.2410 - accuracy: 0.1484\n",
      "Epoch 53/100\n",
      "25000/25000 [==============================] - 16s 625us/step - loss: 2.2549 - accuracy: 0.1368\n",
      "Epoch 54/100\n",
      "25000/25000 [==============================] - 15s 600us/step - loss: 2.2434 - accuracy: 0.1455\n",
      "Epoch 55/100\n",
      "25000/25000 [==============================] - 15s 596us/step - loss: 2.2872 - accuracy: 0.1223\n",
      "Epoch 56/100\n",
      "25000/25000 [==============================] - 14s 549us/step - loss: 2.2973 - accuracy: 0.1104\n",
      "Epoch 57/100\n",
      "25000/25000 [==============================] - 14s 549us/step - loss: 2.3028 - accuracy: 0.1036\n",
      "Epoch 58/100\n",
      "25000/25000 [==============================] - 14s 548us/step - loss: 2.2975 - accuracy: 0.1104\n",
      "Epoch 59/100\n",
      "25000/25000 [==============================] - 15s 602us/step - loss: 2.2986 - accuracy: 0.1106\n",
      "Epoch 60/100\n",
      "25000/25000 [==============================] - 15s 601us/step - loss: 2.3018 - accuracy: 0.1029\n",
      "Epoch 61/100\n",
      "25000/25000 [==============================] - 15s 588us/step - loss: 2.3017 - accuracy: 0.1031\n",
      "Epoch 62/100\n",
      "25000/25000 [==============================] - 15s 608us/step - loss: 2.3019 - accuracy: 0.1038\n",
      "Epoch 63/100\n",
      "25000/25000 [==============================] - 17s 666us/step - loss: 2.3012 - accuracy: 0.1025\n",
      "Epoch 64/100\n",
      "25000/25000 [==============================] - 15s 589us/step - loss: 2.3009 - accuracy: 0.1039\n",
      "Epoch 65/100\n",
      "25000/25000 [==============================] - 15s 592us/step - loss: 2.3016 - accuracy: 0.1054\n",
      "Epoch 66/100\n",
      "25000/25000 [==============================] - 14s 568us/step - loss: 2.3004 - accuracy: 0.1032\n",
      "Epoch 67/100\n",
      "25000/25000 [==============================] - 15s 618us/step - loss: 2.3005 - accuracy: 0.1052\n",
      "Epoch 68/100\n",
      "25000/25000 [==============================] - 13s 530us/step - loss: 2.2990 - accuracy: 0.1059\n",
      "Epoch 69/100\n",
      "25000/25000 [==============================] - 13s 529us/step - loss: 2.2767 - accuracy: 0.1204\n",
      "Epoch 70/100\n",
      "25000/25000 [==============================] - 13s 529us/step - loss: 2.2335 - accuracy: 0.1482\n",
      "Epoch 71/100\n",
      "25000/25000 [==============================] - 13s 531us/step - loss: 2.2469 - accuracy: 0.1454\n",
      "Epoch 72/100\n",
      "25000/25000 [==============================] - 13s 530us/step - loss: 2.2662 - accuracy: 0.1249\n",
      "Epoch 73/100\n",
      "25000/25000 [==============================] - 13s 529us/step - loss: 2.2651 - accuracy: 0.1278\n",
      "Epoch 74/100\n",
      "25000/25000 [==============================] - 13s 529us/step - loss: 2.2994 - accuracy: 0.1050\n",
      "Epoch 75/100\n",
      "25000/25000 [==============================] - 13s 529us/step - loss: 2.2883 - accuracy: 0.1156\n",
      "Epoch 76/100\n",
      "25000/25000 [==============================] - 13s 532us/step - loss: 2.2089 - accuracy: 0.1648\n",
      "Epoch 77/100\n",
      "25000/25000 [==============================] - 13s 529us/step - loss: 2.2183 - accuracy: 0.1628\n",
      "Epoch 78/100\n",
      "25000/25000 [==============================] - 13s 529us/step - loss: 2.1922 - accuracy: 0.1752\n",
      "Epoch 79/100\n",
      "25000/25000 [==============================] - 13s 535us/step - loss: 2.2246 - accuracy: 0.1550\n",
      "Epoch 80/100\n",
      "25000/25000 [==============================] - 13s 531us/step - loss: 2.1888 - accuracy: 0.1743\n",
      "Epoch 81/100\n",
      "25000/25000 [==============================] - 13s 530us/step - loss: 2.1729 - accuracy: 0.1842\n",
      "Epoch 82/100\n",
      "25000/25000 [==============================] - 13s 530us/step - loss: 2.1856 - accuracy: 0.1795\n",
      "Epoch 83/100\n",
      "25000/25000 [==============================] - 13s 531us/step - loss: 2.1562 - accuracy: 0.1932\n",
      "Epoch 84/100\n",
      "25000/25000 [==============================] - 13s 531us/step - loss: 2.1520 - accuracy: 0.1982\n",
      "Epoch 85/100\n",
      "25000/25000 [==============================] - 13s 534us/step - loss: 2.1465 - accuracy: 0.1994\n",
      "Epoch 86/100\n",
      "25000/25000 [==============================] - 13s 537us/step - loss: 2.1300 - accuracy: 0.2111\n",
      "Epoch 87/100\n",
      "25000/25000 [==============================] - 13s 527us/step - loss: 2.1160 - accuracy: 0.2149\n",
      "Epoch 88/100\n",
      "25000/25000 [==============================] - 13s 506us/step - loss: 2.1210 - accuracy: 0.2177\n",
      "Epoch 89/100\n",
      "25000/25000 [==============================] - 13s 513us/step - loss: 2.1102 - accuracy: 0.2174\n",
      "Epoch 90/100\n",
      "25000/25000 [==============================] - 13s 506us/step - loss: 2.0882 - accuracy: 0.2316\n",
      "Epoch 91/100\n",
      "25000/25000 [==============================] - 13s 507us/step - loss: 2.0840 - accuracy: 0.2356\n",
      "Epoch 92/100\n",
      "25000/25000 [==============================] - 13s 507us/step - loss: 2.0740 - accuracy: 0.2376\n",
      "Epoch 93/100\n",
      "25000/25000 [==============================] - 13s 507us/step - loss: 2.0575 - accuracy: 0.2456\n",
      "Epoch 94/100\n",
      "25000/25000 [==============================] - 13s 508us/step - loss: 2.0510 - accuracy: 0.2486\n",
      "Epoch 95/100\n",
      "25000/25000 [==============================] - 13s 509us/step - loss: 2.0638 - accuracy: 0.2450\n",
      "Epoch 96/100\n",
      "25000/25000 [==============================] - 13s 508us/step - loss: 2.0283 - accuracy: 0.2639\n",
      "Epoch 97/100\n",
      "25000/25000 [==============================] - 13s 510us/step - loss: 2.0321 - accuracy: 0.2583\n",
      "Epoch 98/100\n",
      "25000/25000 [==============================] - 13s 509us/step - loss: 2.0214 - accuracy: 0.2623\n",
      "Epoch 99/100\n",
      "25000/25000 [==============================] - 13s 508us/step - loss: 2.0122 - accuracy: 0.2680\n",
      "Epoch 100/100\n",
      "25000/25000 [==============================] - 13s 507us/step - loss: 2.0016 - accuracy: 0.2728\n"
     ]
    }
   ],
   "source": [
    "# モデルの学習\n",
    "result = model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    batch_size=256,\n",
    "    epochs=100,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデル結果の出力\n",
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
