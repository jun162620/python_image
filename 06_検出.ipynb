{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 各種パラメータの設定方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import xml.etree.ElementTree as ET\n",
    "import matplotlib.pyplot as plt \n",
    "from random import shuffle\n",
    "from PIL import Image\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getBB(file):\n",
    "    \"\"\"バウンディングボックス(BB：領域を囲む四角形)の座標を取得する\n",
    "    引数：\n",
    "    　file：ファイル名\n",
    "    返り値：\n",
    "    処理概要：\n",
    "    \"\"\"\n",
    "    # xmlのファイル取得\n",
    "    path = f'data/pet/annotations/annotations/xmls/{file}'\n",
    "    # パースする\n",
    "    tree = ET.parse(path)\n",
    "    # 四隅の座標を取得する\n",
    "    root = tree.getroot()\n",
    "    ob = root.find('object')\n",
    "    bndbox = ob.find('bndbox')\n",
    "    xmin = bndbox.find('xmin').text\n",
    "    xmax = bndbox.find('xmax').text\n",
    "    ymin = bndbox.find('ymin').text\n",
    "    ymax = bndbox.find('ymax').text\n",
    "    four_corners = ((int(xmin), int(ymin)), (int(xmax), int(ymax)))\n",
    "    return four_corners\n",
    "\n",
    "def drawBB(file):\n",
    "    \"\"\"画像にバウンディングボックスを描画する\n",
    "    引数：\n",
    "    　file：\n",
    "    返り値：\n",
    "    処理概要：\n",
    "    　getBBで四隅の座標を取得して、選択した画像に描画し出力する\n",
    "    \"\"\"\n",
    "    # 画像を取得\n",
    "    img_path = f'data/pet/images/images/{file[:-4]}.jpg'\n",
    "    # 画像をオブジェクト化する\n",
    "    img = cv2.imread(img_path)\n",
    "    # 四隅の座標を取得する\n",
    "    (xmin, ymin), (xmax, ymax) = getBB(file)\n",
    "    cv2.rectangle(img, (xmin, ymin), (xmax, ymax), (0,255,0), 2)\n",
    "    plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = np.random.choice(os.listdir('data/pet/annotations/annotations/xmls/'))\n",
    "drawBB(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 画像のサイズをそろえる\n",
    "\n",
    "画像のサイズがバラバラなため、機械学習には使用できない。\n",
    "\n",
    "そのため、画像のサイズをすべてそろえるとともに、ニューラルネットでのバッチ処理の際に再利用するため、ジェネレータ関数として定義する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_generator(all_files, batch_size = 32, optional_size_xy = (256, 256)):\n",
    "    \"\"\"画像を任意の枚数と任意の大きさで出力する\n",
    "    引数：\n",
    "    　all_files：全ファイル名のリスト\n",
    "    　batch_size：バッチサイズ（取得したい画像の任意の枚数）\n",
    "    　optional_size：リサイズしたい画像の大きさ\n",
    "    返り値：\n",
    "    　ジェネレーター\n",
    "    処理概要：\n",
    "    　画像とバウンディングボックスの座標をジェネレータで生成する。\n",
    "    \"\"\"\n",
    "    while True:\n",
    "        # 任意のバッチサイズ分の画像を樹徳\n",
    "        files = np.random.choice(all_files, size = batch_size)    \n",
    "        # 学習データ\n",
    "        batch_x = [] # 画像データ\n",
    "        batch_y = [] # バウンディングボックスの座標\n",
    "        for file in files:\n",
    "            # 画像パス生成＆画像オブジェクト生成\n",
    "            img_path = f'data/pet/images/images/{file[:-4]}.jpg'\n",
    "            img = Image.open(img_path)\n",
    "            # 元の画像サイズを取得しておく\n",
    "            w,h = img.size\n",
    "            # 任意のサイズにリサイズ\n",
    "            img = img.resize(optional_size_xy)\n",
    "            # バウンディングボックスの四隅の座標を取得する\n",
    "            (xmin, ymin), (xmax, ymax) = getBB(file)\n",
    "            box = np.array([xmin/w, ymin/h, xmax/w, ymax/h])# ニューラルネットは入力ベクトルを0~1までに抑えなければならない(元々取得していた画像サイズで割る)\n",
    "            # 画像データのnumpy配列化\n",
    "            img = np.array(img).astype('float32')/255# ニューラルネットは入力ベクトルを0~1までに抑えなければならない(RGBの最高値で割る)\n",
    "            # 追加\n",
    "            batch_x.append(img)\n",
    "            batch_y.append(box)\n",
    "        # numpy配列に変換\n",
    "        batch_x = np.array(batch_x)\n",
    "        batch_y = np.array(batch_y)\n",
    "        # ジェネレータ化\n",
    "        yield (batch_x, batch_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ファイル一覧取得\n",
    "all_files = os.listdir('data/pet/annotations/annotations/xmls/')\n",
    "# ランダムに並べ替える（元々は名前順に並んでいるから）\n",
    "shuffle(all_files)\n",
    "# 訓練データとテストデータの分割数を指定する\n",
    "split = int(0.95 * len(all_files))\n",
    "# 訓練データとテストデータを分割する\n",
    "train_files = all_files[0:split]\n",
    "test_files  = all_files[split:]\n",
    "# 画像生成ジェネレータを作成\n",
    "batch_size = 32\n",
    "optional_size = 256\n",
    "train_generator = image_generator(train_files, batch_size = batch_size, optional_size_xy = (optional_size,optional_size))\n",
    "test_generator  = image_generator(test_files, batch_size =batch_size, optional_size_xy = (optional_size,optional_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 試しに出力\n",
    "x, y = next(train_generator)\n",
    "img = (x[0] * 255).astype('uint8') # 色を元に戻す\n",
    "box = [int(optional_size *i) for i in y[0]]\n",
    "cv2.rectangle(img, (box[0], box[1]), (box[2], box[3]), (0,255,0), 2)\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 評価関数の作成\n",
    "\n",
    "実際のバウンディングボックスの面積(A)と、予測されたバウンディングボックスの面積(B)のAに対する重なり具合を最小にすることを考える"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval(boxA, boxB):\n",
    "    \"\"\"バウンディングボックスの面積の重なり具合を求める。\n",
    "    引数：\n",
    "    　boxA：バウンディングボックスA（ここでは、元のBB）\n",
    "    　boxB：バウンディングボックスB（ここでは、予測したBB）\n",
    "    \"\"\"\n",
    "    xA = np.maximum(boxA[:, 0], boxB[:, 0])\n",
    "    yA = np.maximum(boxA[:, 1], boxB[:, 1])\n",
    "    xB = np.minimum(boxA[:, 2], boxB[:, 2])\n",
    "    yB = np.minimum(boxA[:, 3], boxB[:, 3])\n",
    "    interArea = np.maximum(0, xB - xA + 1) * np.maximum(0, yB - yA + 1)\n",
    "    boxAArea = (boxA[:, 2] - boxA[:, 0] + 1) * (boxA[:, 3] - boxA[:, 1] + 1)\n",
    "    boxBArea = (boxB[:, 2] - boxB[:, 0] + 1) * (boxB[:, 3] - boxB[:, 1] + 1)\n",
    "    unionArea = (boxAArea + boxBArea - interArea)\n",
    "    return tf.reduce_mean(np.mean(interArea / unionArea))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# モデル作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 各レイヤー定義\n",
    "layers = [\n",
    "    Conv2D(filters=32,kernel_size=(3, 3),activation='relu',input_shape=(256,256,3)),\n",
    "    MaxPooling2D(pool_size=(3, 3)),\n",
    "    Dropout(0.2),\n",
    "    Conv2D(filters=32,kernel_size=(3, 3),activation='relu'),\n",
    "    MaxPooling2D(pool_size=(3, 3)),\n",
    "    Dropout(0.2),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(4, activation='sigmoid')\n",
    "]\n",
    "\n",
    "# 基本モデル作成\n",
    "model = Sequential()\n",
    "\n",
    "# レイヤー追加\n",
    "for layer in layers:\n",
    "    model.add(layer)\n",
    "\n",
    "# モデルの学習設定\n",
    "model.compile(\n",
    "    loss=keras.losses.categorical_crossentropy,\n",
    "    optimizer=optimizers.Adam(lr=0.01),\n",
    "    metrics=['mean_squared_error']\n",
    ")\n",
    "\n",
    "train_steps = len(train_files) //batch_size\n",
    "test_steps = len(test_files) //batch_size\n",
    "model.fit_generator(\n",
    "    train_generator, \n",
    "    epochs = 30,\n",
    "    steps_per_epoch = train_steps\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://colab.research.google.com/github/zaidalyafeai/Notebooks/blob/master/Localizer.ipynb#scrollTo=R6YW5Fei2iWY"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
