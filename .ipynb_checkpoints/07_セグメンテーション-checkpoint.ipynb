{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# セグメンテーション\n",
    "\n",
    "画像の1ピクセルごとの領域が、どんな物体に関連する領域化をラベル付けする。\n",
    "\n",
    "手法としては、Semantic Segmentation（SegNet)と呼ばれるアルゴリズムを使用する。\n",
    "\n",
    "その他にも、U-netと呼ばれるアルゴリズムも存在する。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 実際にやってみる\n",
    "\n",
    "https://github.com/alexgkendall/SegNet-Tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from keras.applications import imagenet_utils\n",
    "\n",
    "class Dataset:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def normalized(self, rgb):\n",
    "        #return rgb/255.0\n",
    "        norm=np.zeros((rgb.shape[0], rgb.shape[1], 3),np.float32)\n",
    "\n",
    "        b=rgb[:,:,0]\n",
    "        g=rgb[:,:,1]\n",
    "        r=rgb[:,:,2]\n",
    "\n",
    "        norm[:,:,0]=cv2.equalizeHist(b)\n",
    "        norm[:,:,1]=cv2.equalizeHist(g)\n",
    "        norm[:,:,2]=cv2.equalizeHist(r)\n",
    "\n",
    "        return norm\n",
    "\n",
    "    def one_hot_it(self, labels):\n",
    "        x = np.zeros([360,480,12])\n",
    "        for i in range(360):\n",
    "            for j in range(480):\n",
    "                x[i,j,labels[i][j]] = 1\n",
    "        return x\n",
    "\n",
    "    def load_data(self, mode='train'):\n",
    "        # 画像データと正解ラベルの取得\n",
    "        data = []\n",
    "        label = []\n",
    "        \n",
    "        # 画像データのパスが記載されているファイルを読み込む\n",
    "        if mode=='train':\n",
    "            filelist_path=r'C:/Users/root/Desktop/work/b_python/python_image/data/SegNet-Tutorial/CamVid/train.txt'\n",
    "        elif mode=='test':\n",
    "            filelist_path=r'C:/Users/root/Desktop/work/b_python/python_image/data/SegNet-Tutorial/CamVid/test.txt'\n",
    "        else:\n",
    "            raise ValueError('mode is invalid')\n",
    "        with open(filelist_path) as f:\n",
    "            txt = f.readlines()\n",
    "            txt = [line.split(' ') for line in txt]\n",
    "        \n",
    "        # 取得したファイルパスのデータを読み込む\n",
    "        for i in range(len(txt)):\n",
    "            if mode=='train':\n",
    "                data.append(self.normalized(cv2.imread(filelist_path[:-17] + txt[i][0][7:])))\n",
    "                label.append(self.one_hot_it(cv2.imread(filelist_path[:-17] + txt[i][1][7:][:-1])[:,:,0]))\n",
    "            else:\n",
    "                data.append(self.normalized(cv2.imread(filelist_path[:-16] + txt[i][0][7:])))\n",
    "                label.append(self.one_hot_it(cv2.imread(filelist_path[:-16] + txt[i][1][7:][:-1])[:,:,0]))\n",
    "        return np.array(data), np.array(label)\n",
    "\n",
    "\n",
    "    def preprocess_inputs(self, X):\n",
    "        return imagenet_utils.preprocess_input(X)\n",
    "\n",
    "    def reshape_labels(self, y):\n",
    "        return np.reshape(y, (len(y),360*480, 12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input\n",
    "from keras.layers.core import Activation, Flatten, Reshape\n",
    "from keras.layers.convolutional import Convolution2D, Conv2D, MaxPooling2D, UpSampling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.models import Model\n",
    "from keras.utils import np_utils\n",
    "\n",
    "def SegNet(input_shape=(360, 480, 3), classes=12):\n",
    "    ### @ https://github.com/alexgkendall/SegNet-Tutorial/blob/master/Example_Models/bayesian_segnet_camvid.prototxt\n",
    "    img_input = Input(shape=input_shape)\n",
    "    x = img_input\n",
    "    # Encoder\n",
    "    x = Conv2D(64, (3, 3), padding=\"same\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "    x = Conv2D(128, (3, 3), padding=\"same\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "    x = Conv2D(256, (3, 3), padding=\"same\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "    x = Conv2D(512, (3, 3), padding=\"same\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "\n",
    "    # Decoder\n",
    "    x = Conv2D(512, (3, 3), padding=\"same\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "\n",
    "    x = UpSampling2D(size=(2, 2))(x)\n",
    "    x = Conv2D(256, (3, 3), padding=\"same\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "\n",
    "    x = UpSampling2D(size=(2, 2))(x)\n",
    "    x = Conv2D(128, (3, 3), padding=\"same\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "\n",
    "    x = UpSampling2D(size=(2, 2))(x)\n",
    "    x = Conv2D(64, (3, 3), padding=\"same\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "\n",
    "    x = Conv2D(classes, (1, 1), padding=\"valid\")(x)\n",
    "    x = Reshape((input_shape[0] * input_shape[1], classes))(x)\n",
    "    x = Activation(\"softmax\")(x)\n",
    "    model = Model(img_input, x)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import keras\n",
    "\n",
    "input_shape = (360, 480, 3)\n",
    "classes = 12\n",
    "epochs = 2\n",
    "batch_size = 32\n",
    "log_filepath='./logs/'\n",
    "\n",
    "data_shape = 360*480\n",
    "\n",
    "class_weighting = [0.2595, 0.1826, 4.5640, 0.1417, 0.5051, 0.3826, 9.6446, 1.8418, 6.6823, 6.2478, 3.0, 7.3614]\n",
    "\n",
    "## set gpu usage\n",
    "import tensorflow as tf\n",
    "config = tf.ConfigProto(gpu_options=tf.GPUOptions(allow_growth=True, per_process_gpu_memory_fraction = 0.8))\n",
    "session = tf.Session(config=config)\n",
    "keras.backend.tensorflow_backend.set_session(session)\n",
    "\n",
    "def main():\n",
    "    print(\"loading data...\")\n",
    "    ds = Dataset()\n",
    "    train_X, train_y = ds.load_data() # need to implement, y shape is (None, 360, 480, classes)\n",
    "\n",
    "    train_X = ds.preprocess_inputs(train_X)\n",
    "    train_Y = ds.reshape_labels(train_y)\n",
    "    print(\"input data shape...\", train_X.shape)\n",
    "    print(\"input label shape...\", train_Y.shape)\n",
    "\n",
    "    test_X, test_y = ds.load_data('test') # need to implement, y shape is (None, 360, 480, classes)\n",
    "    test_X = ds.preprocess_inputs(test_X)\n",
    "    test_Y = ds.reshape_labels(test_y)\n",
    "\n",
    "    tb_cb = keras.callbacks.TensorBoard(log_dir=log_filepath, histogram_freq=1, write_graph=True, write_images=True)\n",
    "    print(\"creating model...\")\n",
    "    model = SegNet(input_shape=input_shape, classes=classes)\n",
    "    model.compile(loss=\"categorical_crossentropy\", optimizer='adadelta', metrics=[\"accuracy\"])\n",
    "\n",
    "    model.fit(train_X, train_Y, batch_size=batch_size, epochs=epochs,\n",
    "              verbose=1, class_weight=class_weighting , validation_data=(test_X, test_Y), shuffle=True\n",
    "              , callbacks=[tb_cb])\n",
    "\n",
    "    model.save('seg.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data...\n",
      "input data shape... (367, 360, 480, 3)\n",
      "input label shape... (367, 172800, 12)\n",
      "creating model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0102 20:30:34.337881  9032 deprecation.py:237] From c:\\users\\root\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4139: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0102 20:30:39.384114  9032 deprecation.py:506] From c:\\users\\root\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\training\\moving_averages.py:211: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W0102 20:30:40.436094  9032 deprecation.py:237] From c:\\users\\root\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 367 samples, validate on 233 samples\n",
      "Epoch 1/2\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "from PIL import Image\n",
    "\n",
    "from model import SegNet\n",
    "\n",
    "import dataset\n",
    "\n",
    "height = 360\n",
    "width = 480\n",
    "classes = 12\n",
    "epochs = 100\n",
    "batch_size = 1\n",
    "log_filepath='./logs_100/'\n",
    "\n",
    "data_shape = 360*480\n",
    "\n",
    "def writeImage(image, filename):\n",
    "    \"\"\" label data to colored image \"\"\"\n",
    "    Sky = [128,128,128]\n",
    "    Building = [128,0,0]\n",
    "    Pole = [192,192,128]\n",
    "    Road_marking = [255,69,0]\n",
    "    Road = [128,64,128]\n",
    "    Pavement = [60,40,222]\n",
    "    Tree = [128,128,0]\n",
    "    SignSymbol = [192,128,128]\n",
    "    Fence = [64,64,128]\n",
    "    Car = [64,0,128]\n",
    "    Pedestrian = [64,64,0]\n",
    "    Bicyclist = [0,128,192]\n",
    "    Unlabelled = [0,0,0]\n",
    "    r = image.copy()\n",
    "    g = image.copy()\n",
    "    b = image.copy()\n",
    "    label_colours = np.array([Sky, Building, Pole, Road_marking, Road, Pavement, Tree, SignSymbol, Fence, Car, Pedestrian, Bicyclist, Unlabelled])\n",
    "    for l in range(0,12):\n",
    "        r[image==l] = label_colours[l,0]\n",
    "        g[image==l] = label_colours[l,1]\n",
    "        b[image==l] = label_colours[l,2]\n",
    "    rgb = np.zeros((image.shape[0], image.shape[1], 3))\n",
    "    rgb[:,:,0] = r/1.0\n",
    "    rgb[:,:,1] = g/1.0\n",
    "    rgb[:,:,2] = b/1.0\n",
    "    im = Image.fromarray(np.uint8(rgb))\n",
    "    im.save(filename)\n",
    "\n",
    "def predict(test):\n",
    "    model = keras.models.load_model('seg_100.h5')\n",
    "    probs = model.predict(test, batch_size=1)\n",
    "\n",
    "    prob = probs[0].reshape((height, width, classes)).argmax(axis=2)\n",
    "    return prob\n",
    "\n",
    "def main():\n",
    "    print(\"loading data...\")\n",
    "    ds = dataset.Dataset(test_file='val.txt', classes=classes)\n",
    "    test_X, test_y = ds.load_data('test') # need to implement, y shape is (None, 360, 480, classes)\n",
    "    test_X = ds.preprocess_inputs(test_X)\n",
    "    test_Y = ds.reshape_labels(test_y)\n",
    "\n",
    "    prob = predict(test_X)\n",
    "    writeImage(prob, 'val.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
