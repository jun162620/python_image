{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# keras\n",
    "\n",
    "Kerasは，Pythonで書かれた，TensorFlowまたはCNTK，Theano上で実行可能な高水準のニューラルネットワークライブラリです。\n",
    "\n",
    "### 特徴\n",
    "+ 容易に素早くプロトタイプの作成が可能（ユーザーフレンドリー，モジュール性，および拡張性による）\n",
    "+ CNNとRNNの両方，およびこれらの2つの組み合わせをサポート\n",
    "+ CPUとGPU上でシームレスな動作\n",
    "\n",
    "**公式引用：**https://keras.io/ja/\n",
    "\n",
    "## 下記で通常のディープラーニングを行ってみる"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# データ生成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 連続値データの読み込み\n",
    "from sklearn.datasets import load_boston\n",
    "boston = load_boston()\n",
    "\n",
    "# 訓練データとテストデータに分ける\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(boston['data'], boston['target'], test_size=0.3,  random_state=0)\n",
    "\n",
    "\"\"\"\n",
    "# 標準化（Standardization）\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train_s = scaler.fit_transform(X_train)\n",
    "X_test_s = scaler.transform(X_test) \n",
    "scaler = StandardScaler()\n",
    "y_train_s = scaler.fit_transform(y_train.reshape(len(y_train),1))\n",
    "y_test_s = scaler.transform(y_test.reshape(len(y_test),1)) \n",
    "\"\"\"\n",
    "\n",
    "# 正規化（Normarization）\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler_x = MinMaxScaler()\n",
    "X_train_n = scaler_x.fit_transform(X_train)\n",
    "X_test_n = scaler_x.transform(X_test) \n",
    "scaler_y = MinMaxScaler()\n",
    "y_train_n = scaler_y.fit_transform(y_train.reshape(len(y_train),1))\n",
    "y_test_n = scaler_y.transform(y_test.reshape(len(y_test),1)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 基本的なモデルの作成と学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# 基本モデル生成\n",
    "from keras.models import Sequential\n",
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 層の追加\n",
    "from keras.layers import Dense\n",
    "# 中間層\n",
    "model.add(\n",
    "    Dense(\n",
    "        128, \n",
    "        activation='relu' # 活性化関数\n",
    "    )\n",
    ")\n",
    "\n",
    "# 出力層\n",
    "model.add(\n",
    "    Dense(\n",
    "        1, \n",
    "        activation='linear' # 活性化関数\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデルの学習設定\n",
    "from keras import losses\n",
    "from keras import optimizers\n",
    "model.compile(\n",
    "    loss=losses.mean_squared_error,# 平均二乗誤差\n",
    "    optimizer=optimizers.SGD(lr=0.01),# 確率的勾配降下法\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "354/354 [==============================] - 0s 104us/step - loss: 0.2766\n",
      "Epoch 2/100\n",
      "354/354 [==============================] - 0s 25us/step - loss: 0.0778\n",
      "Epoch 3/100\n",
      "354/354 [==============================] - 0s 23us/step - loss: 0.0634\n",
      "Epoch 4/100\n",
      "354/354 [==============================] - 0s 23us/step - loss: 0.0564\n",
      "Epoch 5/100\n",
      "354/354 [==============================] - 0s 23us/step - loss: 0.0521\n",
      "Epoch 6/100\n",
      "354/354 [==============================] - 0s 23us/step - loss: 0.0482\n",
      "Epoch 7/100\n",
      "354/354 [==============================] - 0s 23us/step - loss: 0.0442\n",
      "Epoch 8/100\n",
      "354/354 [==============================] - 0s 23us/step - loss: 0.0417\n",
      "Epoch 9/100\n",
      "354/354 [==============================] - 0s 23us/step - loss: 0.0395\n",
      "Epoch 10/100\n",
      "354/354 [==============================] - 0s 23us/step - loss: 0.0373\n",
      "Epoch 11/100\n",
      "354/354 [==============================] - 0s 23us/step - loss: 0.0357\n",
      "Epoch 12/100\n",
      "354/354 [==============================] - 0s 20us/step - loss: 0.0345\n",
      "Epoch 13/100\n",
      "354/354 [==============================] - 0s 23us/step - loss: 0.0325\n",
      "Epoch 14/100\n",
      "354/354 [==============================] - 0s 20us/step - loss: 0.0313\n",
      "Epoch 15/100\n",
      "354/354 [==============================] - 0s 22us/step - loss: 0.0303\n",
      "Epoch 16/100\n",
      "354/354 [==============================] - 0s 23us/step - loss: 0.0292\n",
      "Epoch 17/100\n",
      "354/354 [==============================] - 0s 20us/step - loss: 0.0285\n",
      "Epoch 18/100\n",
      "354/354 [==============================] - 0s 23us/step - loss: 0.0275\n",
      "Epoch 19/100\n",
      "354/354 [==============================] - 0s 23us/step - loss: 0.0266\n",
      "Epoch 20/100\n",
      "354/354 [==============================] - 0s 23us/step - loss: 0.0259\n",
      "Epoch 21/100\n",
      "354/354 [==============================] - 0s 23us/step - loss: 0.0253\n",
      "Epoch 22/100\n",
      "354/354 [==============================] - 0s 25us/step - loss: 0.0246\n",
      "Epoch 23/100\n",
      "354/354 [==============================] - 0s 23us/step - loss: 0.0242\n",
      "Epoch 24/100\n",
      "354/354 [==============================] - 0s 23us/step - loss: 0.0231\n",
      "Epoch 25/100\n",
      "354/354 [==============================] - 0s 23us/step - loss: 0.0225\n",
      "Epoch 26/100\n",
      "354/354 [==============================] - 0s 25us/step - loss: 0.0220\n",
      "Epoch 27/100\n",
      "354/354 [==============================] - 0s 23us/step - loss: 0.0215\n",
      "Epoch 28/100\n",
      "354/354 [==============================] - 0s 20us/step - loss: 0.0210\n",
      "Epoch 29/100\n",
      "354/354 [==============================] - 0s 23us/step - loss: 0.0207\n",
      "Epoch 30/100\n",
      "354/354 [==============================] - 0s 20us/step - loss: 0.0203\n",
      "Epoch 31/100\n",
      "354/354 [==============================] - 0s 23us/step - loss: 0.0198\n",
      "Epoch 32/100\n",
      "354/354 [==============================] - 0s 20us/step - loss: 0.0195\n",
      "Epoch 33/100\n",
      "354/354 [==============================] - 0s 23us/step - loss: 0.0191\n",
      "Epoch 34/100\n",
      "354/354 [==============================] - 0s 23us/step - loss: 0.0186\n",
      "Epoch 35/100\n",
      "354/354 [==============================] - 0s 23us/step - loss: 0.0182\n",
      "Epoch 36/100\n",
      "354/354 [==============================] - 0s 23us/step - loss: 0.0178\n",
      "Epoch 37/100\n",
      "354/354 [==============================] - 0s 20us/step - loss: 0.0175\n",
      "Epoch 38/100\n",
      "354/354 [==============================] - 0s 23us/step - loss: 0.0174\n",
      "Epoch 39/100\n",
      "354/354 [==============================] - 0s 23us/step - loss: 0.0170\n",
      "Epoch 40/100\n",
      "354/354 [==============================] - 0s 20us/step - loss: 0.0167\n",
      "Epoch 41/100\n",
      "354/354 [==============================] - 0s 23us/step - loss: 0.0165\n",
      "Epoch 42/100\n",
      "354/354 [==============================] - 0s 25us/step - loss: 0.0162\n",
      "Epoch 43/100\n",
      "354/354 [==============================] - 0s 25us/step - loss: 0.0160\n",
      "Epoch 44/100\n",
      "354/354 [==============================] - 0s 22us/step - loss: 0.0157\n",
      "Epoch 45/100\n",
      "354/354 [==============================] - 0s 23us/step - loss: 0.0155\n",
      "Epoch 46/100\n",
      "354/354 [==============================] - 0s 23us/step - loss: 0.0153\n",
      "Epoch 47/100\n",
      "354/354 [==============================] - 0s 23us/step - loss: 0.0153\n",
      "Epoch 48/100\n",
      "354/354 [==============================] - 0s 23us/step - loss: 0.0150\n",
      "Epoch 49/100\n",
      "354/354 [==============================] - 0s 20us/step - loss: 0.0148\n",
      "Epoch 50/100\n",
      "354/354 [==============================] - 0s 23us/step - loss: 0.0146\n",
      "Epoch 51/100\n",
      "354/354 [==============================] - 0s 23us/step - loss: 0.0146\n",
      "Epoch 52/100\n",
      "354/354 [==============================] - 0s 23us/step - loss: 0.0143\n",
      "Epoch 53/100\n",
      "354/354 [==============================] - 0s 25us/step - loss: 0.0142\n",
      "Epoch 54/100\n",
      "354/354 [==============================] - 0s 23us/step - loss: 0.0140\n",
      "Epoch 55/100\n",
      "354/354 [==============================] - 0s 20us/step - loss: 0.0139\n",
      "Epoch 56/100\n",
      "354/354 [==============================] - 0s 20us/step - loss: 0.0138\n",
      "Epoch 57/100\n",
      "354/354 [==============================] - 0s 23us/step - loss: 0.0140\n",
      "Epoch 58/100\n",
      "354/354 [==============================] - 0s 20us/step - loss: 0.0135\n",
      "Epoch 59/100\n",
      "354/354 [==============================] - 0s 23us/step - loss: 0.0134\n",
      "Epoch 60/100\n",
      "354/354 [==============================] - 0s 23us/step - loss: 0.0132\n",
      "Epoch 61/100\n",
      "354/354 [==============================] - 0s 23us/step - loss: 0.0133\n",
      "Epoch 62/100\n",
      "354/354 [==============================] - 0s 23us/step - loss: 0.0130\n",
      "Epoch 63/100\n",
      "354/354 [==============================] - 0s 23us/step - loss: 0.0130\n",
      "Epoch 64/100\n",
      "354/354 [==============================] - 0s 20us/step - loss: 0.0128\n",
      "Epoch 65/100\n",
      "354/354 [==============================] - 0s 23us/step - loss: 0.0127\n",
      "Epoch 66/100\n",
      "354/354 [==============================] - 0s 20us/step - loss: 0.0127\n",
      "Epoch 67/100\n",
      "354/354 [==============================] - 0s 23us/step - loss: 0.0126\n",
      "Epoch 68/100\n",
      "354/354 [==============================] - 0s 23us/step - loss: 0.0125\n",
      "Epoch 69/100\n",
      "354/354 [==============================] - 0s 23us/step - loss: 0.0124\n",
      "Epoch 70/100\n",
      "354/354 [==============================] - 0s 20us/step - loss: 0.0123\n",
      "Epoch 71/100\n",
      "354/354 [==============================] - 0s 23us/step - loss: 0.0122\n",
      "Epoch 72/100\n",
      "354/354 [==============================] - 0s 20us/step - loss: 0.0122\n",
      "Epoch 73/100\n",
      "354/354 [==============================] - 0s 23us/step - loss: 0.0121\n",
      "Epoch 74/100\n",
      "354/354 [==============================] - 0s 23us/step - loss: 0.0120\n",
      "Epoch 75/100\n",
      "354/354 [==============================] - 0s 23us/step - loss: 0.0120\n",
      "Epoch 76/100\n",
      "354/354 [==============================] - 0s 23us/step - loss: 0.0119\n",
      "Epoch 77/100\n",
      "354/354 [==============================] - 0s 23us/step - loss: 0.0118\n",
      "Epoch 78/100\n",
      "354/354 [==============================] - 0s 23us/step - loss: 0.0118\n",
      "Epoch 79/100\n",
      "354/354 [==============================] - 0s 23us/step - loss: 0.0117\n",
      "Epoch 80/100\n",
      "354/354 [==============================] - 0s 23us/step - loss: 0.0116\n",
      "Epoch 81/100\n",
      "354/354 [==============================] - 0s 23us/step - loss: 0.0115\n",
      "Epoch 82/100\n",
      "354/354 [==============================] - 0s 20us/step - loss: 0.0115\n",
      "Epoch 83/100\n",
      "354/354 [==============================] - 0s 23us/step - loss: 0.0114\n",
      "Epoch 84/100\n",
      "354/354 [==============================] - 0s 23us/step - loss: 0.0114\n",
      "Epoch 85/100\n",
      "354/354 [==============================] - 0s 23us/step - loss: 0.0113\n",
      "Epoch 86/100\n",
      "354/354 [==============================] - 0s 23us/step - loss: 0.0113\n",
      "Epoch 87/100\n",
      "354/354 [==============================] - 0s 23us/step - loss: 0.0113\n",
      "Epoch 88/100\n",
      "354/354 [==============================] - 0s 20us/step - loss: 0.0112\n",
      "Epoch 89/100\n",
      "354/354 [==============================] - 0s 23us/step - loss: 0.0111\n",
      "Epoch 90/100\n",
      "354/354 [==============================] - 0s 23us/step - loss: 0.0111\n",
      "Epoch 91/100\n",
      "354/354 [==============================] - 0s 23us/step - loss: 0.0110\n",
      "Epoch 92/100\n",
      "354/354 [==============================] - 0s 20us/step - loss: 0.0110\n",
      "Epoch 93/100\n",
      "354/354 [==============================] - 0s 23us/step - loss: 0.0110\n",
      "Epoch 94/100\n",
      "354/354 [==============================] - 0s 20us/step - loss: 0.0109\n",
      "Epoch 95/100\n",
      "354/354 [==============================] - 0s 23us/step - loss: 0.0109\n",
      "Epoch 96/100\n",
      "354/354 [==============================] - 0s 20us/step - loss: 0.0108\n",
      "Epoch 97/100\n",
      "354/354 [==============================] - 0s 23us/step - loss: 0.0108\n",
      "Epoch 98/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "354/354 [==============================] - 0s 25us/step - loss: 0.0108\n",
      "Epoch 99/100\n",
      "354/354 [==============================] - 0s 23us/step - loss: 0.0107\n",
      "Epoch 100/100\n",
      "354/354 [==============================] - 0s 23us/step - loss: 0.0107\n"
     ]
    }
   ],
   "source": [
    "# モデルの学習\n",
    "result = model.fit(\n",
    "    X_train_n,\n",
    "    y_train_n,\n",
    "    epochs=100\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[26.540361 ]\n",
      " [20.355433 ]\n",
      " [30.096056 ]\n",
      " [14.087054 ]\n",
      " [21.490719 ]\n",
      " [19.571558 ]\n",
      " [20.75232  ]\n",
      " [21.439552 ]\n",
      " [18.002367 ]\n",
      " [15.617558 ]\n",
      " [ 9.521848 ]\n",
      " [12.79653  ]\n",
      " [16.104622 ]\n",
      " [ 8.508758 ]\n",
      " [38.507717 ]\n",
      " [33.565746 ]\n",
      " [21.690054 ]\n",
      " [38.74527  ]\n",
      " [30.340368 ]\n",
      " [22.396317 ]\n",
      " [24.02364  ]\n",
      " [23.674639 ]\n",
      " [19.993237 ]\n",
      " [28.54551  ]\n",
      " [22.527843 ]\n",
      " [ 8.707439 ]\n",
      " [18.798435 ]\n",
      " [18.230555 ]\n",
      " [34.640854 ]\n",
      " [21.080412 ]\n",
      " [16.799133 ]\n",
      " [18.421398 ]\n",
      " [21.68087  ]\n",
      " [25.203033 ]\n",
      " [28.216055 ]\n",
      " [20.174767 ]\n",
      " [12.733488 ]\n",
      " [24.611864 ]\n",
      " [13.956215 ]\n",
      " [13.302734 ]\n",
      " [26.727783 ]\n",
      " [21.74862  ]\n",
      " [24.515461 ]\n",
      " [14.246795 ]\n",
      " [26.794323 ]\n",
      " [25.546526 ]\n",
      " [22.175747 ]\n",
      " [25.764221 ]\n",
      " [14.415542 ]\n",
      " [23.523367 ]\n",
      " [21.917593 ]\n",
      " [18.56857  ]\n",
      " [23.610498 ]\n",
      " [31.790638 ]\n",
      " [12.736819 ]\n",
      " [24.179893 ]\n",
      " [23.740183 ]\n",
      " [18.775122 ]\n",
      " [13.403653 ]\n",
      " [24.077337 ]\n",
      " [22.09601  ]\n",
      " [22.127213 ]\n",
      " [32.678127 ]\n",
      " [29.98771  ]\n",
      " [18.956963 ]\n",
      " [32.90494  ]\n",
      " [17.495108 ]\n",
      " [23.105799 ]\n",
      " [15.683504 ]\n",
      " [22.323105 ]\n",
      " [21.981886 ]\n",
      " [22.885622 ]\n",
      " [30.238787 ]\n",
      " [29.769878 ]\n",
      " [24.216793 ]\n",
      " [ 8.343515 ]\n",
      " [35.679306 ]\n",
      " [23.391813 ]\n",
      " [26.691355 ]\n",
      " [19.495827 ]\n",
      " [28.97408  ]\n",
      " [18.517279 ]\n",
      " [16.783173 ]\n",
      " [36.264935 ]\n",
      " [37.94399  ]\n",
      " [23.470549 ]\n",
      " [24.550985 ]\n",
      " [12.806978 ]\n",
      " [25.855299 ]\n",
      " [16.40333  ]\n",
      " [17.72763  ]\n",
      " [12.636939 ]\n",
      " [27.61661  ]\n",
      " [33.673462 ]\n",
      " [21.188562 ]\n",
      " [22.283321 ]\n",
      " [ 3.45393  ]\n",
      " [27.840694 ]\n",
      " [13.882144 ]\n",
      " [19.508451 ]\n",
      " [24.087042 ]\n",
      " [21.866558 ]\n",
      " [33.076416 ]\n",
      " [21.025866 ]\n",
      " [28.530607 ]\n",
      " [25.404736 ]\n",
      " [ 7.324854 ]\n",
      " [14.045529 ]\n",
      " [21.240915 ]\n",
      " [29.031452 ]\n",
      " [30.882227 ]\n",
      " [11.03601  ]\n",
      " [23.149343 ]\n",
      " [19.766674 ]\n",
      " [16.801075 ]\n",
      " [24.94562  ]\n",
      " [ 6.2755113]\n",
      " [18.999374 ]\n",
      " [10.627116 ]\n",
      " [43.050014 ]\n",
      " [32.985905 ]\n",
      " [12.357766 ]\n",
      " [20.26395  ]\n",
      " [21.077684 ]\n",
      " [22.830753 ]\n",
      " [18.807545 ]\n",
      " [33.205143 ]\n",
      " [17.409983 ]\n",
      " [21.815308 ]\n",
      " [35.889004 ]\n",
      " [17.890831 ]\n",
      " [11.232899 ]\n",
      " [15.343123 ]\n",
      " [21.752623 ]\n",
      " [13.091415 ]\n",
      " [31.09092  ]\n",
      " [24.31639  ]\n",
      " [20.378273 ]\n",
      " [25.57077  ]\n",
      " [ 8.674294 ]\n",
      " [15.479297 ]\n",
      " [20.788746 ]\n",
      " [31.028782 ]\n",
      " [28.8353   ]\n",
      " [24.793041 ]\n",
      " [17.413046 ]\n",
      " [31.631567 ]\n",
      " [28.308405 ]\n",
      " [12.113599 ]\n",
      " [ 9.237983 ]\n",
      " [27.176737 ]\n",
      " [25.517895 ]]\n"
     ]
    }
   ],
   "source": [
    "# 予測値の算出\n",
    "y_predict_n = model.predict(X_test_n)\n",
    "y_predict = scaler_y.inverse_transform(y_predict_n)\n",
    "print(y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.17926697693184898"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 乖離度の算出\n",
    "import numpy as np\n",
    "np.mean(\n",
    "    np.abs(y_test-y_predict.flatten())\n",
    "    /y_test\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 層を増やしたモデル\n",
    "\n",
    "ディープラーニングといわれるように、一般的に中間層を増やすと、精度が向上することがわかっている"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 基本モデル生成\n",
    "from keras.models import Sequential\n",
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 層の追加\n",
    "from keras.layers import Dense\n",
    "# 中間層\n",
    "model.add(\n",
    "    Dense(\n",
    "        128, \n",
    "        activation='relu'\n",
    "    )\n",
    ")\n",
    "model.add(\n",
    "    Dense(\n",
    "        128, \n",
    "        activation='relu'\n",
    "    )\n",
    ")\n",
    "model.add(\n",
    "    Dense(\n",
    "        128, \n",
    "        activation='relu'\n",
    "    )\n",
    ")\n",
    "# 出力層\n",
    "model.add(\n",
    "    Dense(\n",
    "        1, \n",
    "        activation='linear'\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデルの学習設定\n",
    "from keras import losses\n",
    "from keras import optimizers\n",
    "model.compile(\n",
    "    loss=losses.mean_squared_error,\n",
    "    optimizer=optimizers.SGD(lr=0.01),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "354/354 [==============================] - 0s 133us/step - loss: 0.1304\n",
      "Epoch 2/300\n",
      "354/354 [==============================] - 0s 31us/step - loss: 0.0492\n",
      "Epoch 3/300\n",
      "354/354 [==============================] - 0s 31us/step - loss: 0.0402\n",
      "Epoch 4/300\n",
      "354/354 [==============================] - 0s 31us/step - loss: 0.0364\n",
      "Epoch 5/300\n",
      "354/354 [==============================] - 0s 28us/step - loss: 0.0340\n",
      "Epoch 6/300\n",
      "354/354 [==============================] - 0s 31us/step - loss: 0.0321\n",
      "Epoch 7/300\n",
      "354/354 [==============================] - 0s 28us/step - loss: 0.0302\n",
      "Epoch 8/300\n",
      "354/354 [==============================] - 0s 28us/step - loss: 0.0290\n",
      "Epoch 9/300\n",
      "354/354 [==============================] - 0s 28us/step - loss: 0.0279\n",
      "Epoch 10/300\n",
      "354/354 [==============================] - 0s 28us/step - loss: 0.0271\n",
      "Epoch 11/300\n",
      "354/354 [==============================] - 0s 25us/step - loss: 0.0262\n",
      "Epoch 12/300\n",
      "354/354 [==============================] - 0s 28us/step - loss: 0.0255\n",
      "Epoch 13/300\n",
      "354/354 [==============================] - 0s 25us/step - loss: 0.0250\n",
      "Epoch 14/300\n",
      "354/354 [==============================] - 0s 28us/step - loss: 0.0243\n",
      "Epoch 15/300\n",
      "354/354 [==============================] - 0s 28us/step - loss: 0.0236\n",
      "Epoch 16/300\n",
      "354/354 [==============================] - 0s 28us/step - loss: 0.0230\n",
      "Epoch 17/300\n",
      "354/354 [==============================] - 0s 28us/step - loss: 0.0224\n",
      "Epoch 18/300\n",
      "354/354 [==============================] - 0s 26us/step - loss: 0.0219\n",
      "Epoch 19/300\n",
      "354/354 [==============================] - 0s 28us/step - loss: 0.0215\n",
      "Epoch 20/300\n",
      "354/354 [==============================] - 0s 28us/step - loss: 0.0210\n",
      "Epoch 21/300\n",
      "354/354 [==============================] - 0s 28us/step - loss: 0.0207\n",
      "Epoch 22/300\n",
      "354/354 [==============================] - 0s 28us/step - loss: 0.0202\n",
      "Epoch 23/300\n",
      "354/354 [==============================] - 0s 28us/step - loss: 0.0200\n",
      "Epoch 24/300\n",
      "354/354 [==============================] - 0s 28us/step - loss: 0.0194\n",
      "Epoch 25/300\n",
      "354/354 [==============================] - 0s 28us/step - loss: 0.0192\n",
      "Epoch 26/300\n",
      "354/354 [==============================] - 0s 28us/step - loss: 0.0187\n",
      "Epoch 27/300\n",
      "354/354 [==============================] - 0s 28us/step - loss: 0.0184\n",
      "Epoch 28/300\n",
      "354/354 [==============================] - 0s 28us/step - loss: 0.0181\n",
      "Epoch 29/300\n",
      "354/354 [==============================] - 0s 28us/step - loss: 0.0179\n",
      "Epoch 30/300\n",
      "354/354 [==============================] - 0s 28us/step - loss: 0.0178\n",
      "Epoch 31/300\n",
      "354/354 [==============================] - 0s 31us/step - loss: 0.0172\n",
      "Epoch 32/300\n",
      "354/354 [==============================] - 0s 28us/step - loss: 0.0170\n",
      "Epoch 33/300\n",
      "354/354 [==============================] - 0s 28us/step - loss: 0.0167\n",
      "Epoch 34/300\n",
      "354/354 [==============================] - 0s 25us/step - loss: 0.0166\n",
      "Epoch 35/300\n",
      "354/354 [==============================] - 0s 34us/step - loss: 0.0163\n",
      "Epoch 36/300\n",
      "354/354 [==============================] - 0s 31us/step - loss: 0.0160\n",
      "Epoch 37/300\n",
      "354/354 [==============================] - 0s 28us/step - loss: 0.0158\n",
      "Epoch 38/300\n",
      "354/354 [==============================] - 0s 28us/step - loss: 0.0156\n",
      "Epoch 39/300\n",
      "354/354 [==============================] - 0s 31us/step - loss: 0.0154\n",
      "Epoch 40/300\n",
      "354/354 [==============================] - 0s 28us/step - loss: 0.0153\n",
      "Epoch 41/300\n",
      "354/354 [==============================] - 0s 25us/step - loss: 0.0155\n",
      "Epoch 42/300\n",
      "354/354 [==============================] - 0s 31us/step - loss: 0.0148\n",
      "Epoch 43/300\n",
      "354/354 [==============================] - ETA: 0s - loss: 0.006 - 0s 31us/step - loss: 0.0147\n",
      "Epoch 44/300\n",
      "354/354 [==============================] - 0s 25us/step - loss: 0.0144\n",
      "Epoch 45/300\n",
      "354/354 [==============================] - 0s 28us/step - loss: 0.0144\n",
      "Epoch 46/300\n",
      "354/354 [==============================] - 0s 25us/step - loss: 0.0143\n",
      "Epoch 47/300\n",
      "354/354 [==============================] - 0s 25us/step - loss: 0.0139\n",
      "Epoch 48/300\n",
      "354/354 [==============================] - 0s 28us/step - loss: 0.0139\n",
      "Epoch 49/300\n",
      "354/354 [==============================] - 0s 25us/step - loss: 0.0140\n",
      "Epoch 50/300\n",
      "354/354 [==============================] - 0s 28us/step - loss: 0.0134\n",
      "Epoch 51/300\n",
      "354/354 [==============================] - 0s 28us/step - loss: 0.0132\n",
      "Epoch 52/300\n",
      "354/354 [==============================] - 0s 28us/step - loss: 0.0132\n",
      "Epoch 53/300\n",
      "354/354 [==============================] - 0s 25us/step - loss: 0.0131\n",
      "Epoch 54/300\n",
      "354/354 [==============================] - 0s 25us/step - loss: 0.0128\n",
      "Epoch 55/300\n",
      "354/354 [==============================] - 0s 28us/step - loss: 0.0127\n",
      "Epoch 56/300\n",
      "354/354 [==============================] - 0s 25us/step - loss: 0.0125\n",
      "Epoch 57/300\n",
      "354/354 [==============================] - 0s 28us/step - loss: 0.0124\n",
      "Epoch 58/300\n",
      "354/354 [==============================] - 0s 28us/step - loss: 0.0123\n",
      "Epoch 59/300\n",
      "354/354 [==============================] - 0s 28us/step - loss: 0.0123\n",
      "Epoch 60/300\n",
      "354/354 [==============================] - 0s 31us/step - loss: 0.0121\n",
      "Epoch 61/300\n",
      "354/354 [==============================] - 0s 28us/step - loss: 0.0121\n",
      "Epoch 62/300\n",
      "354/354 [==============================] - 0s 31us/step - loss: 0.0119\n",
      "Epoch 63/300\n",
      "354/354 [==============================] - 0s 28us/step - loss: 0.0118\n",
      "Epoch 64/300\n",
      "354/354 [==============================] - 0s 31us/step - loss: 0.0117\n",
      "Epoch 65/300\n",
      "354/354 [==============================] - 0s 25us/step - loss: 0.0115\n",
      "Epoch 66/300\n",
      "354/354 [==============================] - 0s 26us/step - loss: 0.0115\n",
      "Epoch 67/300\n",
      "354/354 [==============================] - 0s 25us/step - loss: 0.0113\n",
      "Epoch 68/300\n",
      "354/354 [==============================] - 0s 28us/step - loss: 0.0112\n",
      "Epoch 69/300\n",
      "354/354 [==============================] - 0s 28us/step - loss: 0.0112\n",
      "Epoch 70/300\n",
      "354/354 [==============================] - 0s 25us/step - loss: 0.0111\n",
      "Epoch 71/300\n",
      "354/354 [==============================] - 0s 26us/step - loss: 0.0110\n",
      "Epoch 72/300\n",
      "354/354 [==============================] - 0s 28us/step - loss: 0.0110\n",
      "Epoch 73/300\n",
      "354/354 [==============================] - 0s 28us/step - loss: 0.0108\n",
      "Epoch 74/300\n",
      "354/354 [==============================] - ETA: 0s - loss: 0.011 - 0s 28us/step - loss: 0.0107\n",
      "Epoch 75/300\n",
      "354/354 [==============================] - 0s 28us/step - loss: 0.0107\n",
      "Epoch 76/300\n",
      "354/354 [==============================] - 0s 28us/step - loss: 0.0105\n",
      "Epoch 77/300\n",
      "354/354 [==============================] - 0s 28us/step - loss: 0.0106\n",
      "Epoch 78/300\n",
      "354/354 [==============================] - 0s 25us/step - loss: 0.0104\n",
      "Epoch 79/300\n",
      "354/354 [==============================] - 0s 28us/step - loss: 0.0104\n",
      "Epoch 80/300\n",
      "354/354 [==============================] - 0s 28us/step - loss: 0.0103\n",
      "Epoch 81/300\n",
      "354/354 [==============================] - 0s 28us/step - loss: 0.0102\n",
      "Epoch 82/300\n",
      "354/354 [==============================] - 0s 28us/step - loss: 0.0102\n",
      "Epoch 83/300\n",
      "354/354 [==============================] - 0s 25us/step - loss: 0.0101\n",
      "Epoch 84/300\n",
      "354/354 [==============================] - 0s 25us/step - loss: 0.0100\n",
      "Epoch 85/300\n",
      "354/354 [==============================] - 0s 28us/step - loss: 0.0099\n",
      "Epoch 86/300\n",
      "354/354 [==============================] - 0s 25us/step - loss: 0.0098\n",
      "Epoch 87/300\n",
      "354/354 [==============================] - 0s 28us/step - loss: 0.0098\n",
      "Epoch 88/300\n",
      "354/354 [==============================] - 0s 25us/step - loss: 0.0098\n",
      "Epoch 89/300\n",
      "354/354 [==============================] - 0s 28us/step - loss: 0.0097\n",
      "Epoch 90/300\n",
      "354/354 [==============================] - 0s 28us/step - loss: 0.0096\n",
      "Epoch 91/300\n",
      "354/354 [==============================] - 0s 28us/step - loss: 0.0096\n",
      "Epoch 92/300\n",
      "354/354 [==============================] - 0s 25us/step - loss: 0.0095\n",
      "Epoch 93/300\n",
      "354/354 [==============================] - 0s 28us/step - loss: 0.0098\n",
      "Epoch 94/300\n",
      "354/354 [==============================] - 0s 28us/step - loss: 0.0093\n",
      "Epoch 95/300\n",
      "354/354 [==============================] - 0s 26us/step - loss: 0.0093\n",
      "Epoch 96/300\n",
      "354/354 [==============================] - 0s 25us/step - loss: 0.0093\n",
      "Epoch 97/300\n",
      "354/354 [==============================] - 0s 28us/step - loss: 0.0092\n",
      "Epoch 98/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "354/354 [==============================] - 0s 28us/step - loss: 0.0092\n",
      "Epoch 99/300\n",
      "354/354 [==============================] - 0s 28us/step - loss: 0.0091\n",
      "Epoch 100/300\n",
      "354/354 [==============================] - 0s 26us/step - loss: 0.0090\n",
      "Epoch 101/300\n",
      "354/354 [==============================] - 0s 25us/step - loss: 0.0090\n",
      "Epoch 102/300\n",
      "354/354 [==============================] - 0s 28us/step - loss: 0.0090\n",
      "Epoch 103/300\n",
      "354/354 [==============================] - 0s 28us/step - loss: 0.0090\n",
      "Epoch 104/300\n",
      "354/354 [==============================] - 0s 28us/step - loss: 0.0090\n",
      "Epoch 105/300\n",
      "354/354 [==============================] - 0s 25us/step - loss: 0.0088\n",
      "Epoch 106/300\n",
      "354/354 [==============================] - 0s 25us/step - loss: 0.0089\n",
      "Epoch 107/300\n",
      "354/354 [==============================] - 0s 28us/step - loss: 0.0088\n",
      "Epoch 108/300\n",
      "354/354 [==============================] - 0s 25us/step - loss: 0.0087\n",
      "Epoch 109/300\n",
      "354/354 [==============================] - 0s 28us/step - loss: 0.0091\n",
      "Epoch 110/300\n",
      "354/354 [==============================] - 0s 25us/step - loss: 0.0086\n",
      "Epoch 111/300\n",
      "354/354 [==============================] - 0s 28us/step - loss: 0.0085\n",
      "Epoch 112/300\n",
      "354/354 [==============================] - 0s 28us/step - loss: 0.0085\n",
      "Epoch 113/300\n",
      "354/354 [==============================] - 0s 28us/step - loss: 0.0085\n",
      "Epoch 114/300\n",
      "354/354 [==============================] - 0s 26us/step - loss: 0.0084\n",
      "Epoch 115/300\n",
      "354/354 [==============================] - 0s 28us/step - loss: 0.0084\n",
      "Epoch 116/300\n",
      "354/354 [==============================] - 0s 28us/step - loss: 0.0083\n",
      "Epoch 117/300\n",
      "354/354 [==============================] - 0s 28us/step - loss: 0.0084\n",
      "Epoch 118/300\n",
      "354/354 [==============================] - 0s 28us/step - loss: 0.0083\n",
      "Epoch 119/300\n",
      "354/354 [==============================] - 0s 28us/step - loss: 0.0082\n",
      "Epoch 120/300\n",
      "354/354 [==============================] - 0s 31us/step - loss: 0.0082\n",
      "Epoch 121/300\n",
      "354/354 [==============================] - 0s 28us/step - loss: 0.0082\n",
      "Epoch 122/300\n",
      "354/354 [==============================] - 0s 28us/step - loss: 0.0082\n",
      "Epoch 123/300\n",
      "354/354 [==============================] - 0s 31us/step - loss: 0.0081\n",
      "Epoch 124/300\n",
      "354/354 [==============================] - 0s 28us/step - loss: 0.0081\n",
      "Epoch 125/300\n",
      "354/354 [==============================] - 0s 28us/step - loss: 0.0081\n",
      "Epoch 126/300\n",
      "354/354 [==============================] - 0s 28us/step - loss: 0.0080\n",
      "Epoch 127/300\n",
      "354/354 [==============================] - 0s 28us/step - loss: 0.0081\n",
      "Epoch 128/300\n",
      "354/354 [==============================] - 0s 28us/step - loss: 0.0080\n",
      "Epoch 129/300\n",
      "354/354 [==============================] - 0s 28us/step - loss: 0.0080\n",
      "Epoch 130/300\n",
      "354/354 [==============================] - 0s 28us/step - loss: 0.0080\n",
      "Epoch 131/300\n",
      "354/354 [==============================] - 0s 31us/step - loss: 0.0080\n",
      "Epoch 132/300\n",
      "354/354 [==============================] - 0s 31us/step - loss: 0.0079\n",
      "Epoch 133/300\n",
      "354/354 [==============================] - 0s 28us/step - loss: 0.0079\n",
      "Epoch 134/300\n",
      "354/354 [==============================] - 0s 25us/step - loss: 0.0078\n",
      "Epoch 135/300\n",
      "354/354 [==============================] - 0s 28us/step - loss: 0.0078\n",
      "Epoch 136/300\n",
      "354/354 [==============================] - 0s 26us/step - loss: 0.0078\n",
      "Epoch 137/300\n",
      "354/354 [==============================] - 0s 28us/step - loss: 0.0078\n",
      "Epoch 138/300\n",
      "354/354 [==============================] - 0s 28us/step - loss: 0.0078\n",
      "Epoch 139/300\n",
      "354/354 [==============================] - 0s 28us/step - loss: 0.0077\n",
      "Epoch 140/300\n",
      "354/354 [==============================] - 0s 28us/step - loss: 0.0077\n",
      "Epoch 141/300\n",
      "354/354 [==============================] - 0s 34us/step - loss: 0.0076\n",
      "Epoch 142/300\n",
      "354/354 [==============================] - 0s 31us/step - loss: 0.0076\n",
      "Epoch 143/300\n",
      "354/354 [==============================] - 0s 28us/step - loss: 0.0076\n",
      "Epoch 144/300\n",
      "354/354 [==============================] - 0s 25us/step - loss: 0.0076\n",
      "Epoch 145/300\n",
      "354/354 [==============================] - 0s 28us/step - loss: 0.0076\n",
      "Epoch 146/300\n",
      "354/354 [==============================] - 0s 28us/step - loss: 0.0077\n",
      "Epoch 147/300\n",
      "354/354 [==============================] - 0s 28us/step - loss: 0.0075\n",
      "Epoch 148/300\n",
      "354/354 [==============================] - 0s 28us/step - loss: 0.0075\n",
      "Epoch 149/300\n",
      "354/354 [==============================] - 0s 28us/step - loss: 0.0075\n",
      "Epoch 150/300\n",
      "354/354 [==============================] - 0s 28us/step - loss: 0.0074\n",
      "Epoch 151/300\n",
      "354/354 [==============================] - 0s 25us/step - loss: 0.0074\n",
      "Epoch 152/300\n",
      "354/354 [==============================] - 0s 25us/step - loss: 0.0079\n",
      "Epoch 153/300\n",
      "354/354 [==============================] - 0s 28us/step - loss: 0.0079\n",
      "Epoch 154/300\n",
      "354/354 [==============================] - 0s 28us/step - loss: 0.0074\n",
      "Epoch 155/300\n",
      "354/354 [==============================] - 0s 25us/step - loss: 0.0074\n",
      "Epoch 156/300\n",
      "354/354 [==============================] - 0s 25us/step - loss: 0.0074\n",
      "Epoch 157/300\n",
      "354/354 [==============================] - 0s 28us/step - loss: 0.0073\n",
      "Epoch 158/300\n",
      "354/354 [==============================] - 0s 31us/step - loss: 0.0073\n",
      "Epoch 159/300\n",
      "354/354 [==============================] - 0s 28us/step - loss: 0.0072\n",
      "Epoch 160/300\n",
      "354/354 [==============================] - 0s 28us/step - loss: 0.0073\n",
      "Epoch 161/300\n",
      "354/354 [==============================] - 0s 28us/step - loss: 0.0072\n",
      "Epoch 162/300\n",
      "354/354 [==============================] - 0s 25us/step - loss: 0.0072\n",
      "Epoch 163/300\n",
      "354/354 [==============================] - 0s 28us/step - loss: 0.0072\n",
      "Epoch 164/300\n",
      "354/354 [==============================] - 0s 28us/step - loss: 0.0071\n",
      "Epoch 165/300\n",
      "354/354 [==============================] - 0s 26us/step - loss: 0.0072\n",
      "Epoch 166/300\n",
      "354/354 [==============================] - 0s 25us/step - loss: 0.0071\n",
      "Epoch 167/300\n",
      "354/354 [==============================] - 0s 28us/step - loss: 0.0072\n",
      "Epoch 168/300\n",
      "354/354 [==============================] - 0s 28us/step - loss: 0.0071\n",
      "Epoch 169/300\n",
      "354/354 [==============================] - 0s 28us/step - loss: 0.0071\n",
      "Epoch 170/300\n",
      "354/354 [==============================] - 0s 28us/step - loss: 0.0070\n",
      "Epoch 171/300\n",
      "354/354 [==============================] - 0s 28us/step - loss: 0.0070\n",
      "Epoch 172/300\n",
      "354/354 [==============================] - 0s 28us/step - loss: 0.0070\n",
      "Epoch 173/300\n",
      "354/354 [==============================] - 0s 28us/step - loss: 0.0070\n",
      "Epoch 174/300\n",
      "354/354 [==============================] - 0s 28us/step - loss: 0.0069\n",
      "Epoch 175/300\n",
      "354/354 [==============================] - 0s 25us/step - loss: 0.0069\n",
      "Epoch 176/300\n",
      "354/354 [==============================] - 0s 28us/step - loss: 0.0069\n",
      "Epoch 177/300\n",
      "354/354 [==============================] - 0s 28us/step - loss: 0.0069\n",
      "Epoch 178/300\n",
      "354/354 [==============================] - 0s 28us/step - loss: 0.0070\n",
      "Epoch 179/300\n",
      "354/354 [==============================] - 0s 28us/step - loss: 0.0070\n",
      "Epoch 180/300\n",
      "354/354 [==============================] - 0s 28us/step - loss: 0.0069\n",
      "Epoch 181/300\n",
      "354/354 [==============================] - 0s 25us/step - loss: 0.0068\n",
      "Epoch 182/300\n",
      "354/354 [==============================] - 0s 25us/step - loss: 0.0069\n",
      "Epoch 183/300\n",
      "354/354 [==============================] - 0s 25us/step - loss: 0.0068\n",
      "Epoch 184/300\n",
      "354/354 [==============================] - 0s 28us/step - loss: 0.0068\n",
      "Epoch 185/300\n",
      "354/354 [==============================] - 0s 25us/step - loss: 0.0068\n",
      "Epoch 186/300\n",
      "354/354 [==============================] - 0s 26us/step - loss: 0.0068\n",
      "Epoch 187/300\n",
      "354/354 [==============================] - 0s 28us/step - loss: 0.0068\n",
      "Epoch 188/300\n",
      "354/354 [==============================] - 0s 25us/step - loss: 0.0068\n",
      "Epoch 189/300\n",
      "354/354 [==============================] - 0s 28us/step - loss: 0.0067\n",
      "Epoch 190/300\n",
      "354/354 [==============================] - 0s 28us/step - loss: 0.0068\n",
      "Epoch 191/300\n",
      "354/354 [==============================] - 0s 25us/step - loss: 0.0067\n",
      "Epoch 192/300\n",
      "354/354 [==============================] - 0s 25us/step - loss: 0.0067\n",
      "Epoch 193/300\n",
      "354/354 [==============================] - 0s 31us/step - loss: 0.0066\n",
      "Epoch 194/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "354/354 [==============================] - 0s 28us/step - loss: 0.0066\n",
      "Epoch 195/300\n",
      "354/354 [==============================] - 0s 28us/step - loss: 0.0066\n",
      "Epoch 196/300\n",
      "354/354 [==============================] - 0s 28us/step - loss: 0.0066\n",
      "Epoch 197/300\n",
      "354/354 [==============================] - 0s 25us/step - loss: 0.0066\n",
      "Epoch 198/300\n",
      "354/354 [==============================] - 0s 25us/step - loss: 0.0067\n",
      "Epoch 199/300\n",
      "354/354 [==============================] - 0s 28us/step - loss: 0.0065\n",
      "Epoch 200/300\n",
      "354/354 [==============================] - 0s 28us/step - loss: 0.0065\n",
      "Epoch 201/300\n",
      "354/354 [==============================] - 0s 28us/step - loss: 0.0066\n",
      "Epoch 202/300\n",
      "354/354 [==============================] - 0s 31us/step - loss: 0.0065\n",
      "Epoch 203/300\n",
      "354/354 [==============================] - 0s 28us/step - loss: 0.0065\n",
      "Epoch 204/300\n",
      "354/354 [==============================] - ETA: 0s - loss: 0.005 - 0s 31us/step - loss: 0.0065\n",
      "Epoch 205/300\n",
      "354/354 [==============================] - 0s 31us/step - loss: 0.0065\n",
      "Epoch 206/300\n",
      "354/354 [==============================] - 0s 25us/step - loss: 0.0065\n",
      "Epoch 207/300\n",
      "354/354 [==============================] - 0s 31us/step - loss: 0.0065\n",
      "Epoch 208/300\n",
      "354/354 [==============================] - 0s 34us/step - loss: 0.0064\n",
      "Epoch 209/300\n",
      "354/354 [==============================] - 0s 28us/step - loss: 0.0064\n",
      "Epoch 210/300\n",
      "354/354 [==============================] - 0s 31us/step - loss: 0.0064\n",
      "Epoch 211/300\n",
      "354/354 [==============================] - 0s 31us/step - loss: 0.0064\n",
      "Epoch 212/300\n",
      "354/354 [==============================] - 0s 28us/step - loss: 0.0064\n",
      "Epoch 213/300\n",
      "354/354 [==============================] - 0s 31us/step - loss: 0.0064\n",
      "Epoch 214/300\n",
      "354/354 [==============================] - 0s 28us/step - loss: 0.0063\n",
      "Epoch 215/300\n",
      "354/354 [==============================] - 0s 31us/step - loss: 0.0064\n",
      "Epoch 216/300\n",
      "354/354 [==============================] - 0s 28us/step - loss: 0.0065\n",
      "Epoch 217/300\n",
      "354/354 [==============================] - 0s 31us/step - loss: 0.0064\n",
      "Epoch 218/300\n",
      "354/354 [==============================] - 0s 28us/step - loss: 0.0068\n",
      "Epoch 219/300\n",
      "354/354 [==============================] - 0s 28us/step - loss: 0.0064\n",
      "Epoch 220/300\n",
      "354/354 [==============================] - 0s 31us/step - loss: 0.0063\n",
      "Epoch 221/300\n",
      "354/354 [==============================] - 0s 28us/step - loss: 0.0063\n",
      "Epoch 222/300\n",
      "354/354 [==============================] - 0s 25us/step - loss: 0.0063\n",
      "Epoch 223/300\n",
      "354/354 [==============================] - 0s 25us/step - loss: 0.0062\n",
      "Epoch 224/300\n",
      "354/354 [==============================] - 0s 25us/step - loss: 0.0062\n",
      "Epoch 225/300\n",
      "354/354 [==============================] - 0s 25us/step - loss: 0.0062\n",
      "Epoch 226/300\n",
      "354/354 [==============================] - 0s 28us/step - loss: 0.0062\n",
      "Epoch 227/300\n",
      "354/354 [==============================] - 0s 28us/step - loss: 0.0062\n",
      "Epoch 228/300\n",
      "354/354 [==============================] - 0s 28us/step - loss: 0.0062\n",
      "Epoch 229/300\n",
      "354/354 [==============================] - 0s 28us/step - loss: 0.0061\n",
      "Epoch 230/300\n",
      "354/354 [==============================] - 0s 28us/step - loss: 0.0062\n",
      "Epoch 231/300\n",
      "354/354 [==============================] - 0s 28us/step - loss: 0.0062\n",
      "Epoch 232/300\n",
      "354/354 [==============================] - 0s 28us/step - loss: 0.0062\n",
      "Epoch 233/300\n",
      "354/354 [==============================] - 0s 28us/step - loss: 0.0061\n",
      "Epoch 234/300\n",
      "354/354 [==============================] - 0s 25us/step - loss: 0.0061\n",
      "Epoch 235/300\n",
      "354/354 [==============================] - 0s 28us/step - loss: 0.0061\n",
      "Epoch 236/300\n",
      "354/354 [==============================] - 0s 31us/step - loss: 0.0061\n",
      "Epoch 237/300\n",
      "354/354 [==============================] - 0s 28us/step - loss: 0.0061\n",
      "Epoch 238/300\n",
      "354/354 [==============================] - 0s 28us/step - loss: 0.0061\n",
      "Epoch 239/300\n",
      "354/354 [==============================] - 0s 25us/step - loss: 0.0063\n",
      "Epoch 240/300\n",
      "354/354 [==============================] - 0s 28us/step - loss: 0.0061\n",
      "Epoch 241/300\n",
      "354/354 [==============================] - 0s 28us/step - loss: 0.0060\n",
      "Epoch 242/300\n",
      "354/354 [==============================] - 0s 25us/step - loss: 0.0060\n",
      "Epoch 243/300\n",
      "354/354 [==============================] - 0s 28us/step - loss: 0.0060\n",
      "Epoch 244/300\n",
      "354/354 [==============================] - 0s 28us/step - loss: 0.0061\n",
      "Epoch 245/300\n",
      "354/354 [==============================] - 0s 25us/step - loss: 0.0067\n",
      "Epoch 246/300\n",
      "354/354 [==============================] - 0s 28us/step - loss: 0.0060\n",
      "Epoch 247/300\n",
      "354/354 [==============================] - 0s 25us/step - loss: 0.0060\n",
      "Epoch 248/300\n",
      "354/354 [==============================] - 0s 28us/step - loss: 0.0060\n",
      "Epoch 249/300\n",
      "354/354 [==============================] - 0s 34us/step - loss: 0.0060\n",
      "Epoch 250/300\n",
      "354/354 [==============================] - 0s 37us/step - loss: 0.0060\n",
      "Epoch 251/300\n",
      "354/354 [==============================] - 0s 31us/step - loss: 0.0059\n",
      "Epoch 252/300\n",
      "354/354 [==============================] - 0s 28us/step - loss: 0.0059\n",
      "Epoch 253/300\n",
      "354/354 [==============================] - 0s 31us/step - loss: 0.0060\n",
      "Epoch 254/300\n",
      "354/354 [==============================] - 0s 31us/step - loss: 0.0059\n",
      "Epoch 255/300\n",
      "354/354 [==============================] - 0s 31us/step - loss: 0.0059\n",
      "Epoch 256/300\n",
      "354/354 [==============================] - 0s 31us/step - loss: 0.0059\n",
      "Epoch 257/300\n",
      "354/354 [==============================] - 0s 28us/step - loss: 0.0059\n",
      "Epoch 258/300\n",
      "354/354 [==============================] - 0s 31us/step - loss: 0.0059\n",
      "Epoch 259/300\n",
      "354/354 [==============================] - 0s 31us/step - loss: 0.0059\n",
      "Epoch 260/300\n",
      "354/354 [==============================] - 0s 28us/step - loss: 0.0059\n",
      "Epoch 261/300\n",
      "354/354 [==============================] - 0s 28us/step - loss: 0.0059\n",
      "Epoch 262/300\n",
      "354/354 [==============================] - 0s 28us/step - loss: 0.0058\n",
      "Epoch 263/300\n",
      "354/354 [==============================] - 0s 28us/step - loss: 0.0059\n",
      "Epoch 264/300\n",
      "354/354 [==============================] - 0s 28us/step - loss: 0.0058\n",
      "Epoch 265/300\n",
      "354/354 [==============================] - 0s 28us/step - loss: 0.0058\n",
      "Epoch 266/300\n",
      "354/354 [==============================] - 0s 28us/step - loss: 0.0060\n",
      "Epoch 267/300\n",
      "354/354 [==============================] - 0s 28us/step - loss: 0.0058\n",
      "Epoch 268/300\n",
      "354/354 [==============================] - 0s 28us/step - loss: 0.0058\n",
      "Epoch 269/300\n",
      "354/354 [==============================] - 0s 28us/step - loss: 0.0058\n",
      "Epoch 270/300\n",
      "354/354 [==============================] - 0s 25us/step - loss: 0.0058\n",
      "Epoch 271/300\n",
      "354/354 [==============================] - 0s 28us/step - loss: 0.0058\n",
      "Epoch 272/300\n",
      "354/354 [==============================] - 0s 25us/step - loss: 0.0057\n",
      "Epoch 273/300\n",
      "354/354 [==============================] - 0s 25us/step - loss: 0.0058\n",
      "Epoch 274/300\n",
      "354/354 [==============================] - 0s 28us/step - loss: 0.0058\n",
      "Epoch 275/300\n",
      "354/354 [==============================] - 0s 28us/step - loss: 0.0058\n",
      "Epoch 276/300\n",
      "354/354 [==============================] - 0s 31us/step - loss: 0.0057\n",
      "Epoch 277/300\n",
      "354/354 [==============================] - 0s 28us/step - loss: 0.0057\n",
      "Epoch 278/300\n",
      "354/354 [==============================] - 0s 31us/step - loss: 0.0058\n",
      "Epoch 279/300\n",
      "354/354 [==============================] - 0s 31us/step - loss: 0.0057\n",
      "Epoch 280/300\n",
      "354/354 [==============================] - 0s 25us/step - loss: 0.0057\n",
      "Epoch 281/300\n",
      "354/354 [==============================] - 0s 25us/step - loss: 0.0057\n",
      "Epoch 282/300\n",
      "354/354 [==============================] - 0s 28us/step - loss: 0.0057\n",
      "Epoch 283/300\n",
      "354/354 [==============================] - 0s 28us/step - loss: 0.0057\n",
      "Epoch 284/300\n",
      "354/354 [==============================] - 0s 25us/step - loss: 0.0057\n",
      "Epoch 285/300\n",
      "354/354 [==============================] - 0s 26us/step - loss: 0.0057\n",
      "Epoch 286/300\n",
      "354/354 [==============================] - 0s 28us/step - loss: 0.0057\n",
      "Epoch 287/300\n",
      "354/354 [==============================] - 0s 28us/step - loss: 0.0056\n",
      "Epoch 288/300\n",
      "354/354 [==============================] - 0s 29us/step - loss: 0.0056\n",
      "Epoch 289/300\n",
      "354/354 [==============================] - 0s 25us/step - loss: 0.0056\n",
      "Epoch 290/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "354/354 [==============================] - 0s 28us/step - loss: 0.0056\n",
      "Epoch 291/300\n",
      "354/354 [==============================] - 0s 31us/step - loss: 0.0056\n",
      "Epoch 292/300\n",
      "354/354 [==============================] - 0s 31us/step - loss: 0.0060\n",
      "Epoch 293/300\n",
      "354/354 [==============================] - 0s 28us/step - loss: 0.0056\n",
      "Epoch 294/300\n",
      "354/354 [==============================] - 0s 28us/step - loss: 0.0056\n",
      "Epoch 295/300\n",
      "354/354 [==============================] - 0s 26us/step - loss: 0.0056\n",
      "Epoch 296/300\n",
      "354/354 [==============================] - 0s 25us/step - loss: 0.0056\n",
      "Epoch 297/300\n",
      "354/354 [==============================] - 0s 28us/step - loss: 0.0056\n",
      "Epoch 298/300\n",
      "354/354 [==============================] - 0s 28us/step - loss: 0.0056\n",
      "Epoch 299/300\n",
      "354/354 [==============================] - 0s 28us/step - loss: 0.0056\n",
      "Epoch 300/300\n",
      "354/354 [==============================] - 0s 25us/step - loss: 0.0056\n"
     ]
    }
   ],
   "source": [
    "# モデルの学習\n",
    "result = model.fit(\n",
    "    X_train_n,\n",
    "    y_train_n,\n",
    "    epochs=300\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[25.429918 ]\n",
      " [23.583126 ]\n",
      " [27.10225  ]\n",
      " [12.820384 ]\n",
      " [19.932047 ]\n",
      " [19.694136 ]\n",
      " [22.222729 ]\n",
      " [21.10737  ]\n",
      " [18.195631 ]\n",
      " [17.584158 ]\n",
      " [10.488771 ]\n",
      " [13.985705 ]\n",
      " [14.740687 ]\n",
      " [ 9.015993 ]\n",
      " [41.643127 ]\n",
      " [32.226326 ]\n",
      " [23.836056 ]\n",
      " [37.765972 ]\n",
      " [30.461802 ]\n",
      " [21.933298 ]\n",
      " [23.910543 ]\n",
      " [21.73043  ]\n",
      " [19.128689 ]\n",
      " [28.249931 ]\n",
      " [21.204292 ]\n",
      " [15.130055 ]\n",
      " [17.07368  ]\n",
      " [17.457115 ]\n",
      " [39.42995  ]\n",
      " [17.241293 ]\n",
      " [17.026848 ]\n",
      " [17.698706 ]\n",
      " [18.568226 ]\n",
      " [21.112284 ]\n",
      " [26.624033 ]\n",
      " [23.559248 ]\n",
      " [10.118853 ]\n",
      " [29.188368 ]\n",
      " [15.607941 ]\n",
      " [13.431594 ]\n",
      " [25.114786 ]\n",
      " [20.07399  ]\n",
      " [21.850748 ]\n",
      " [16.259556 ]\n",
      " [23.28755  ]\n",
      " [24.352755 ]\n",
      " [18.291973 ]\n",
      " [19.078583 ]\n",
      " [13.891622 ]\n",
      " [23.148294 ]\n",
      " [16.348772 ]\n",
      " [17.676203 ]\n",
      " [20.376785 ]\n",
      " [34.46929  ]\n",
      " [13.597902 ]\n",
      " [19.801815 ]\n",
      " [19.38449  ]\n",
      " [16.109    ]\n",
      " [15.111745 ]\n",
      " [21.839472 ]\n",
      " [19.437008 ]\n",
      " [19.7325   ]\n",
      " [32.19111  ]\n",
      " [30.630987 ]\n",
      " [19.762774 ]\n",
      " [30.887691 ]\n",
      " [16.132175 ]\n",
      " [19.103323 ]\n",
      " [15.121482 ]\n",
      " [22.076593 ]\n",
      " [19.722511 ]\n",
      " [22.596888 ]\n",
      " [28.3448   ]\n",
      " [27.727592 ]\n",
      " [26.870756 ]\n",
      " [ 8.3987665]\n",
      " [40.40746  ]\n",
      " [22.38562  ]\n",
      " [26.077232 ]\n",
      " [17.443544 ]\n",
      " [26.960634 ]\n",
      " [19.215458 ]\n",
      " [19.05442  ]\n",
      " [41.063293 ]\n",
      " [43.187714 ]\n",
      " [23.776262 ]\n",
      " [23.207712 ]\n",
      " [15.940978 ]\n",
      " [26.58127  ]\n",
      " [15.656467 ]\n",
      " [17.760223 ]\n",
      " [11.042112 ]\n",
      " [22.83439  ]\n",
      " [30.416294 ]\n",
      " [22.644056 ]\n",
      " [19.836514 ]\n",
      " [ 7.503477 ]\n",
      " [24.51865  ]\n",
      " [12.980967 ]\n",
      " [17.177158 ]\n",
      " [24.22845  ]\n",
      " [20.708765 ]\n",
      " [30.40318  ]\n",
      " [21.011278 ]\n",
      " [26.379099 ]\n",
      " [21.082336 ]\n",
      " [ 9.686808 ]\n",
      " [16.205547 ]\n",
      " [22.705084 ]\n",
      " [27.085648 ]\n",
      " [35.245953 ]\n",
      " [11.804485 ]\n",
      " [18.987854 ]\n",
      " [16.550503 ]\n",
      " [13.129947 ]\n",
      " [24.133116 ]\n",
      " [ 9.276223 ]\n",
      " [19.983753 ]\n",
      " [10.965225 ]\n",
      " [41.542336 ]\n",
      " [30.115208 ]\n",
      " [11.975382 ]\n",
      " [16.912199 ]\n",
      " [19.257328 ]\n",
      " [20.61198  ]\n",
      " [20.664251 ]\n",
      " [35.63987  ]\n",
      " [14.230602 ]\n",
      " [19.667545 ]\n",
      " [33.527153 ]\n",
      " [17.16974  ]\n",
      " [11.681719 ]\n",
      " [15.729947 ]\n",
      " [19.32699  ]\n",
      " [11.706006 ]\n",
      " [31.620483 ]\n",
      " [21.58315  ]\n",
      " [14.566979 ]\n",
      " [24.852533 ]\n",
      " [10.635034 ]\n",
      " [12.636994 ]\n",
      " [19.813335 ]\n",
      " [34.831482 ]\n",
      " [28.318605 ]\n",
      " [26.280107 ]\n",
      " [15.519231 ]\n",
      " [30.269691 ]\n",
      " [31.282581 ]\n",
      " [12.288766 ]\n",
      " [ 9.066006 ]\n",
      " [27.66774  ]\n",
      " [26.51753  ]]\n"
     ]
    }
   ],
   "source": [
    "# 予測値の算出\n",
    "y_predict_n = model.predict(X_test_n)\n",
    "y_predict = scaler_y.inverse_transform(y_predict_n)\n",
    "print(y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.14642277685672345"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 乖離度の算出\n",
    "import numpy as np\n",
    "np.mean(\n",
    "    np.abs(y_test-y_predict.flatten())\n",
    "    /y_test\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 分類問題を解いてみる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 連続値データの読み込み\n",
    "from sklearn.datasets import load_iris\n",
    "iris = load_iris()\n",
    "\n",
    "# 訓練データとテストデータに分ける\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(iris['data'], iris['target'], test_size=0.3,  random_state=0)\n",
    "\n",
    "\"\"\"\n",
    "# 標準化（Standardization）\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train_s = scaler.fit_transform(X_train)\n",
    "X_test_s = scaler.transform(X_test) \n",
    "scaler = StandardScaler()\n",
    "y_train_s = scaler.fit_transform(y_train.reshape(len(y_train),1))\n",
    "y_test_s = scaler.transform(y_test.reshape(len(y_test),1)) \n",
    "\"\"\"\n",
    "\n",
    "# 正規化（Normarization）\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler_x = MinMaxScaler()\n",
    "X_train_n = scaler_x.fit_transform(X_train)\n",
    "X_test_n = scaler_x.transform(X_test) \n",
    "\n",
    "# one-hotベクトル化\n",
    "import keras\n",
    "y_train = keras.utils.to_categorical(y_train,3)\n",
    "y_test = keras.utils.to_categorical(y_test,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 基本モデル生成\n",
    "from keras.models import Sequential\n",
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 層の追加\n",
    "from keras.layers import Dense\n",
    "# 中間層\n",
    "model.add(\n",
    "    Dense(\n",
    "        128, \n",
    "        activation='relu'\n",
    "    )\n",
    ")\n",
    "model.add(\n",
    "    Dense(\n",
    "        128, \n",
    "        activation='relu'\n",
    "    )\n",
    ")\n",
    "model.add(\n",
    "    Dense(\n",
    "        128, \n",
    "        activation='relu'\n",
    "    )\n",
    ")\n",
    "# 出力層\n",
    "model.add(\n",
    "    Dense(\n",
    "        3, \n",
    "        activation='linear'\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデルの学習設定\n",
    "from keras import losses\n",
    "from keras import optimizers\n",
    "model.compile(\n",
    "    loss=losses.mean_squared_error,\n",
    "    optimizer=optimizers.SGD(lr=0.01),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "105/105 [==============================] - 0s 57us/step - loss: 0.0165\n",
      "Epoch 2/100\n",
      "105/105 [==============================] - 0s 48us/step - loss: 0.0172\n",
      "Epoch 3/100\n",
      "105/105 [==============================] - 0s 57us/step - loss: 0.0171\n",
      "Epoch 4/100\n",
      "105/105 [==============================] - 0s 67us/step - loss: 0.0173\n",
      "Epoch 5/100\n",
      "105/105 [==============================] - 0s 57us/step - loss: 0.0166\n",
      "Epoch 6/100\n",
      "105/105 [==============================] - 0s 57us/step - loss: 0.0166\n",
      "Epoch 7/100\n",
      "105/105 [==============================] - 0s 57us/step - loss: 0.0165\n",
      "Epoch 8/100\n",
      "105/105 [==============================] - 0s 47us/step - loss: 0.0165\n",
      "Epoch 9/100\n",
      "105/105 [==============================] - 0s 57us/step - loss: 0.0163\n",
      "Epoch 10/100\n",
      "105/105 [==============================] - 0s 48us/step - loss: 0.0161\n",
      "Epoch 11/100\n",
      "105/105 [==============================] - 0s 57us/step - loss: 0.0163\n",
      "Epoch 12/100\n",
      "105/105 [==============================] - 0s 57us/step - loss: 0.0167\n",
      "Epoch 13/100\n",
      "105/105 [==============================] - 0s 67us/step - loss: 0.0160\n",
      "Epoch 14/100\n",
      "105/105 [==============================] - 0s 67us/step - loss: 0.0172\n",
      "Epoch 15/100\n",
      "105/105 [==============================] - 0s 47us/step - loss: 0.0161\n",
      "Epoch 16/100\n",
      "105/105 [==============================] - 0s 67us/step - loss: 0.0167\n",
      "Epoch 17/100\n",
      "105/105 [==============================] - 0s 57us/step - loss: 0.0166\n",
      "Epoch 18/100\n",
      "105/105 [==============================] - 0s 57us/step - loss: 0.0161\n",
      "Epoch 19/100\n",
      "105/105 [==============================] - 0s 48us/step - loss: 0.0166\n",
      "Epoch 20/100\n",
      "105/105 [==============================] - 0s 76us/step - loss: 0.0191\n",
      "Epoch 21/100\n",
      "105/105 [==============================] - 0s 57us/step - loss: 0.0160\n",
      "Epoch 22/100\n",
      "105/105 [==============================] - 0s 48us/step - loss: 0.0171\n",
      "Epoch 23/100\n",
      "105/105 [==============================] - 0s 48us/step - loss: 0.0160\n",
      "Epoch 24/100\n",
      "105/105 [==============================] - 0s 48us/step - loss: 0.0164\n",
      "Epoch 25/100\n",
      "105/105 [==============================] - 0s 48us/step - loss: 0.0159\n",
      "Epoch 26/100\n",
      "105/105 [==============================] - 0s 48us/step - loss: 0.0158\n",
      "Epoch 27/100\n",
      "105/105 [==============================] - 0s 57us/step - loss: 0.0160\n",
      "Epoch 28/100\n",
      "105/105 [==============================] - 0s 67us/step - loss: 0.0158\n",
      "Epoch 29/100\n",
      "105/105 [==============================] - 0s 67us/step - loss: 0.0164\n",
      "Epoch 30/100\n",
      "105/105 [==============================] - 0s 57us/step - loss: 0.0158\n",
      "Epoch 31/100\n",
      "105/105 [==============================] - 0s 76us/step - loss: 0.0158\n",
      "Epoch 32/100\n",
      "105/105 [==============================] - 0s 67us/step - loss: 0.0157\n",
      "Epoch 33/100\n",
      "105/105 [==============================] - 0s 57us/step - loss: 0.0159\n",
      "Epoch 34/100\n",
      "105/105 [==============================] - 0s 48us/step - loss: 0.0156\n",
      "Epoch 35/100\n",
      "105/105 [==============================] - 0s 38us/step - loss: 0.0162\n",
      "Epoch 36/100\n",
      "105/105 [==============================] - 0s 57us/step - loss: 0.0156\n",
      "Epoch 37/100\n",
      "105/105 [==============================] - 0s 57us/step - loss: 0.0160\n",
      "Epoch 38/100\n",
      "105/105 [==============================] - 0s 48us/step - loss: 0.0159\n",
      "Epoch 39/100\n",
      "105/105 [==============================] - 0s 48us/step - loss: 0.0158\n",
      "Epoch 40/100\n",
      "105/105 [==============================] - 0s 57us/step - loss: 0.0154\n",
      "Epoch 41/100\n",
      "105/105 [==============================] - 0s 57us/step - loss: 0.0154\n",
      "Epoch 42/100\n",
      "105/105 [==============================] - 0s 48us/step - loss: 0.0155\n",
      "Epoch 43/100\n",
      "105/105 [==============================] - 0s 57us/step - loss: 0.0166\n",
      "Epoch 44/100\n",
      "105/105 [==============================] - 0s 48us/step - loss: 0.0158\n",
      "Epoch 45/100\n",
      "105/105 [==============================] - 0s 48us/step - loss: 0.0157\n",
      "Epoch 46/100\n",
      "105/105 [==============================] - 0s 57us/step - loss: 0.0160\n",
      "Epoch 47/100\n",
      "105/105 [==============================] - 0s 57us/step - loss: 0.0157\n",
      "Epoch 48/100\n",
      "105/105 [==============================] - 0s 48us/step - loss: 0.0154\n",
      "Epoch 49/100\n",
      "105/105 [==============================] - 0s 48us/step - loss: 0.0164\n",
      "Epoch 50/100\n",
      "105/105 [==============================] - 0s 57us/step - loss: 0.0160\n",
      "Epoch 51/100\n",
      "105/105 [==============================] - 0s 57us/step - loss: 0.0157\n",
      "Epoch 52/100\n",
      "105/105 [==============================] - 0s 48us/step - loss: 0.0160\n",
      "Epoch 53/100\n",
      "105/105 [==============================] - 0s 57us/step - loss: 0.0154\n",
      "Epoch 54/100\n",
      "105/105 [==============================] - 0s 57us/step - loss: 0.0153\n",
      "Epoch 55/100\n",
      "105/105 [==============================] - 0s 57us/step - loss: 0.0152\n",
      "Epoch 56/100\n",
      "105/105 [==============================] - 0s 38us/step - loss: 0.0153\n",
      "Epoch 57/100\n",
      "105/105 [==============================] - 0s 57us/step - loss: 0.0157\n",
      "Epoch 58/100\n",
      "105/105 [==============================] - 0s 48us/step - loss: 0.0153\n",
      "Epoch 59/100\n",
      "105/105 [==============================] - 0s 48us/step - loss: 0.0151\n",
      "Epoch 60/100\n",
      "105/105 [==============================] - 0s 48us/step - loss: 0.0154\n",
      "Epoch 61/100\n",
      "105/105 [==============================] - 0s 48us/step - loss: 0.0164\n",
      "Epoch 62/100\n",
      "105/105 [==============================] - 0s 48us/step - loss: 0.0160\n",
      "Epoch 63/100\n",
      "105/105 [==============================] - 0s 48us/step - loss: 0.0153\n",
      "Epoch 64/100\n",
      "105/105 [==============================] - 0s 48us/step - loss: 0.0152\n",
      "Epoch 65/100\n",
      "105/105 [==============================] - 0s 48us/step - loss: 0.0150\n",
      "Epoch 66/100\n",
      "105/105 [==============================] - 0s 48us/step - loss: 0.0153\n",
      "Epoch 67/100\n",
      "105/105 [==============================] - 0s 48us/step - loss: 0.0152\n",
      "Epoch 68/100\n",
      "105/105 [==============================] - 0s 48us/step - loss: 0.0152\n",
      "Epoch 69/100\n",
      "105/105 [==============================] - 0s 38us/step - loss: 0.0152\n",
      "Epoch 70/100\n",
      "105/105 [==============================] - 0s 48us/step - loss: 0.0150\n",
      "Epoch 71/100\n",
      "105/105 [==============================] - 0s 48us/step - loss: 0.0152\n",
      "Epoch 72/100\n",
      "105/105 [==============================] - 0s 38us/step - loss: 0.0151\n",
      "Epoch 73/100\n",
      "105/105 [==============================] - 0s 48us/step - loss: 0.0149\n",
      "Epoch 74/100\n",
      "105/105 [==============================] - 0s 48us/step - loss: 0.0153\n",
      "Epoch 75/100\n",
      "105/105 [==============================] - 0s 48us/step - loss: 0.0149\n",
      "Epoch 76/100\n",
      "105/105 [==============================] - 0s 48us/step - loss: 0.0150\n",
      "Epoch 77/100\n",
      "105/105 [==============================] - 0s 38us/step - loss: 0.0151\n",
      "Epoch 78/100\n",
      "105/105 [==============================] - 0s 48us/step - loss: 0.0153\n",
      "Epoch 79/100\n",
      "105/105 [==============================] - 0s 48us/step - loss: 0.0149\n",
      "Epoch 80/100\n",
      "105/105 [==============================] - 0s 48us/step - loss: 0.0150\n",
      "Epoch 81/100\n",
      "105/105 [==============================] - 0s 48us/step - loss: 0.0148\n",
      "Epoch 82/100\n",
      "105/105 [==============================] - 0s 57us/step - loss: 0.0148\n",
      "Epoch 83/100\n",
      "105/105 [==============================] - 0s 48us/step - loss: 0.0155\n",
      "Epoch 84/100\n",
      "105/105 [==============================] - 0s 47us/step - loss: 0.0149\n",
      "Epoch 85/100\n",
      "105/105 [==============================] - 0s 48us/step - loss: 0.0151\n",
      "Epoch 86/100\n",
      "105/105 [==============================] - 0s 48us/step - loss: 0.0152\n",
      "Epoch 87/100\n",
      "105/105 [==============================] - 0s 48us/step - loss: 0.0150\n",
      "Epoch 88/100\n",
      "105/105 [==============================] - 0s 47us/step - loss: 0.0149\n",
      "Epoch 89/100\n",
      "105/105 [==============================] - 0s 47us/step - loss: 0.0148\n",
      "Epoch 90/100\n",
      "105/105 [==============================] - 0s 48us/step - loss: 0.0160\n",
      "Epoch 91/100\n",
      "105/105 [==============================] - 0s 48us/step - loss: 0.0150\n",
      "Epoch 92/100\n",
      "105/105 [==============================] - 0s 48us/step - loss: 0.0154\n",
      "Epoch 93/100\n",
      "105/105 [==============================] - 0s 48us/step - loss: 0.0146\n",
      "Epoch 94/100\n",
      "105/105 [==============================] - 0s 47us/step - loss: 0.0146\n",
      "Epoch 95/100\n",
      "105/105 [==============================] - 0s 48us/step - loss: 0.0151\n",
      "Epoch 96/100\n",
      "105/105 [==============================] - 0s 48us/step - loss: 0.0152\n",
      "Epoch 97/100\n",
      "105/105 [==============================] - 0s 48us/step - loss: 0.0151\n",
      "Epoch 98/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105/105 [==============================] - 0s 38us/step - loss: 0.0145\n",
      "Epoch 99/100\n",
      "105/105 [==============================] - 0s 48us/step - loss: 0.0145\n",
      "Epoch 100/100\n",
      "105/105 [==============================] - 0s 57us/step - loss: 0.0152\n"
     ]
    }
   ],
   "source": [
    "# モデルの学習\n",
    "result = model.fit(\n",
    "    X_train_n,\n",
    "    y_train,\n",
    "    epochs=100\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 1 0 2 0 2 0 1 1 1 2 1 1 1 1 0 1 1 0 0 2 1 0 0 2 0 0 1 1 0 2 1 0 2 2 1 0\n",
      " 2 1 1 2 0 2 0 0]\n"
     ]
    }
   ],
   "source": [
    "# 予測値の算出\n",
    "y_predict = np.argmax(model.predict(X_test_n),axis=1)\n",
    "print(y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9777777777777777"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 正答率の算出\n",
    "np.sum(\n",
    "    np.array(y_predict)\n",
    "    ==\n",
    "    np.argmax(np.array(y_test),axis=1)\n",
    ")/len(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 様々な精度向上テクニック\n",
    "\n",
    "+ **ミニバッチ学習**：ニューラルネットは、データが増えれば増えるほど、1epoch毎の計算時間が多くなるため、全てのデータを使って、勾配(重み)を更新していては、非効率的である。そのため、全データから、ランダムに任意の個数のデータを抽出し、学習させると、扱うデータ量が減り、計算速度が向上し、限られたリソースで、多くの勾配(重み)を更新できる。\n",
    "+ **重み更新法の変更**：上記で使用していたSGDは確率的勾配降下法と呼ばれるもので、その他にも、「Adam」「RMSprop」「Adagrad」「Adamax」「Nadam」などがある。\n",
    "+ **活性化関数の変更**：上記で使用してきた「relu」「linear(恒等関数)」で、その他にも、「elu」「selu」「relu」「softmax」「softplus」「spftsign」「tanh」「sigmoid」「hard_sigmoid」などがある。\n",
    "中間層には、原則として、「linear」以外のすべての活性化関数が用いれる。\n",
    "    + 出力層\n",
    "        + 回帰問題：「linear」を用いるのが一般的であるが、目的変数の取りうる値(値域)が-1~1とわかっているなどの場合は、tanhを利用することができる。目的変数の値域と一致する活性化関数を選択する。\n",
    "        + 分類問題：\n",
    "            + 2項分類：sigmoidを用いるのが一般的\n",
    "            + 多項分類：softmaxを用いるのが一般的。\n",
    "+ **ドロップアウト**：一定の確率でランダムにニューロンを無視して学習を進める\n",
    "+ **Batch Normalization**：バッチ正規化と呼ばれ、基本的には、勾配消失・勾配爆発を防ぐための手法であり、これまでは、活性化関数の変更・学習係数を下げる・DropOut層の追加などで対応してきたが、Batch Normalizationは、ミニバッチの各出力を正規化させ、学習過程の安定と学習速度の向上を実現した。\n",
    "+ **勾配(重み)やバイアスの初期値**\n",
    "    + Heの初期値：中間層の活性化関数がReluの時に、有効で、勾配(重み)やバイアスに対し、特定の法則に則って算出した、初期値を与えてやることで、中間層からの出力を偏りのないものにすることで、勾配消失問題と表現力の低下を解決する\n",
    "    + Xavierの初期値：中間層の活性化関数がsigmoid/tanhの時に、有効で、勾配(重み)やバイアスに対し、特定の法則に則って算出した、初期値を与えてやることで、中間層からの出力を偏りのないものにすることで、勾配消失問題と表現力の低下を解決する\n",
    "+ **正則化項**：過学習防止のために、勾配(重み)が大きくなりすぎると、ペナルティを与える\n",
    "    + l1正則化：大きな次元の入力データに対して有効で、意味のないベクトルをそぎ落としてくれる\n",
    "    + l2正則化：特定の変数について、重要視したモデルを作成することを防ぐ\n",
    "    + l1_l2正則化：上記2つの合体版"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 連続値データの読み込み\n",
    "from sklearn.datasets import load_boston\n",
    "boston = load_boston()\n",
    "\n",
    "# 訓練データとテストデータに分ける\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(boston['data'], boston['target'], test_size=0.3,  random_state=0)\n",
    "\n",
    "\"\"\"\n",
    "# 標準化（Standardization）\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train_s = scaler.fit_transform(X_train)\n",
    "X_test_s = scaler.transform(X_test) \n",
    "scaler = StandardScaler()\n",
    "y_train_s = scaler.fit_transform(y_train.reshape(len(y_train),1))\n",
    "y_test_s = scaler.transform(y_test.reshape(len(y_test),1)) \n",
    "\"\"\"\n",
    "\n",
    "# 正規化（Normarization）\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler_x = MinMaxScaler()\n",
    "X_train_n = scaler_x.fit_transform(X_train)\n",
    "X_test_n = scaler_x.transform(X_test) \n",
    "scaler_y = MinMaxScaler()\n",
    "y_train_n = scaler_y.fit_transform(y_train.reshape(len(y_train),1))\n",
    "y_test_n = scaler_y.transform(y_test.reshape(len(y_test),1)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 基本モデル生成\n",
    "from keras.models import Sequential\n",
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 層の追加\n",
    "from keras.layers import Dense,Dropout\n",
    "from keras.layers import normalization\n",
    "from keras import regularizers\n",
    "\n",
    "# 中間層\n",
    "model.add(\n",
    "    Dense(\n",
    "        128, \n",
    "        activation='relu',\n",
    "        kernel_initializer='he_normal',                  # 勾配(重み)の初期値\n",
    "        bias_initializer='he_normal',                    # バイアス項の初期値\n",
    "        kernel_regularizer=regularizers.l1_l2(0.001),    # 勾配(重み)の正則化項\n",
    "        bias_regularizer=regularizers.l1_l2(0.001)       # バイアス項の正則化項\n",
    "    )\n",
    ")\n",
    "model.add(Dropout(0.1))                      # ドロップアウト層\n",
    "model.add(normalization.BatchNormalization())# バッチ正規化\n",
    "model.add(Dense(128, activation='selu'))\n",
    "model.add(Dropout(0.1))                      # ドロップアウト層\n",
    "model.add(normalization.BatchNormalization())# バッチ正規化\n",
    "model.add(Dense(64, activation='softmax'))\n",
    "\n",
    "# 出力層\n",
    "model.add(Dense(1, activation='linear'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデルの学習設定\n",
    "from keras import losses\n",
    "from keras import optimizers\n",
    "model.compile(\n",
    "    loss=losses.mean_squared_error,\n",
    "    optimizer=optimizers.Adam(),             # 勾配(重み)更新法の変更\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "354/354 [==============================] - 0s 65us/step - loss: 0.0139\n",
      "Epoch 2/100\n",
      "354/354 [==============================] - 0s 59us/step - loss: 0.0138\n",
      "Epoch 3/100\n",
      "354/354 [==============================] - 0s 62us/step - loss: 0.0142\n",
      "Epoch 4/100\n",
      "354/354 [==============================] - 0s 59us/step - loss: 0.0146\n",
      "Epoch 5/100\n",
      "354/354 [==============================] - 0s 59us/step - loss: 0.0137\n",
      "Epoch 6/100\n",
      "354/354 [==============================] - 0s 62us/step - loss: 0.0149\n",
      "Epoch 7/100\n",
      "354/354 [==============================] - 0s 62us/step - loss: 0.0133\n",
      "Epoch 8/100\n",
      "354/354 [==============================] - 0s 59us/step - loss: 0.0154\n",
      "Epoch 9/100\n",
      "354/354 [==============================] - 0s 65us/step - loss: 0.0166\n",
      "Epoch 10/100\n",
      "354/354 [==============================] - 0s 59us/step - loss: 0.0158\n",
      "Epoch 11/100\n",
      "354/354 [==============================] - 0s 59us/step - loss: 0.0160\n",
      "Epoch 12/100\n",
      "354/354 [==============================] - 0s 65us/step - loss: 0.0155\n",
      "Epoch 13/100\n",
      "354/354 [==============================] - 0s 62us/step - loss: 0.0166\n",
      "Epoch 14/100\n",
      "354/354 [==============================] - 0s 62us/step - loss: 0.0232\n",
      "Epoch 15/100\n",
      "354/354 [==============================] - 0s 56us/step - loss: 0.0177\n",
      "Epoch 16/100\n",
      "354/354 [==============================] - 0s 59us/step - loss: 0.0183\n",
      "Epoch 17/100\n",
      "354/354 [==============================] - 0s 65us/step - loss: 0.0162\n",
      "Epoch 18/100\n",
      "354/354 [==============================] - 0s 62us/step - loss: 0.0145\n",
      "Epoch 19/100\n",
      "354/354 [==============================] - 0s 62us/step - loss: 0.0126\n",
      "Epoch 20/100\n",
      "354/354 [==============================] - 0s 59us/step - loss: 0.0142\n",
      "Epoch 21/100\n",
      "354/354 [==============================] - 0s 62us/step - loss: 0.0177\n",
      "Epoch 22/100\n",
      "354/354 [==============================] - 0s 59us/step - loss: 0.0159\n",
      "Epoch 23/100\n",
      "354/354 [==============================] - 0s 62us/step - loss: 0.0164\n",
      "Epoch 24/100\n",
      "354/354 [==============================] - 0s 62us/step - loss: 0.0165\n",
      "Epoch 25/100\n",
      "354/354 [==============================] - 0s 59us/step - loss: 0.0199\n",
      "Epoch 26/100\n",
      "354/354 [==============================] - 0s 59us/step - loss: 0.0178\n",
      "Epoch 27/100\n",
      "354/354 [==============================] - 0s 71us/step - loss: 0.0184\n",
      "Epoch 28/100\n",
      "354/354 [==============================] - 0s 62us/step - loss: 0.0166\n",
      "Epoch 29/100\n",
      "354/354 [==============================] - 0s 59us/step - loss: 0.0169\n",
      "Epoch 30/100\n",
      "354/354 [==============================] - 0s 59us/step - loss: 0.0188\n",
      "Epoch 31/100\n",
      "354/354 [==============================] - 0s 59us/step - loss: 0.0186\n",
      "Epoch 32/100\n",
      "354/354 [==============================] - 0s 62us/step - loss: 0.0178\n",
      "Epoch 33/100\n",
      "354/354 [==============================] - 0s 59us/step - loss: 0.0162\n",
      "Epoch 34/100\n",
      "354/354 [==============================] - 0s 59us/step - loss: 0.0159\n",
      "Epoch 35/100\n",
      "354/354 [==============================] - 0s 59us/step - loss: 0.0160\n",
      "Epoch 36/100\n",
      "354/354 [==============================] - 0s 62us/step - loss: 0.0150\n",
      "Epoch 37/100\n",
      "354/354 [==============================] - 0s 59us/step - loss: 0.0173\n",
      "Epoch 38/100\n",
      "354/354 [==============================] - 0s 59us/step - loss: 0.0247\n",
      "Epoch 39/100\n",
      "354/354 [==============================] - 0s 59us/step - loss: 0.0247\n",
      "Epoch 40/100\n",
      "354/354 [==============================] - 0s 59us/step - loss: 0.0242\n",
      "Epoch 41/100\n",
      "354/354 [==============================] - 0s 59us/step - loss: 0.0255\n",
      "Epoch 42/100\n",
      "354/354 [==============================] - 0s 59us/step - loss: 0.0241\n",
      "Epoch 43/100\n",
      "354/354 [==============================] - 0s 59us/step - loss: 0.0230\n",
      "Epoch 44/100\n",
      "354/354 [==============================] - 0s 56us/step - loss: 0.0224\n",
      "Epoch 45/100\n",
      "354/354 [==============================] - 0s 56us/step - loss: 0.0213\n",
      "Epoch 46/100\n",
      "354/354 [==============================] - 0s 62us/step - loss: 0.0226\n",
      "Epoch 47/100\n",
      "354/354 [==============================] - 0s 59us/step - loss: 0.0228\n",
      "Epoch 48/100\n",
      "354/354 [==============================] - 0s 59us/step - loss: 0.0202\n",
      "Epoch 49/100\n",
      "354/354 [==============================] - 0s 59us/step - loss: 0.0192\n",
      "Epoch 50/100\n",
      "354/354 [==============================] - 0s 59us/step - loss: 0.0190\n",
      "Epoch 51/100\n",
      "354/354 [==============================] - 0s 59us/step - loss: 0.0179\n",
      "Epoch 52/100\n",
      "354/354 [==============================] - 0s 59us/step - loss: 0.0208\n",
      "Epoch 53/100\n",
      "354/354 [==============================] - 0s 59us/step - loss: 0.0178\n",
      "Epoch 54/100\n",
      "354/354 [==============================] - 0s 57us/step - loss: 0.0208\n",
      "Epoch 55/100\n",
      "354/354 [==============================] - 0s 62us/step - loss: 0.0244\n",
      "Epoch 56/100\n",
      "354/354 [==============================] - 0s 65us/step - loss: 0.0240\n",
      "Epoch 57/100\n",
      "354/354 [==============================] - 0s 62us/step - loss: 0.0224\n",
      "Epoch 58/100\n",
      "354/354 [==============================] - 0s 59us/step - loss: 0.0236\n",
      "Epoch 59/100\n",
      "354/354 [==============================] - 0s 59us/step - loss: 0.0214\n",
      "Epoch 60/100\n",
      "354/354 [==============================] - 0s 59us/step - loss: 0.0276\n",
      "Epoch 61/100\n",
      "354/354 [==============================] - 0s 62us/step - loss: 0.0246\n",
      "Epoch 62/100\n",
      "354/354 [==============================] - 0s 62us/step - loss: 0.0291\n",
      "Epoch 63/100\n",
      "354/354 [==============================] - 0s 57us/step - loss: 0.0239\n",
      "Epoch 64/100\n",
      "354/354 [==============================] - 0s 59us/step - loss: 0.0242\n",
      "Epoch 65/100\n",
      "354/354 [==============================] - 0s 62us/step - loss: 0.0239\n",
      "Epoch 66/100\n",
      "354/354 [==============================] - 0s 57us/step - loss: 0.0218\n",
      "Epoch 67/100\n",
      "354/354 [==============================] - 0s 56us/step - loss: 0.0194\n",
      "Epoch 68/100\n",
      "354/354 [==============================] - 0s 59us/step - loss: 0.0186\n",
      "Epoch 69/100\n",
      "354/354 [==============================] - 0s 59us/step - loss: 0.0204\n",
      "Epoch 70/100\n",
      "354/354 [==============================] - 0s 59us/step - loss: 0.0193\n",
      "Epoch 71/100\n",
      "354/354 [==============================] - 0s 62us/step - loss: 0.0193\n",
      "Epoch 72/100\n",
      "354/354 [==============================] - 0s 62us/step - loss: 0.0204\n",
      "Epoch 73/100\n",
      "354/354 [==============================] - 0s 62us/step - loss: 0.0230\n",
      "Epoch 74/100\n",
      "354/354 [==============================] - 0s 59us/step - loss: 0.0244\n",
      "Epoch 75/100\n",
      "354/354 [==============================] - 0s 56us/step - loss: 0.0263\n",
      "Epoch 76/100\n",
      "354/354 [==============================] - 0s 57us/step - loss: 0.0280\n",
      "Epoch 77/100\n",
      "354/354 [==============================] - 0s 65us/step - loss: 0.0250\n",
      "Epoch 78/100\n",
      "354/354 [==============================] - 0s 62us/step - loss: 0.0281\n",
      "Epoch 79/100\n",
      "354/354 [==============================] - 0s 59us/step - loss: 0.0277\n",
      "Epoch 80/100\n",
      "354/354 [==============================] - 0s 62us/step - loss: 0.0258\n",
      "Epoch 81/100\n",
      "354/354 [==============================] - 0s 59us/step - loss: 0.0252\n",
      "Epoch 82/100\n",
      "354/354 [==============================] - 0s 62us/step - loss: 0.0224\n",
      "Epoch 83/100\n",
      "354/354 [==============================] - 0s 56us/step - loss: 0.0224\n",
      "Epoch 84/100\n",
      "354/354 [==============================] - 0s 59us/step - loss: 0.0217\n",
      "Epoch 85/100\n",
      "354/354 [==============================] - 0s 59us/step - loss: 0.0196\n",
      "Epoch 86/100\n",
      "354/354 [==============================] - 0s 59us/step - loss: 0.0201\n",
      "Epoch 87/100\n",
      "354/354 [==============================] - 0s 62us/step - loss: 0.0205\n",
      "Epoch 88/100\n",
      "354/354 [==============================] - 0s 59us/step - loss: 0.0194\n",
      "Epoch 89/100\n",
      "354/354 [==============================] - 0s 59us/step - loss: 0.0176\n",
      "Epoch 90/100\n",
      "354/354 [==============================] - 0s 57us/step - loss: 0.0168\n",
      "Epoch 91/100\n",
      "354/354 [==============================] - 0s 59us/step - loss: 0.0177\n",
      "Epoch 92/100\n",
      "354/354 [==============================] - 0s 59us/step - loss: 0.0156\n",
      "Epoch 93/100\n",
      "354/354 [==============================] - 0s 59us/step - loss: 0.0148\n",
      "Epoch 94/100\n",
      "354/354 [==============================] - 0s 59us/step - loss: 0.0153\n",
      "Epoch 95/100\n",
      "354/354 [==============================] - 0s 59us/step - loss: 0.0163\n",
      "Epoch 96/100\n",
      "354/354 [==============================] - 0s 62us/step - loss: 0.0182\n",
      "Epoch 97/100\n",
      "354/354 [==============================] - 0s 62us/step - loss: 0.0183\n",
      "Epoch 98/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "354/354 [==============================] - 0s 59us/step - loss: 0.0167\n",
      "Epoch 99/100\n",
      "354/354 [==============================] - 0s 59us/step - loss: 0.0167\n",
      "Epoch 100/100\n",
      "354/354 [==============================] - 0s 62us/step - loss: 0.0178\n"
     ]
    }
   ],
   "source": [
    "# モデルの学習\n",
    "result = model.fit(\n",
    "    X_train_n,\n",
    "    y_train_n,\n",
    "    batch_size=32,                          # ミニバッチ処理\n",
    "    epochs=100\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[23.930578]\n",
      " [26.0946  ]\n",
      " [24.450039]\n",
      " [20.544035]\n",
      " [23.653536]\n",
      " [23.397242]\n",
      " [24.456907]\n",
      " [23.49563 ]\n",
      " [23.411594]\n",
      " [22.9304  ]\n",
      " [13.333006]\n",
      " [17.387506]\n",
      " [20.73334 ]\n",
      " [16.716558]\n",
      " [45.374405]\n",
      " [30.472412]\n",
      " [24.8558  ]\n",
      " [36.378338]\n",
      " [25.477175]\n",
      " [23.666609]\n",
      " [23.919397]\n",
      " [24.292625]\n",
      " [22.981037]\n",
      " [25.027187]\n",
      " [23.572218]\n",
      " [21.645351]\n",
      " [22.750872]\n",
      " [22.893757]\n",
      " [44.478695]\n",
      " [23.151447]\n",
      " [22.150944]\n",
      " [22.870333]\n",
      " [23.398153]\n",
      " [23.823353]\n",
      " [24.52095 ]\n",
      " [22.928736]\n",
      " [17.206196]\n",
      " [28.503975]\n",
      " [20.34945 ]\n",
      " [19.772598]\n",
      " [23.968262]\n",
      " [23.526978]\n",
      " [23.789776]\n",
      " [22.274685]\n",
      " [24.147243]\n",
      " [23.947586]\n",
      " [23.644224]\n",
      " [23.79026 ]\n",
      " [19.006449]\n",
      " [23.61165 ]\n",
      " [23.312729]\n",
      " [23.305277]\n",
      " [23.932756]\n",
      " [40.17698 ]\n",
      " [21.133078]\n",
      " [23.821732]\n",
      " [23.449518]\n",
      " [23.301632]\n",
      " [19.773237]\n",
      " [23.374067]\n",
      " [23.295525]\n",
      " [23.626501]\n",
      " [29.391953]\n",
      " [26.119936]\n",
      " [23.803576]\n",
      " [26.569042]\n",
      " [21.32222 ]\n",
      " [23.330729]\n",
      " [19.69961 ]\n",
      " [23.674387]\n",
      " [23.692068]\n",
      " [23.879307]\n",
      " [25.647055]\n",
      " [26.470812]\n",
      " [26.892496]\n",
      " [15.487568]\n",
      " [45.64925 ]\n",
      " [23.819027]\n",
      " [24.111874]\n",
      " [23.278921]\n",
      " [24.67905 ]\n",
      " [22.199959]\n",
      " [23.575016]\n",
      " [45.987038]\n",
      " [47.2068  ]\n",
      " [23.84827 ]\n",
      " [23.76295 ]\n",
      " [21.115122]\n",
      " [25.724422]\n",
      " [21.761875]\n",
      " [22.709036]\n",
      " [16.005028]\n",
      " [23.884237]\n",
      " [27.152168]\n",
      " [23.418785]\n",
      " [23.559328]\n",
      " [13.198079]\n",
      " [24.473537]\n",
      " [18.628658]\n",
      " [23.141514]\n",
      " [23.969307]\n",
      " [23.067587]\n",
      " [25.455242]\n",
      " [23.571644]\n",
      " [24.420347]\n",
      " [24.027483]\n",
      " [14.915905]\n",
      " [22.639923]\n",
      " [23.380022]\n",
      " [24.639238]\n",
      " [31.728739]\n",
      " [18.876152]\n",
      " [23.431625]\n",
      " [23.507572]\n",
      " [20.737156]\n",
      " [23.681448]\n",
      " [12.317378]\n",
      " [22.756126]\n",
      " [18.810331]\n",
      " [45.63423 ]\n",
      " [26.528522]\n",
      " [19.22457 ]\n",
      " [23.339958]\n",
      " [23.49633 ]\n",
      " [23.75122 ]\n",
      " [22.845455]\n",
      " [32.511482]\n",
      " [22.827686]\n",
      " [23.495544]\n",
      " [30.210093]\n",
      " [21.928818]\n",
      " [14.87159 ]\n",
      " [21.609505]\n",
      " [24.155207]\n",
      " [16.77774 ]\n",
      " [30.813976]\n",
      " [24.042023]\n",
      " [20.894129]\n",
      " [24.161392]\n",
      " [13.004198]\n",
      " [19.195015]\n",
      " [23.55964 ]\n",
      " [30.021635]\n",
      " [24.94968 ]\n",
      " [23.873392]\n",
      " [22.572573]\n",
      " [29.961163]\n",
      " [26.129429]\n",
      " [18.410372]\n",
      " [15.909237]\n",
      " [24.972925]\n",
      " [23.957972]]\n"
     ]
    }
   ],
   "source": [
    "# 予測値の算出\n",
    "y_predict_n = model.predict(X_test_n)\n",
    "y_predict = scaler_y.inverse_transform(y_predict_n)\n",
    "print(y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.262929790378757"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 乖離度の算出\n",
    "import numpy as np\n",
    "np.mean(np.abs(y_test-y_predict.flatten())/y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
