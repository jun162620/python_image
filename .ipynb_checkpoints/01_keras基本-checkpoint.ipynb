{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# keras\n",
    "\n",
    "Kerasは，Pythonで書かれた高水準のニューラルネットワークライブラリです。\n",
    "\n",
    "Tensorflow,Pytorchなどと並び、Pythonエンジニアには広く用いられているライブラリです。\n",
    "\n",
    "### 特徴\n",
    "+ **直感的に使用できる**\n",
    "\n",
    "ニューラルネットの基本構造がわかっていれば、詳細なアルゴリズムの知識なしに、ニューラルネットの構築が可能です。\n",
    "\n",
    "+ **様々なアルゴリズムを搭載**\n",
    "\n",
    "単純なニューラルネットだけでなく、CNN,RNN,GRU,LSTMなど、幅広いアルゴリズムに対応しています。\n",
    "既存のアルゴリズムを使用することは勿論、独自のニューラルネットも簡単に構築できます。\n",
    "\n",
    "+ **GPUをサポート**\n",
    "\n",
    "ニューラルネットはCPUで処理するより、GPUで処理したほうが数倍～数百倍速くなります。\n",
    "\n",
    "**公式：**https://keras.io/ja/\n",
    "\n",
    "## 下記で通常のディープラーニングを行ってみる"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# データ生成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 連続値データの読み込み\n",
    "from sklearn.datasets import load_boston\n",
    "boston = load_boston()\n",
    "\n",
    "# 訓練データとテストデータに分ける\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    boston['data'], \n",
    "    boston['target'], \n",
    "    test_size=0.3,  \n",
    "    random_state=0\n",
    ")\n",
    "\n",
    "# 正規化（Normarization）\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler_x = MinMaxScaler()\n",
    "X_train_n = scaler_x.fit_transform(X_train)\n",
    "X_test_n = scaler_x.transform(X_test) \n",
    "scaler_y = MinMaxScaler()\n",
    "y_train_n = scaler_y.fit_transform(y_train.reshape(len(y_train),1))\n",
    "y_test_n = scaler_y.transform(y_test.reshape(len(y_test),1)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 基本的なモデルの作成と学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# 基本モデル生成\n",
    "from keras.models import Sequential # 基本モデルのクラス\n",
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 層の追加\n",
    "\n",
    "from keras.layers import Dense # 層\n",
    "from keras.layers import core  # 活性化関数\n",
    "from keras.layers import ReLU  # 活性化関数発展版\n",
    "\n",
    "# 中間層\n",
    "model.add(\n",
    "    Dense(\n",
    "        128,# ユニット数 \n",
    "        input_shape=(13,), # 入力ベクトルの次元数の指定\n",
    "        activation=ReLU()  # 活性化関数　ReLU\n",
    "    )\n",
    ")\n",
    "\n",
    "# 出力層\n",
    "model.add(\n",
    "    Dense(\n",
    "        1,# ユニット数  \n",
    "        activation=core.activations.linear     # 活性化関数　linear\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# モデルの学習設定\n",
    "from keras import losses     # 損失関数\n",
    "from keras import optimizers # 重み更新法\n",
    "model.compile(\n",
    "    loss=losses.mean_squared_error,    # 損失関数　平均二乗誤差\n",
    "    optimizer=optimizers.SGD(lr=0.01), # 重み更新法　確率的勾配降下法\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "354/354 [==============================] - 0s 56us/step - loss: 0.0174\n",
      "Epoch 2/100\n",
      "354/354 [==============================] - 0s 59us/step - loss: 0.0173\n",
      "Epoch 3/100\n",
      "354/354 [==============================] - 0s 59us/step - loss: 0.0171\n",
      "Epoch 4/100\n",
      "354/354 [==============================] - 0s 59us/step - loss: 0.0169\n",
      "Epoch 5/100\n",
      "354/354 [==============================] - 0s 57us/step - loss: 0.0167\n",
      "Epoch 6/100\n",
      "354/354 [==============================] - 0s 57us/step - loss: 0.0166\n",
      "Epoch 7/100\n",
      "354/354 [==============================] - 0s 59us/step - loss: 0.0164\n",
      "Epoch 8/100\n",
      "354/354 [==============================] - 0s 56us/step - loss: 0.0163\n",
      "Epoch 9/100\n",
      "354/354 [==============================] - 0s 56us/step - loss: 0.0161\n",
      "Epoch 10/100\n",
      "354/354 [==============================] - 0s 54us/step - loss: 0.0159\n",
      "Epoch 11/100\n",
      "354/354 [==============================] - 0s 54us/step - loss: 0.0157\n",
      "Epoch 12/100\n",
      "354/354 [==============================] - 0s 56us/step - loss: 0.0157\n",
      "Epoch 13/100\n",
      "354/354 [==============================] - 0s 62us/step - loss: 0.0156\n",
      "Epoch 14/100\n",
      "354/354 [==============================] - 0s 68us/step - loss: 0.0153\n",
      "Epoch 15/100\n",
      "354/354 [==============================] - 0s 68us/step - loss: 0.0152\n",
      "Epoch 16/100\n",
      "354/354 [==============================] - 0s 62us/step - loss: 0.0152\n",
      "Epoch 17/100\n",
      "354/354 [==============================] - 0s 65us/step - loss: 0.0149\n",
      "Epoch 18/100\n",
      "354/354 [==============================] - 0s 68us/step - loss: 0.0147\n",
      "Epoch 19/100\n",
      "354/354 [==============================] - 0s 62us/step - loss: 0.0147\n",
      "Epoch 20/100\n",
      "354/354 [==============================] - 0s 62us/step - loss: 0.0145\n",
      "Epoch 21/100\n",
      "354/354 [==============================] - 0s 65us/step - loss: 0.0145\n",
      "Epoch 22/100\n",
      "354/354 [==============================] - 0s 54us/step - loss: 0.0143\n",
      "Epoch 23/100\n",
      "354/354 [==============================] - 0s 48us/step - loss: 0.0141\n",
      "Epoch 24/100\n",
      "354/354 [==============================] - 0s 48us/step - loss: 0.0142\n",
      "Epoch 25/100\n",
      "354/354 [==============================] - 0s 48us/step - loss: 0.0139\n",
      "Epoch 26/100\n",
      "354/354 [==============================] - 0s 51us/step - loss: 0.0138\n",
      "Epoch 27/100\n",
      "354/354 [==============================] - 0s 54us/step - loss: 0.0136\n",
      "Epoch 28/100\n",
      "354/354 [==============================] - 0s 51us/step - loss: 0.0135\n",
      "Epoch 29/100\n",
      "354/354 [==============================] - 0s 48us/step - loss: 0.0134\n",
      "Epoch 30/100\n",
      "354/354 [==============================] - 0s 48us/step - loss: 0.0133\n",
      "Epoch 31/100\n",
      "354/354 [==============================] - 0s 51us/step - loss: 0.0133\n",
      "Epoch 32/100\n",
      "354/354 [==============================] - 0s 48us/step - loss: 0.0131\n",
      "Epoch 33/100\n",
      "354/354 [==============================] - 0s 51us/step - loss: 0.0131\n",
      "Epoch 34/100\n",
      "354/354 [==============================] - 0s 51us/step - loss: 0.0129\n",
      "Epoch 35/100\n",
      "354/354 [==============================] - 0s 51us/step - loss: 0.0131\n",
      "Epoch 36/100\n",
      "354/354 [==============================] - 0s 54us/step - loss: 0.0127\n",
      "Epoch 37/100\n",
      "354/354 [==============================] - 0s 51us/step - loss: 0.0127\n",
      "Epoch 38/100\n",
      "354/354 [==============================] - 0s 51us/step - loss: 0.0126\n",
      "Epoch 39/100\n",
      "354/354 [==============================] - 0s 45us/step - loss: 0.0125\n",
      "Epoch 40/100\n",
      "354/354 [==============================] - 0s 51us/step - loss: 0.0124\n",
      "Epoch 41/100\n",
      "354/354 [==============================] - 0s 54us/step - loss: 0.0123\n",
      "Epoch 42/100\n",
      "354/354 [==============================] - 0s 51us/step - loss: 0.0122\n",
      "Epoch 43/100\n",
      "354/354 [==============================] - 0s 48us/step - loss: 0.0122\n",
      "Epoch 44/100\n",
      "354/354 [==============================] - 0s 51us/step - loss: 0.0121\n",
      "Epoch 45/100\n",
      "354/354 [==============================] - 0s 54us/step - loss: 0.0120\n",
      "Epoch 46/100\n",
      "354/354 [==============================] - 0s 48us/step - loss: 0.0119\n",
      "Epoch 47/100\n",
      "354/354 [==============================] - 0s 48us/step - loss: 0.0119\n",
      "Epoch 48/100\n",
      "354/354 [==============================] - 0s 48us/step - loss: 0.0118\n",
      "Epoch 49/100\n",
      "354/354 [==============================] - 0s 51us/step - loss: 0.0117\n",
      "Epoch 50/100\n",
      "354/354 [==============================] - 0s 51us/step - loss: 0.0116\n",
      "Epoch 51/100\n",
      "354/354 [==============================] - 0s 51us/step - loss: 0.0117\n",
      "Epoch 52/100\n",
      "354/354 [==============================] - 0s 54us/step - loss: 0.0115\n",
      "Epoch 53/100\n",
      "354/354 [==============================] - 0s 51us/step - loss: 0.0114\n",
      "Epoch 54/100\n",
      "354/354 [==============================] - 0s 51us/step - loss: 0.0114\n",
      "Epoch 55/100\n",
      "354/354 [==============================] - 0s 51us/step - loss: 0.0113\n",
      "Epoch 56/100\n",
      "354/354 [==============================] - 0s 51us/step - loss: 0.0113\n",
      "Epoch 57/100\n",
      "354/354 [==============================] - 0s 51us/step - loss: 0.0112\n",
      "Epoch 58/100\n",
      "354/354 [==============================] - 0s 54us/step - loss: 0.0111\n",
      "Epoch 59/100\n",
      "354/354 [==============================] - 0s 54us/step - loss: 0.0110\n",
      "Epoch 60/100\n",
      "354/354 [==============================] - 0s 54us/step - loss: 0.0110\n",
      "Epoch 61/100\n",
      "354/354 [==============================] - 0s 51us/step - loss: 0.0111\n",
      "Epoch 62/100\n",
      "354/354 [==============================] - 0s 54us/step - loss: 0.0108\n",
      "Epoch 63/100\n",
      "354/354 [==============================] - 0s 54us/step - loss: 0.0110\n",
      "Epoch 64/100\n",
      "354/354 [==============================] - 0s 56us/step - loss: 0.0108\n",
      "Epoch 65/100\n",
      "354/354 [==============================] - 0s 54us/step - loss: 0.0108\n",
      "Epoch 66/100\n",
      "354/354 [==============================] - 0s 56us/step - loss: 0.0107\n",
      "Epoch 67/100\n",
      "354/354 [==============================] - 0s 51us/step - loss: 0.0106\n",
      "Epoch 68/100\n",
      "354/354 [==============================] - 0s 54us/step - loss: 0.0105\n",
      "Epoch 69/100\n",
      "354/354 [==============================] - 0s 54us/step - loss: 0.0105\n",
      "Epoch 70/100\n",
      "354/354 [==============================] - 0s 54us/step - loss: 0.0107\n",
      "Epoch 71/100\n",
      "354/354 [==============================] - 0s 51us/step - loss: 0.0106\n",
      "Epoch 72/100\n",
      "354/354 [==============================] - 0s 51us/step - loss: 0.0104\n",
      "Epoch 73/100\n",
      "354/354 [==============================] - 0s 51us/step - loss: 0.0103\n",
      "Epoch 74/100\n",
      "354/354 [==============================] - 0s 51us/step - loss: 0.0103\n",
      "Epoch 75/100\n",
      "354/354 [==============================] - 0s 54us/step - loss: 0.0102\n",
      "Epoch 76/100\n",
      "354/354 [==============================] - 0s 54us/step - loss: 0.0102\n",
      "Epoch 77/100\n",
      "354/354 [==============================] - 0s 51us/step - loss: 0.0102\n",
      "Epoch 78/100\n",
      "354/354 [==============================] - 0s 51us/step - loss: 0.0101\n",
      "Epoch 79/100\n",
      "354/354 [==============================] - 0s 54us/step - loss: 0.0101\n",
      "Epoch 80/100\n",
      "354/354 [==============================] - 0s 54us/step - loss: 0.0101\n",
      "Epoch 81/100\n",
      "354/354 [==============================] - 0s 51us/step - loss: 0.0100\n",
      "Epoch 82/100\n",
      "354/354 [==============================] - 0s 51us/step - loss: 0.0100\n",
      "Epoch 83/100\n",
      "354/354 [==============================] - 0s 51us/step - loss: 0.0099\n",
      "Epoch 84/100\n",
      "354/354 [==============================] - 0s 54us/step - loss: 0.0099\n",
      "Epoch 85/100\n",
      "354/354 [==============================] - 0s 51us/step - loss: 0.0099\n",
      "Epoch 86/100\n",
      "354/354 [==============================] - 0s 51us/step - loss: 0.0099\n",
      "Epoch 87/100\n",
      "354/354 [==============================] - 0s 51us/step - loss: 0.0097\n",
      "Epoch 88/100\n",
      "354/354 [==============================] - 0s 54us/step - loss: 0.0098\n",
      "Epoch 89/100\n",
      "354/354 [==============================] - 0s 51us/step - loss: 0.0097\n",
      "Epoch 90/100\n",
      "354/354 [==============================] - 0s 54us/step - loss: 0.0096\n",
      "Epoch 91/100\n",
      "354/354 [==============================] - 0s 54us/step - loss: 0.0096\n",
      "Epoch 92/100\n",
      "354/354 [==============================] - 0s 54us/step - loss: 0.0096\n",
      "Epoch 93/100\n",
      "354/354 [==============================] - 0s 56us/step - loss: 0.0095\n",
      "Epoch 94/100\n",
      "354/354 [==============================] - 0s 51us/step - loss: 0.0095\n",
      "Epoch 95/100\n",
      "354/354 [==============================] - 0s 51us/step - loss: 0.0097\n",
      "Epoch 96/100\n",
      "354/354 [==============================] - 0s 51us/step - loss: 0.0094\n",
      "Epoch 97/100\n",
      "354/354 [==============================] - 0s 54us/step - loss: 0.0094\n",
      "Epoch 98/100\n",
      "354/354 [==============================] - 0s 56us/step - loss: 0.0094\n",
      "Epoch 99/100\n",
      "354/354 [==============================] - 0s 54us/step - loss: 0.0093\n",
      "Epoch 100/100\n",
      "354/354 [==============================] - 0s 51us/step - loss: 0.0101\n"
     ]
    }
   ],
   "source": [
    "# モデルの学習\n",
    "result = model.fit(\n",
    "    X_train_n,\n",
    "    y_train_n,\n",
    "    epochs=100 # 学習回数\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[26.463623 ]\n",
      " [22.043823 ]\n",
      " [31.522408 ]\n",
      " [13.367223 ]\n",
      " [20.563257 ]\n",
      " [18.251616 ]\n",
      " [20.605896 ]\n",
      " [19.653498 ]\n",
      " [17.065113 ]\n",
      " [16.781155 ]\n",
      " [11.0006275]\n",
      " [13.1108465]\n",
      " [15.8609495]\n",
      " [10.895085 ]\n",
      " [39.381725 ]\n",
      " [31.892418 ]\n",
      " [22.181746 ]\n",
      " [36.63967  ]\n",
      " [30.575874 ]\n",
      " [21.719099 ]\n",
      " [23.539524 ]\n",
      " [24.32399  ]\n",
      " [17.722395 ]\n",
      " [28.814512 ]\n",
      " [21.600473 ]\n",
      " [11.864839 ]\n",
      " [16.12997  ]\n",
      " [18.317514 ]\n",
      " [35.29958  ]\n",
      " [19.08913  ]\n",
      " [16.60661  ]\n",
      " [17.437721 ]\n",
      " [19.436937 ]\n",
      " [23.848114 ]\n",
      " [28.255411 ]\n",
      " [19.34036  ]\n",
      " [12.279703 ]\n",
      " [24.360723 ]\n",
      " [15.081624 ]\n",
      " [13.859858 ]\n",
      " [26.344242 ]\n",
      " [20.45036  ]\n",
      " [23.969864 ]\n",
      " [14.549658 ]\n",
      " [25.303974 ]\n",
      " [24.708426 ]\n",
      " [20.160158 ]\n",
      " [24.688313 ]\n",
      " [12.39993  ]\n",
      " [21.998941 ]\n",
      " [19.053677 ]\n",
      " [17.12882  ]\n",
      " [23.600103 ]\n",
      " [31.553017 ]\n",
      " [12.945642 ]\n",
      " [22.528345 ]\n",
      " [20.627756 ]\n",
      " [17.228006 ]\n",
      " [14.081583 ]\n",
      " [23.993063 ]\n",
      " [19.72957  ]\n",
      " [20.486437 ]\n",
      " [32.97681  ]\n",
      " [30.294107 ]\n",
      " [17.906748 ]\n",
      " [32.71533  ]\n",
      " [17.131363 ]\n",
      " [21.126534 ]\n",
      " [15.885475 ]\n",
      " [21.66053  ]\n",
      " [20.74558  ]\n",
      " [22.943764 ]\n",
      " [29.872828 ]\n",
      " [28.680086 ]\n",
      " [25.558641 ]\n",
      " [10.81587  ]\n",
      " [36.58844  ]\n",
      " [22.67919  ]\n",
      " [26.417532 ]\n",
      " [17.817356 ]\n",
      " [28.514498 ]\n",
      " [17.331842 ]\n",
      " [17.616182 ]\n",
      " [37.229237 ]\n",
      " [38.612015 ]\n",
      " [22.699518 ]\n",
      " [24.158396 ]\n",
      " [14.933646 ]\n",
      " [27.009108 ]\n",
      " [15.80872  ]\n",
      " [15.9510765]\n",
      " [12.423892 ]\n",
      " [24.630346 ]\n",
      " [31.74681  ]\n",
      " [20.479359 ]\n",
      " [20.29306  ]\n",
      " [10.308183 ]\n",
      " [24.83571  ]\n",
      " [14.164196 ]\n",
      " [17.296139 ]\n",
      " [24.181547 ]\n",
      " [19.444775 ]\n",
      " [32.104095 ]\n",
      " [20.854733 ]\n",
      " [28.063618 ]\n",
      " [24.05199  ]\n",
      " [10.829408 ]\n",
      " [14.849501 ]\n",
      " [20.393562 ]\n",
      " [29.307392 ]\n",
      " [33.382404 ]\n",
      " [12.283124 ]\n",
      " [21.331083 ]\n",
      " [18.64389  ]\n",
      " [15.322509 ]\n",
      " [23.59739  ]\n",
      " [10.555206 ]\n",
      " [18.57596  ]\n",
      " [11.366259 ]\n",
      " [40.44619  ]\n",
      " [31.549084 ]\n",
      " [12.55072  ]\n",
      " [17.73027  ]\n",
      " [19.894072 ]\n",
      " [21.786102 ]\n",
      " [18.7946   ]\n",
      " [34.06161  ]\n",
      " [14.755104 ]\n",
      " [19.990788 ]\n",
      " [35.624084 ]\n",
      " [17.82869  ]\n",
      " [11.880075 ]\n",
      " [14.446078 ]\n",
      " [21.474394 ]\n",
      " [13.351179 ]\n",
      " [30.034897 ]\n",
      " [24.560942 ]\n",
      " [18.511406 ]\n",
      " [24.44241  ]\n",
      " [10.944898 ]\n",
      " [14.5290365]\n",
      " [20.008745 ]\n",
      " [31.778566 ]\n",
      " [27.959253 ]\n",
      " [25.810667 ]\n",
      " [14.755803 ]\n",
      " [29.07512  ]\n",
      " [28.223104 ]\n",
      " [13.227005 ]\n",
      " [11.027572 ]\n",
      " [26.820972 ]\n",
      " [24.972847 ]]\n"
     ]
    }
   ],
   "source": [
    "# 予測値の算出\n",
    "y_predict_n = model.predict(X_test_n)\n",
    "# 正規化の復元\n",
    "y_predict = scaler_y.inverse_transform(y_predict_n)\n",
    "print(y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.16880755857072707"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 乖離度の算出\n",
    "import numpy as np\n",
    "np.mean(\n",
    "    np.abs(y_test-y_predict.flatten())\n",
    "    /y_test\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 層を増やしたモデル\n",
    "\n",
    "ディープラーニングといわれるように、一般的に中間層を増やすと、精度が向上することがわかっている"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 基本モデル生成\n",
    "from keras.models import Sequential # 基本モデルのクラス\n",
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 層の追加\n",
    "\n",
    "from keras.layers import Dense # 層\n",
    "from keras.layers import core  # 活性化関数\n",
    "from keras.layers import ReLU  # 活性化関数発展版\n",
    "\n",
    "# 中間層\n",
    "model.add(\n",
    "    Dense(\n",
    "        128,# ユニット数 \n",
    "        input_shape=(13,), # 入力ベクトルの次元数の指定\n",
    "        activation=ReLU() # 活性化関数　ReLU\n",
    "    )\n",
    ")\n",
    "\n",
    "# 中間層\n",
    "model.add(\n",
    "    Dense(\n",
    "        128,# ユニット数 \n",
    "        activation=ReLU() # 活性化関数　ReLU\n",
    "    )\n",
    ")\n",
    "\n",
    "# 中間層\n",
    "model.add(\n",
    "    Dense(\n",
    "        128,# ユニット数 \n",
    "        activation=ReLU() # 活性化関数　ReLU\n",
    "    )\n",
    ")\n",
    "\n",
    "# 出力層\n",
    "model.add(\n",
    "    Dense(\n",
    "        1,# ユニット数  \n",
    "        activation=core.activations.linear # 活性化関数　linear\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# モデルの学習設定\n",
    "from keras import losses     # 損失関数\n",
    "from keras import optimizers # 重み更新法\n",
    "model.compile(\n",
    "    loss=losses.mean_squared_error,    # 損失関数　平均二乗誤差\n",
    "    optimizer=optimizers.SGD(lr=0.01), # 重み更新法　確率的勾配降下法\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "354/354 [==============================] - 0s 241us/step - loss: 0.1194\n",
      "Epoch 2/100\n",
      "354/354 [==============================] - 0s 65us/step - loss: 0.0659\n",
      "Epoch 3/100\n",
      "354/354 [==============================] - 0s 59us/step - loss: 0.0529\n",
      "Epoch 4/100\n",
      "354/354 [==============================] - 0s 56us/step - loss: 0.0471\n",
      "Epoch 5/100\n",
      "354/354 [==============================] - 0s 57us/step - loss: 0.0423\n",
      "Epoch 6/100\n",
      "354/354 [==============================] - 0s 59us/step - loss: 0.0385\n",
      "Epoch 7/100\n",
      "354/354 [==============================] - 0s 57us/step - loss: 0.0355\n",
      "Epoch 8/100\n",
      "354/354 [==============================] - 0s 59us/step - loss: 0.0327\n",
      "Epoch 9/100\n",
      "354/354 [==============================] - 0s 57us/step - loss: 0.0303\n",
      "Epoch 10/100\n",
      "354/354 [==============================] - 0s 59us/step - loss: 0.0281\n",
      "Epoch 11/100\n",
      "354/354 [==============================] - 0s 59us/step - loss: 0.0266\n",
      "Epoch 12/100\n",
      "354/354 [==============================] - 0s 56us/step - loss: 0.0253\n",
      "Epoch 13/100\n",
      "354/354 [==============================] - 0s 59us/step - loss: 0.0241\n",
      "Epoch 14/100\n",
      "354/354 [==============================] - 0s 57us/step - loss: 0.0230\n",
      "Epoch 15/100\n",
      "354/354 [==============================] - 0s 59us/step - loss: 0.0218\n",
      "Epoch 16/100\n",
      "354/354 [==============================] - 0s 54us/step - loss: 0.0206\n",
      "Epoch 17/100\n",
      "354/354 [==============================] - 0s 57us/step - loss: 0.0199\n",
      "Epoch 18/100\n",
      "354/354 [==============================] - 0s 54us/step - loss: 0.0194\n",
      "Epoch 19/100\n",
      "354/354 [==============================] - 0s 57us/step - loss: 0.0189\n",
      "Epoch 20/100\n",
      "354/354 [==============================] - 0s 57us/step - loss: 0.0183\n",
      "Epoch 21/100\n",
      "354/354 [==============================] - 0s 59us/step - loss: 0.0180\n",
      "Epoch 22/100\n",
      "354/354 [==============================] - 0s 56us/step - loss: 0.0175\n",
      "Epoch 23/100\n",
      "354/354 [==============================] - 0s 57us/step - loss: 0.0173\n",
      "Epoch 24/100\n",
      "354/354 [==============================] - 0s 57us/step - loss: 0.0168\n",
      "Epoch 25/100\n",
      "354/354 [==============================] - 0s 51us/step - loss: 0.0164\n",
      "Epoch 26/100\n",
      "354/354 [==============================] - 0s 54us/step - loss: 0.0160\n",
      "Epoch 27/100\n",
      "354/354 [==============================] - 0s 54us/step - loss: 0.0158\n",
      "Epoch 28/100\n",
      "354/354 [==============================] - 0s 56us/step - loss: 0.0155\n",
      "Epoch 29/100\n",
      "354/354 [==============================] - 0s 56us/step - loss: 0.0152\n",
      "Epoch 30/100\n",
      "354/354 [==============================] - 0s 59us/step - loss: 0.0150\n",
      "Epoch 31/100\n",
      "354/354 [==============================] - 0s 57us/step - loss: 0.0147\n",
      "Epoch 32/100\n",
      "354/354 [==============================] - 0s 54us/step - loss: 0.0145\n",
      "Epoch 33/100\n",
      "354/354 [==============================] - 0s 57us/step - loss: 0.0143\n",
      "Epoch 34/100\n",
      "354/354 [==============================] - 0s 56us/step - loss: 0.0141\n",
      "Epoch 35/100\n",
      "354/354 [==============================] - 0s 57us/step - loss: 0.0139\n",
      "Epoch 36/100\n",
      "354/354 [==============================] - 0s 57us/step - loss: 0.0138\n",
      "Epoch 37/100\n",
      "354/354 [==============================] - 0s 59us/step - loss: 0.0136\n",
      "Epoch 38/100\n",
      "354/354 [==============================] - 0s 54us/step - loss: 0.0133\n",
      "Epoch 39/100\n",
      "354/354 [==============================] - 0s 54us/step - loss: 0.0131\n",
      "Epoch 40/100\n",
      "354/354 [==============================] - 0s 51us/step - loss: 0.0130\n",
      "Epoch 41/100\n",
      "354/354 [==============================] - 0s 59us/step - loss: 0.0129\n",
      "Epoch 42/100\n",
      "354/354 [==============================] - 0s 54us/step - loss: 0.0128\n",
      "Epoch 43/100\n",
      "354/354 [==============================] - 0s 56us/step - loss: 0.0126\n",
      "Epoch 44/100\n",
      "354/354 [==============================] - 0s 57us/step - loss: 0.0126\n",
      "Epoch 45/100\n",
      "354/354 [==============================] - 0s 59us/step - loss: 0.0124\n",
      "Epoch 46/100\n",
      "354/354 [==============================] - 0s 59us/step - loss: 0.0123\n",
      "Epoch 47/100\n",
      "354/354 [==============================] - 0s 57us/step - loss: 0.0122\n",
      "Epoch 48/100\n",
      "354/354 [==============================] - 0s 59us/step - loss: 0.0122\n",
      "Epoch 49/100\n",
      "354/354 [==============================] - 0s 57us/step - loss: 0.0121\n",
      "Epoch 50/100\n",
      "354/354 [==============================] - 0s 57us/step - loss: 0.0118\n",
      "Epoch 51/100\n",
      "354/354 [==============================] - 0s 56us/step - loss: 0.0117\n",
      "Epoch 52/100\n",
      "354/354 [==============================] - 0s 54us/step - loss: 0.0117\n",
      "Epoch 53/100\n",
      "354/354 [==============================] - 0s 59us/step - loss: 0.0116\n",
      "Epoch 54/100\n",
      "354/354 [==============================] - 0s 59us/step - loss: 0.0115\n",
      "Epoch 55/100\n",
      "354/354 [==============================] - 0s 57us/step - loss: 0.0115\n",
      "Epoch 56/100\n",
      "354/354 [==============================] - 0s 57us/step - loss: 0.0115\n",
      "Epoch 57/100\n",
      "354/354 [==============================] - 0s 56us/step - loss: 0.0114\n",
      "Epoch 58/100\n",
      "354/354 [==============================] - 0s 57us/step - loss: 0.0113\n",
      "Epoch 59/100\n",
      "354/354 [==============================] - 0s 56us/step - loss: 0.0112\n",
      "Epoch 60/100\n",
      "354/354 [==============================] - 0s 54us/step - loss: 0.0111\n",
      "Epoch 61/100\n",
      "354/354 [==============================] - 0s 56us/step - loss: 0.0110\n",
      "Epoch 62/100\n",
      "354/354 [==============================] - 0s 54us/step - loss: 0.0109\n",
      "Epoch 63/100\n",
      "354/354 [==============================] - 0s 57us/step - loss: 0.0109\n",
      "Epoch 64/100\n",
      "354/354 [==============================] - 0s 57us/step - loss: 0.0108\n",
      "Epoch 65/100\n",
      "354/354 [==============================] - 0s 57us/step - loss: 0.0108\n",
      "Epoch 66/100\n",
      "354/354 [==============================] - 0s 56us/step - loss: 0.0108\n",
      "Epoch 67/100\n",
      "354/354 [==============================] - 0s 59us/step - loss: 0.0106\n",
      "Epoch 68/100\n",
      "354/354 [==============================] - 0s 54us/step - loss: 0.0106\n",
      "Epoch 69/100\n",
      "354/354 [==============================] - 0s 54us/step - loss: 0.0105\n",
      "Epoch 70/100\n",
      "354/354 [==============================] - 0s 56us/step - loss: 0.0105\n",
      "Epoch 71/100\n",
      "354/354 [==============================] - 0s 54us/step - loss: 0.0104\n",
      "Epoch 72/100\n",
      "354/354 [==============================] - 0s 57us/step - loss: 0.0103\n",
      "Epoch 73/100\n",
      "354/354 [==============================] - 0s 57us/step - loss: 0.0120\n",
      "Epoch 74/100\n",
      "354/354 [==============================] - 0s 59us/step - loss: 0.0103\n",
      "Epoch 75/100\n",
      "354/354 [==============================] - 0s 54us/step - loss: 0.0102\n",
      "Epoch 76/100\n",
      "354/354 [==============================] - 0s 54us/step - loss: 0.0101\n",
      "Epoch 77/100\n",
      "354/354 [==============================] - 0s 59us/step - loss: 0.0101\n",
      "Epoch 78/100\n",
      "354/354 [==============================] - 0s 51us/step - loss: 0.0100\n",
      "Epoch 79/100\n",
      "354/354 [==============================] - 0s 54us/step - loss: 0.0099\n",
      "Epoch 80/100\n",
      "354/354 [==============================] - 0s 57us/step - loss: 0.0099\n",
      "Epoch 81/100\n",
      "354/354 [==============================] - 0s 59us/step - loss: 0.0099\n",
      "Epoch 82/100\n",
      "354/354 [==============================] - 0s 54us/step - loss: 0.0098\n",
      "Epoch 83/100\n",
      "354/354 [==============================] - 0s 57us/step - loss: 0.0098\n",
      "Epoch 84/100\n",
      "354/354 [==============================] - 0s 56us/step - loss: 0.0097\n",
      "Epoch 85/100\n",
      "354/354 [==============================] - 0s 56us/step - loss: 0.0097\n",
      "Epoch 86/100\n",
      "354/354 [==============================] - 0s 54us/step - loss: 0.0097\n",
      "Epoch 87/100\n",
      "354/354 [==============================] - 0s 57us/step - loss: 0.0096\n",
      "Epoch 88/100\n",
      "354/354 [==============================] - 0s 56us/step - loss: 0.0096\n",
      "Epoch 89/100\n",
      "354/354 [==============================] - 0s 56us/step - loss: 0.0096\n",
      "Epoch 90/100\n",
      "354/354 [==============================] - 0s 59us/step - loss: 0.0096\n",
      "Epoch 91/100\n",
      "354/354 [==============================] - 0s 56us/step - loss: 0.0095\n",
      "Epoch 92/100\n",
      "354/354 [==============================] - 0s 57us/step - loss: 0.0094\n",
      "Epoch 93/100\n",
      "354/354 [==============================] - 0s 59us/step - loss: 0.0094\n",
      "Epoch 94/100\n",
      "354/354 [==============================] - 0s 62us/step - loss: 0.0094\n",
      "Epoch 95/100\n",
      "354/354 [==============================] - 0s 59us/step - loss: 0.0094\n",
      "Epoch 96/100\n",
      "354/354 [==============================] - 0s 57us/step - loss: 0.0093\n",
      "Epoch 97/100\n",
      "354/354 [==============================] - 0s 54us/step - loss: 0.0093\n",
      "Epoch 98/100\n",
      "354/354 [==============================] - 0s 57us/step - loss: 0.0092\n",
      "Epoch 99/100\n",
      "354/354 [==============================] - 0s 59us/step - loss: 0.0092\n",
      "Epoch 100/100\n",
      "354/354 [==============================] - 0s 59us/step - loss: 0.0092\n"
     ]
    }
   ],
   "source": [
    "# モデルの学習\n",
    "result = model.fit(\n",
    "    X_train_n,\n",
    "    y_train_n,\n",
    "    epochs=100 # 学習回数\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[23.297224 ]\n",
      " [19.39893  ]\n",
      " [29.208921 ]\n",
      " [11.746293 ]\n",
      " [18.725916 ]\n",
      " [18.647715 ]\n",
      " [20.40136  ]\n",
      " [19.819572 ]\n",
      " [16.445158 ]\n",
      " [14.563844 ]\n",
      " [10.296863 ]\n",
      " [13.091312 ]\n",
      " [14.619905 ]\n",
      " [ 7.812422 ]\n",
      " [37.334415 ]\n",
      " [31.235022 ]\n",
      " [21.686525 ]\n",
      " [36.460533 ]\n",
      " [29.654787 ]\n",
      " [21.166216 ]\n",
      " [23.377462 ]\n",
      " [22.598402 ]\n",
      " [16.768305 ]\n",
      " [27.210955 ]\n",
      " [21.287647 ]\n",
      " [10.298084 ]\n",
      " [16.115957 ]\n",
      " [18.810543 ]\n",
      " [33.79027  ]\n",
      " [19.277584 ]\n",
      " [15.663301 ]\n",
      " [16.951431 ]\n",
      " [18.926191 ]\n",
      " [21.997446 ]\n",
      " [27.315332 ]\n",
      " [21.61791  ]\n",
      " [10.739469 ]\n",
      " [25.037933 ]\n",
      " [14.147971 ]\n",
      " [12.787796 ]\n",
      " [24.56827  ]\n",
      " [19.700363 ]\n",
      " [21.735514 ]\n",
      " [13.781111 ]\n",
      " [25.5854   ]\n",
      " [24.259785 ]\n",
      " [18.64457  ]\n",
      " [25.316744 ]\n",
      " [14.721385 ]\n",
      " [20.902878 ]\n",
      " [20.677662 ]\n",
      " [16.97027  ]\n",
      " [21.418062 ]\n",
      " [31.31454  ]\n",
      " [12.744638 ]\n",
      " [21.539557 ]\n",
      " [20.279427 ]\n",
      " [16.749765 ]\n",
      " [13.036167 ]\n",
      " [22.3093   ]\n",
      " [21.696194 ]\n",
      " [20.367092 ]\n",
      " [30.379873 ]\n",
      " [28.96153  ]\n",
      " [18.463411 ]\n",
      " [29.34357  ]\n",
      " [16.13307  ]\n",
      " [21.273178 ]\n",
      " [14.27893  ]\n",
      " [21.53082  ]\n",
      " [19.09898  ]\n",
      " [21.057795 ]\n",
      " [28.345926 ]\n",
      " [27.962006 ]\n",
      " [24.034267 ]\n",
      " [ 7.965052 ]\n",
      " [35.69905  ]\n",
      " [21.831696 ]\n",
      " [25.341038 ]\n",
      " [17.335592 ]\n",
      " [27.148102 ]\n",
      " [17.775593 ]\n",
      " [15.448194 ]\n",
      " [36.090168 ]\n",
      " [37.632854 ]\n",
      " [23.79684  ]\n",
      " [22.115702 ]\n",
      " [14.862913 ]\n",
      " [26.647888 ]\n",
      " [15.409392 ]\n",
      " [16.807518 ]\n",
      " [12.279169 ]\n",
      " [25.888245 ]\n",
      " [30.325489 ]\n",
      " [20.052591 ]\n",
      " [21.296356 ]\n",
      " [ 6.1773276]\n",
      " [26.736471 ]\n",
      " [14.015812 ]\n",
      " [16.741396 ]\n",
      " [23.481884 ]\n",
      " [18.790468 ]\n",
      " [30.133656 ]\n",
      " [21.312857 ]\n",
      " [26.009632 ]\n",
      " [24.067928 ]\n",
      " [ 8.938265 ]\n",
      " [13.45929  ]\n",
      " [19.824696 ]\n",
      " [26.367989 ]\n",
      " [31.455545 ]\n",
      " [10.8543215]\n",
      " [21.620996 ]\n",
      " [17.415352 ]\n",
      " [16.063093 ]\n",
      " [23.734274 ]\n",
      " [ 9.591206 ]\n",
      " [18.474236 ]\n",
      " [ 9.951003 ]\n",
      " [39.99536  ]\n",
      " [29.631498 ]\n",
      " [11.505349 ]\n",
      " [16.831816 ]\n",
      " [18.840637 ]\n",
      " [21.356485 ]\n",
      " [17.633574 ]\n",
      " [31.540157 ]\n",
      " [13.839764 ]\n",
      " [20.357626 ]\n",
      " [33.830208 ]\n",
      " [16.609379 ]\n",
      " [12.716321 ]\n",
      " [13.757322 ]\n",
      " [20.52944  ]\n",
      " [13.714918 ]\n",
      " [30.580246 ]\n",
      " [22.39077  ]\n",
      " [21.042074 ]\n",
      " [24.880558 ]\n",
      " [11.059131 ]\n",
      " [13.265754 ]\n",
      " [18.719704 ]\n",
      " [31.308075 ]\n",
      " [28.290554 ]\n",
      " [23.409918 ]\n",
      " [14.955691 ]\n",
      " [29.687319 ]\n",
      " [28.72182  ]\n",
      " [13.041459 ]\n",
      " [ 8.654234 ]\n",
      " [27.168726 ]\n",
      " [25.627623 ]]\n"
     ]
    }
   ],
   "source": [
    "# 予測値の算出\n",
    "y_predict_n = model.predict(X_test_n)\n",
    "# 正規化の復元\n",
    "y_predict = scaler_y.inverse_transform(y_predict_n)\n",
    "print(y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.16624746840067425"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 乖離度の算出\n",
    "import numpy as np\n",
    "np.mean(\n",
    "    np.abs(y_test-y_predict.flatten())\n",
    "    /y_test\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 分類問題を解いてみる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 連続値データの読み込み\n",
    "from sklearn.datasets import load_iris\n",
    "iris = load_iris()\n",
    "\n",
    "# 訓練データとテストデータに分ける\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    iris['data'], \n",
    "    iris['target'], \n",
    "    test_size=0.3,  \n",
    "    random_state=0\n",
    ")\n",
    "\n",
    "# 正規化（Normarization）\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler_x = MinMaxScaler()\n",
    "X_train_n = scaler_x.fit_transform(X_train)\n",
    "X_test_n = scaler_x.transform(X_test) \n",
    "\n",
    "# one-hotベクトル化\n",
    "import keras\n",
    "y_train = keras.utils.to_categorical(y_train,3)\n",
    "y_test = keras.utils.to_categorical(y_test,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 基本モデル生成\n",
    "from keras.models import Sequential # 基本モデルのクラス\n",
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 層の追加\n",
    "\n",
    "from keras.layers import Dense # 層\n",
    "from keras.layers import core  # 活性化関数\n",
    "from keras.layers import ReLU,Softmax  # 活性化関数発展版\n",
    "\n",
    "# 中間層\n",
    "model.add(\n",
    "    Dense(\n",
    "        128,# ユニット数 \n",
    "        input_shape=(4,), # 入力ベクトルの次元数の指定\n",
    "        activation=ReLU() # 活性化関数　ReLU\n",
    "    )\n",
    ")\n",
    "\n",
    "# 中間層\n",
    "model.add(\n",
    "    Dense(\n",
    "        128,# ユニット数 \n",
    "        activation=ReLU() # 活性化関数　ReLU\n",
    "    )\n",
    ")\n",
    "\n",
    "# 中間層\n",
    "model.add(\n",
    "    Dense(\n",
    "        128,# ユニット数 \n",
    "        activation=ReLU() # 活性化関数　ReLU\n",
    "    )\n",
    ")\n",
    "\n",
    "# 出力層\n",
    "model.add(\n",
    "    Dense(\n",
    "        3, \n",
    "        activation=Softmax() # 活性化関数　softmax\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# モデルの学習設定\n",
    "from keras import losses     # 損失関数\n",
    "from keras import optimizers # 重み更新法\n",
    "model.compile(\n",
    "    loss=losses.mean_squared_error,    # 損失関数　平均二乗誤差\n",
    "    optimizer=optimizers.SGD(lr=0.01), # 重み更新法　確率的勾配降下法\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "105/105 [==============================] - 0s 752us/step - loss: 0.2167\n",
      "Epoch 2/100\n",
      "105/105 [==============================] - 0s 86us/step - loss: 0.2164\n",
      "Epoch 3/100\n",
      "105/105 [==============================] - 0s 76us/step - loss: 0.2162\n",
      "Epoch 4/100\n",
      "105/105 [==============================] - 0s 86us/step - loss: 0.2159\n",
      "Epoch 5/100\n",
      "105/105 [==============================] - 0s 76us/step - loss: 0.2157\n",
      "Epoch 6/100\n",
      "105/105 [==============================] - 0s 85us/step - loss: 0.2154\n",
      "Epoch 7/100\n",
      "105/105 [==============================] - 0s 76us/step - loss: 0.2151\n",
      "Epoch 8/100\n",
      "105/105 [==============================] - 0s 86us/step - loss: 0.2149\n",
      "Epoch 9/100\n",
      "105/105 [==============================] - 0s 76us/step - loss: 0.2146\n",
      "Epoch 10/100\n",
      "105/105 [==============================] - 0s 67us/step - loss: 0.2144\n",
      "Epoch 11/100\n",
      "105/105 [==============================] - 0s 76us/step - loss: 0.2141\n",
      "Epoch 12/100\n",
      "105/105 [==============================] - 0s 76us/step - loss: 0.2138\n",
      "Epoch 13/100\n",
      "105/105 [==============================] - 0s 76us/step - loss: 0.2136\n",
      "Epoch 14/100\n",
      "105/105 [==============================] - 0s 67us/step - loss: 0.2133\n",
      "Epoch 15/100\n",
      "105/105 [==============================] - 0s 76us/step - loss: 0.2131\n",
      "Epoch 16/100\n",
      "105/105 [==============================] - 0s 76us/step - loss: 0.2128\n",
      "Epoch 17/100\n",
      "105/105 [==============================] - 0s 86us/step - loss: 0.2126\n",
      "Epoch 18/100\n",
      "105/105 [==============================] - 0s 76us/step - loss: 0.2123\n",
      "Epoch 19/100\n",
      "105/105 [==============================] - 0s 76us/step - loss: 0.2121\n",
      "Epoch 20/100\n",
      "105/105 [==============================] - 0s 67us/step - loss: 0.2118\n",
      "Epoch 21/100\n",
      "105/105 [==============================] - 0s 76us/step - loss: 0.2116\n",
      "Epoch 22/100\n",
      "105/105 [==============================] - 0s 76us/step - loss: 0.2113\n",
      "Epoch 23/100\n",
      "105/105 [==============================] - 0s 76us/step - loss: 0.2111\n",
      "Epoch 24/100\n",
      "105/105 [==============================] - 0s 76us/step - loss: 0.2109\n",
      "Epoch 25/100\n",
      "105/105 [==============================] - 0s 76us/step - loss: 0.2107\n",
      "Epoch 26/100\n",
      "105/105 [==============================] - 0s 67us/step - loss: 0.2104\n",
      "Epoch 27/100\n",
      "105/105 [==============================] - 0s 76us/step - loss: 0.2102\n",
      "Epoch 28/100\n",
      "105/105 [==============================] - 0s 76us/step - loss: 0.2099\n",
      "Epoch 29/100\n",
      "105/105 [==============================] - 0s 67us/step - loss: 0.2097\n",
      "Epoch 30/100\n",
      "105/105 [==============================] - 0s 76us/step - loss: 0.2095\n",
      "Epoch 31/100\n",
      "105/105 [==============================] - 0s 76us/step - loss: 0.2092\n",
      "Epoch 32/100\n",
      "105/105 [==============================] - 0s 76us/step - loss: 0.2090\n",
      "Epoch 33/100\n",
      "105/105 [==============================] - 0s 76us/step - loss: 0.2088\n",
      "Epoch 34/100\n",
      "105/105 [==============================] - 0s 86us/step - loss: 0.2085\n",
      "Epoch 35/100\n",
      "105/105 [==============================] - 0s 76us/step - loss: 0.2083\n",
      "Epoch 36/100\n",
      "105/105 [==============================] - 0s 76us/step - loss: 0.2081\n",
      "Epoch 37/100\n",
      "105/105 [==============================] - 0s 67us/step - loss: 0.2079\n",
      "Epoch 38/100\n",
      "105/105 [==============================] - 0s 76us/step - loss: 0.2076\n",
      "Epoch 39/100\n",
      "105/105 [==============================] - 0s 76us/step - loss: 0.2074\n",
      "Epoch 40/100\n",
      "105/105 [==============================] - 0s 76us/step - loss: 0.2072\n",
      "Epoch 41/100\n",
      "105/105 [==============================] - ETA: 0s - loss: 0.210 - 0s 76us/step - loss: 0.2070\n",
      "Epoch 42/100\n",
      "105/105 [==============================] - 0s 86us/step - loss: 0.2068\n",
      "Epoch 43/100\n",
      "105/105 [==============================] - 0s 76us/step - loss: 0.2066\n",
      "Epoch 44/100\n",
      "105/105 [==============================] - 0s 76us/step - loss: 0.2063\n",
      "Epoch 45/100\n",
      "105/105 [==============================] - 0s 76us/step - loss: 0.2061\n",
      "Epoch 46/100\n",
      "105/105 [==============================] - 0s 76us/step - loss: 0.2059\n",
      "Epoch 47/100\n",
      "105/105 [==============================] - 0s 76us/step - loss: 0.2057\n",
      "Epoch 48/100\n",
      "105/105 [==============================] - 0s 76us/step - loss: 0.2055\n",
      "Epoch 49/100\n",
      "105/105 [==============================] - 0s 86us/step - loss: 0.2053\n",
      "Epoch 50/100\n",
      "105/105 [==============================] - 0s 76us/step - loss: 0.2051\n",
      "Epoch 51/100\n",
      "105/105 [==============================] - 0s 76us/step - loss: 0.2049\n",
      "Epoch 52/100\n",
      "105/105 [==============================] - 0s 76us/step - loss: 0.2047\n",
      "Epoch 53/100\n",
      "105/105 [==============================] - 0s 76us/step - loss: 0.2045\n",
      "Epoch 54/100\n",
      "105/105 [==============================] - 0s 67us/step - loss: 0.2042\n",
      "Epoch 55/100\n",
      "105/105 [==============================] - 0s 76us/step - loss: 0.2041\n",
      "Epoch 56/100\n",
      "105/105 [==============================] - 0s 76us/step - loss: 0.2039\n",
      "Epoch 57/100\n",
      "105/105 [==============================] - 0s 86us/step - loss: 0.2036\n",
      "Epoch 58/100\n",
      "105/105 [==============================] - 0s 76us/step - loss: 0.2034\n",
      "Epoch 59/100\n",
      "105/105 [==============================] - 0s 76us/step - loss: 0.2032\n",
      "Epoch 60/100\n",
      "105/105 [==============================] - 0s 76us/step - loss: 0.2030\n",
      "Epoch 61/100\n",
      "105/105 [==============================] - 0s 76us/step - loss: 0.2027\n",
      "Epoch 62/100\n",
      "105/105 [==============================] - 0s 67us/step - loss: 0.2025\n",
      "Epoch 63/100\n",
      "105/105 [==============================] - 0s 77us/step - loss: 0.2023\n",
      "Epoch 64/100\n",
      "105/105 [==============================] - 0s 67us/step - loss: 0.2021\n",
      "Epoch 65/100\n",
      "105/105 [==============================] - 0s 76us/step - loss: 0.2019\n",
      "Epoch 66/100\n",
      "105/105 [==============================] - 0s 67us/step - loss: 0.2016\n",
      "Epoch 67/100\n",
      "105/105 [==============================] - 0s 76us/step - loss: 0.2014\n",
      "Epoch 68/100\n",
      "105/105 [==============================] - 0s 67us/step - loss: 0.2012\n",
      "Epoch 69/100\n",
      "105/105 [==============================] - 0s 76us/step - loss: 0.2010\n",
      "Epoch 70/100\n",
      "105/105 [==============================] - 0s 67us/step - loss: 0.2008\n",
      "Epoch 71/100\n",
      "105/105 [==============================] - 0s 76us/step - loss: 0.2006\n",
      "Epoch 72/100\n",
      "105/105 [==============================] - 0s 67us/step - loss: 0.2004\n",
      "Epoch 73/100\n",
      "105/105 [==============================] - 0s 76us/step - loss: 0.2002\n",
      "Epoch 74/100\n",
      "105/105 [==============================] - 0s 67us/step - loss: 0.1999\n",
      "Epoch 75/100\n",
      "105/105 [==============================] - 0s 76us/step - loss: 0.1997\n",
      "Epoch 76/100\n",
      "105/105 [==============================] - 0s 77us/step - loss: 0.1995\n",
      "Epoch 77/100\n",
      "105/105 [==============================] - 0s 85us/step - loss: 0.1993\n",
      "Epoch 78/100\n",
      "105/105 [==============================] - 0s 67us/step - loss: 0.1991\n",
      "Epoch 79/100\n",
      "105/105 [==============================] - 0s 86us/step - loss: 0.1989\n",
      "Epoch 80/100\n",
      "105/105 [==============================] - 0s 76us/step - loss: 0.1986\n",
      "Epoch 81/100\n",
      "105/105 [==============================] - 0s 67us/step - loss: 0.1984\n",
      "Epoch 82/100\n",
      "105/105 [==============================] - 0s 76us/step - loss: 0.1982\n",
      "Epoch 83/100\n",
      "105/105 [==============================] - 0s 76us/step - loss: 0.1980\n",
      "Epoch 84/100\n",
      "105/105 [==============================] - 0s 67us/step - loss: 0.1978\n",
      "Epoch 85/100\n",
      "105/105 [==============================] - 0s 76us/step - loss: 0.1976\n",
      "Epoch 86/100\n",
      "105/105 [==============================] - 0s 67us/step - loss: 0.1973\n",
      "Epoch 87/100\n",
      "105/105 [==============================] - 0s 76us/step - loss: 0.1971\n",
      "Epoch 88/100\n",
      "105/105 [==============================] - 0s 67us/step - loss: 0.1969\n",
      "Epoch 89/100\n",
      "105/105 [==============================] - 0s 76us/step - loss: 0.1966\n",
      "Epoch 90/100\n",
      "105/105 [==============================] - 0s 66us/step - loss: 0.1964\n",
      "Epoch 91/100\n",
      "105/105 [==============================] - 0s 76us/step - loss: 0.1962\n",
      "Epoch 92/100\n",
      "105/105 [==============================] - 0s 76us/step - loss: 0.1960\n",
      "Epoch 93/100\n",
      "105/105 [==============================] - 0s 66us/step - loss: 0.1957\n",
      "Epoch 94/100\n",
      "105/105 [==============================] - 0s 86us/step - loss: 0.1955\n",
      "Epoch 95/100\n",
      "105/105 [==============================] - 0s 76us/step - loss: 0.1953\n",
      "Epoch 96/100\n",
      "105/105 [==============================] - 0s 67us/step - loss: 0.1951\n",
      "Epoch 97/100\n",
      "105/105 [==============================] - 0s 67us/step - loss: 0.1949\n",
      "Epoch 98/100\n",
      "105/105 [==============================] - 0s 67us/step - loss: 0.1947\n",
      "Epoch 99/100\n",
      "105/105 [==============================] - 0s 76us/step - loss: 0.1944\n",
      "Epoch 100/100\n",
      "105/105 [==============================] - 0s 76us/step - loss: 0.1942\n"
     ]
    }
   ],
   "source": [
    "# モデルの学習\n",
    "result = model.fit(\n",
    "    X_train_n,\n",
    "    y_train,\n",
    "    epochs=100 # 学習回数\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 2 0 2 0 2 0 2 2 2 2 2 2 2 2 0 2 2 0 0 2 2 0 0 2 0 0 2 2 0 2 2 0 2 2 2 0\n",
      " 2 2 2 2 0 2 0 0]\n"
     ]
    }
   ],
   "source": [
    "# 予測値の算出\n",
    "y_predict = np.argmax(model.predict(X_test_n),axis=1)\n",
    "print(y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 正答率の算出\n",
    "np.sum(\n",
    "    np.array(y_predict)\n",
    "    ==\n",
    "    np.argmax(np.array(y_test),axis=1)\n",
    ")/len(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 様々な精度向上テクニック\n",
    "\n",
    "+ **ミニバッチ学習**：ニューラルネットは、データが増えれば増えるほど、1epoch毎の計算時間が多くなるため、全てのデータを使って、勾配(重み)を更新していては、非効率的である。そのため、全データから、ランダムに任意の個数のデータを抽出し、学習させると、扱うデータ量が減り、計算速度が向上し、限られたリソースで、多くの勾配(重み)を更新できる。\n",
    "<dir></dir>\n",
    "+ **重み更新法の変更**：今まで使用してきたSGDは確率的勾配降下法と呼ばれるもので、その他にも、「Adam」「RMSprop」「Adagrad」「Adamax」「Nadam」などがある。\n",
    "<dir></dir>\n",
    "+ **活性化関数の変更**：今まで使用してきた活性化関数は「relu」「linear(恒等関数)」で、その他にも、「elu」「selu」「softmax」「softplus」「spftsign」「tanh」「sigmoid」「hard_sigmoid」などがある。\n",
    "中間層には、原則として、「linear」以外のすべての活性化関数が用いれる。\n",
    "    + 出力層\n",
    "        + 回帰問題：「linear」を用いるのが一般的であるが、目的変数の取りうる値(値域)が-1~1とわかっているなどの場合は、tanhを利用することができる。目的変数の値域と一致する活性化関数を選択する。\n",
    "        + 分類問題：\n",
    "            + 2項分類：sigmoidを用いるのが一般的\n",
    "            + 多項分類：softmaxを用いるのが一般的。\n",
    "<dir></dir>\n",
    "+ **ドロップアウト**：一定の確率でランダムにニューロンを無視して学習を進めることで、過学習を押さえ、汎化性能の高いモデルを作ることができます。\n",
    "<dir></dir>\n",
    "+ **Batch Normalization**：バッチ正規化と呼ばれ、基本的には、勾配消失・勾配爆発を防ぐための手法であり、これまでは、活性化関数の変更・学習係数を下げる・DropOut層の追加などで対応してきたが、Batch Normalizationは、ミニバッチの各出力を正規化させ、学習過程の安定と学習速度の向上を実現した。\n",
    "<dir></dir>\n",
    "+ **勾配(重み)やバイアスの初期値**\n",
    "    + Heの初期値：中間層の活性化関数がReluの時に、有効で、勾配(重み)やバイアスに対し、特定の法則に則って算出した、初期値を与えてやることで、中間層からの出力を偏りのないものにすることで、勾配消失問題と表現力の低下を解決する\n",
    "    + Xavierの初期値：中間層の活性化関数がsigmoid/tanhの時に、有効で、勾配(重み)やバイアスに対し、特定の法則に則って算出した、初期値を与えてやることで、中間層からの出力を偏りのないものにすることで、勾配消失問題と表現力の低下を解決する\n",
    "<dir></dir>\n",
    "+ **正則化項**：過学習防止のために、勾配(重み)が大きくなりすぎると、ペナルティを与える\n",
    "    + l1正則化：大きな次元の入力データに対して有効で、意味のないベクトルをそぎ落としてくれる\n",
    "    + l2正則化：特定の変数について、重要視したモデルを作成することを防ぐ\n",
    "    + l1_l2正則化：上記2つの合体版"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 連続値データの読み込み\n",
    "from sklearn.datasets import load_boston\n",
    "boston = load_boston()\n",
    "\n",
    "# 訓練データとテストデータに分ける\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    boston['data'], \n",
    "    boston['target'], \n",
    "    test_size=0.3,  \n",
    "    random_state=0\n",
    ")\n",
    "\n",
    "# 正規化（Normarization）\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler_x = MinMaxScaler()\n",
    "X_train_n = scaler_x.fit_transform(X_train)\n",
    "X_test_n = scaler_x.transform(X_test) \n",
    "scaler_y = MinMaxScaler()\n",
    "y_train_n = scaler_y.fit_transform(y_train.reshape(len(y_train),1))\n",
    "y_test_n = scaler_y.transform(y_test.reshape(len(y_test),1)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# 基本モデル生成\n",
    "from keras.models import Sequential # 基本モデルのクラス\n",
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 層の追加\n",
    "from keras.layers import Dense                # 層\n",
    "from keras.layers import core                 # 活性化関数\n",
    "from keras.layers import ReLU,LeakyReLU       # 活性化関数発展版\n",
    "from keras.layers import Dropout              # ドロップアウト\n",
    "from keras.layers import normalization        # バッチノーマリゼーション\n",
    "from keras import regularizers                # 正規化用\n",
    "from keras import initializers                # 初期化用\n",
    "\n",
    "# 中間層\n",
    "model.add(\n",
    "    Dense(\n",
    "        128, \n",
    "        input_shape=(13,),                               # 入力ベクトルの次元数の指定\n",
    "        activation=ReLU(),                               # 活性化関数　ReLU\n",
    "        kernel_initializer=initializers.he_normal(),     # 勾配(重み)の初期値\n",
    "        bias_initializer=initializers.he_normal(),       # バイアス項の初期値\n",
    "        kernel_regularizer=regularizers.l1_l2(0.001),    # 勾配(重み)の正則化項\n",
    "        bias_regularizer=regularizers.l1_l2(0.001)       # バイアス項の正則化項\n",
    "    )\n",
    ")\n",
    "model.add(Dropout(0.1))                                          # ドロップアウト\n",
    "model.add(normalization.BatchNormalization())                    # バッチ正規化\n",
    "model.add(Dense(128, activation=LeakyReLU()))                    # 活性化関数　LeakyReLU\n",
    "model.add(Dropout(0.1))                                          # ドロップアウト\n",
    "model.add(normalization.BatchNormalization())                    # バッチ正規化\n",
    "model.add(Dense(64, activation=core.activations.softmax))        # 活性化関数　softmax\n",
    "\n",
    "# 出力層\n",
    "model.add(Dense(1, activation=core.activations.linear))  # 活性化関数　linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# モデルの学習設定\n",
    "from keras import losses     # 損失関数\n",
    "from keras import optimizers # 重み更新法\n",
    "model.compile(\n",
    "    loss=losses.mean_absolute_error,   # 損失関数　平均絶対誤差\n",
    "    optimizer=optimizers.Adam(),       # 重み更新法　Adam\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "354/354 [==============================] - 0s 203us/step - loss: 4.8752\n",
      "Epoch 2/100\n",
      "354/354 [==============================] - 0s 192us/step - loss: 4.7349\n",
      "Epoch 3/100\n",
      "354/354 [==============================] - 0s 186us/step - loss: 4.6015\n",
      "Epoch 4/100\n",
      "354/354 [==============================] - 0s 181us/step - loss: 4.4742\n",
      "Epoch 5/100\n",
      "354/354 [==============================] - 0s 186us/step - loss: 4.3545\n",
      "Epoch 6/100\n",
      "354/354 [==============================] - 0s 181us/step - loss: 4.2311\n",
      "Epoch 7/100\n",
      "354/354 [==============================] - 0s 181us/step - loss: 4.1223\n",
      "Epoch 8/100\n",
      "354/354 [==============================] - 0s 186us/step - loss: 4.0115\n",
      "Epoch 9/100\n",
      "354/354 [==============================] - 0s 186us/step - loss: 3.9064\n",
      "Epoch 10/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 3.8008\n",
      "Epoch 11/100\n",
      "354/354 [==============================] - 0s 212us/step - loss: 3.7033\n",
      "Epoch 12/100\n",
      "354/354 [==============================] - 0s 215us/step - loss: 3.6058\n",
      "Epoch 13/100\n",
      "354/354 [==============================] - 0s 203us/step - loss: 3.5163\n",
      "Epoch 14/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 3.4266\n",
      "Epoch 15/100\n",
      "354/354 [==============================] - 0s 189us/step - loss: 3.3399\n",
      "Epoch 16/100\n",
      "354/354 [==============================] - 0s 201us/step - loss: 3.2698\n",
      "Epoch 17/100\n",
      "354/354 [==============================] - 0s 189us/step - loss: 3.2043\n",
      "Epoch 18/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 3.1222\n",
      "Epoch 19/100\n",
      "354/354 [==============================] - 0s 189us/step - loss: 3.0541\n",
      "Epoch 20/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 2.9880\n",
      "Epoch 21/100\n",
      "354/354 [==============================] - 0s 189us/step - loss: 2.9191\n",
      "Epoch 22/100\n",
      "354/354 [==============================] - 0s 189us/step - loss: 2.8517\n",
      "Epoch 23/100\n",
      "354/354 [==============================] - 0s 192us/step - loss: 2.7905\n",
      "Epoch 24/100\n",
      "354/354 [==============================] - 0s 189us/step - loss: 2.7310\n",
      "Epoch 25/100\n",
      "354/354 [==============================] - 0s 181us/step - loss: 2.6725\n",
      "Epoch 26/100\n",
      "354/354 [==============================] - 0s 184us/step - loss: 2.6241\n",
      "Epoch 27/100\n",
      "354/354 [==============================] - 0s 181us/step - loss: 2.5609\n",
      "Epoch 28/100\n",
      "354/354 [==============================] - 0s 178us/step - loss: 2.5090\n",
      "Epoch 29/100\n",
      "354/354 [==============================] - 0s 186us/step - loss: 2.4561\n",
      "Epoch 30/100\n",
      "354/354 [==============================] - 0s 186us/step - loss: 2.4060\n",
      "Epoch 31/100\n",
      "354/354 [==============================] - 0s 206us/step - loss: 2.3575\n",
      "Epoch 32/100\n",
      "354/354 [==============================] - 0s 184us/step - loss: 2.3053\n",
      "Epoch 33/100\n",
      "354/354 [==============================] - 0s 189us/step - loss: 2.2581\n",
      "Epoch 34/100\n",
      "354/354 [==============================] - 0s 201us/step - loss: 2.2170\n",
      "Epoch 35/100\n",
      "354/354 [==============================] - 0s 195us/step - loss: 2.1718\n",
      "Epoch 36/100\n",
      "354/354 [==============================] - 0s 186us/step - loss: 2.1321\n",
      "Epoch 37/100\n",
      "354/354 [==============================] - 0s 192us/step - loss: 2.0880\n",
      "Epoch 38/100\n",
      "354/354 [==============================] - 0s 184us/step - loss: 2.0471\n",
      "Epoch 39/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 2.0071\n",
      "Epoch 40/100\n",
      "354/354 [==============================] - 0s 184us/step - loss: 1.9683\n",
      "Epoch 41/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 1.9391\n",
      "Epoch 42/100\n",
      "354/354 [==============================] - 0s 195us/step - loss: 1.8957\n",
      "Epoch 43/100\n",
      "354/354 [==============================] - 0s 181us/step - loss: 1.8588\n",
      "Epoch 44/100\n",
      "354/354 [==============================] - 0s 192us/step - loss: 1.8282\n",
      "Epoch 45/100\n",
      "354/354 [==============================] - 0s 189us/step - loss: 1.7956\n",
      "Epoch 46/100\n",
      "354/354 [==============================] - 0s 186us/step - loss: 1.7628\n",
      "Epoch 47/100\n",
      "354/354 [==============================] - 0s 184us/step - loss: 1.7321\n",
      "Epoch 48/100\n",
      "354/354 [==============================] - 0s 201us/step - loss: 1.7002\n",
      "Epoch 49/100\n",
      "354/354 [==============================] - 0s 181us/step - loss: 1.6677\n",
      "Epoch 50/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 1.6435\n",
      "Epoch 51/100\n",
      "354/354 [==============================] - 0s 186us/step - loss: 1.6220\n",
      "Epoch 52/100\n",
      "354/354 [==============================] - 0s 192us/step - loss: 1.5949\n",
      "Epoch 53/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 1.5679\n",
      "Epoch 54/100\n",
      "354/354 [==============================] - 0s 189us/step - loss: 1.5397\n",
      "Epoch 55/100\n",
      "354/354 [==============================] - 0s 181us/step - loss: 1.5152\n",
      "Epoch 56/100\n",
      "354/354 [==============================] - 0s 186us/step - loss: 1.4920\n",
      "Epoch 57/100\n",
      "354/354 [==============================] - 0s 181us/step - loss: 1.4706\n",
      "Epoch 58/100\n",
      "354/354 [==============================] - 0s 184us/step - loss: 1.4469\n",
      "Epoch 59/100\n",
      "354/354 [==============================] - 0s 189us/step - loss: 1.4204\n",
      "Epoch 60/100\n",
      "354/354 [==============================] - 0s 189us/step - loss: 1.3937\n",
      "Epoch 61/100\n",
      "354/354 [==============================] - 0s 189us/step - loss: 1.3719\n",
      "Epoch 62/100\n",
      "354/354 [==============================] - 0s 184us/step - loss: 1.3492\n",
      "Epoch 63/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 1.3334\n",
      "Epoch 64/100\n",
      "354/354 [==============================] - 0s 192us/step - loss: 1.3079\n",
      "Epoch 65/100\n",
      "354/354 [==============================] - 0s 192us/step - loss: 1.2921\n",
      "Epoch 66/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 1.2733\n",
      "Epoch 67/100\n",
      "354/354 [==============================] - 0s 186us/step - loss: 1.2501\n",
      "Epoch 68/100\n",
      "354/354 [==============================] - 0s 234us/step - loss: 1.2279\n",
      "Epoch 69/100\n",
      "354/354 [==============================] - 0s 189us/step - loss: 1.2114\n",
      "Epoch 70/100\n",
      "354/354 [==============================] - 0s 192us/step - loss: 1.1940\n",
      "Epoch 71/100\n",
      "354/354 [==============================] - 0s 184us/step - loss: 1.1781\n",
      "Epoch 72/100\n",
      "354/354 [==============================] - 0s 203us/step - loss: 1.1553\n",
      "Epoch 73/100\n",
      "354/354 [==============================] - 0s 192us/step - loss: 1.1382\n",
      "Epoch 74/100\n",
      "354/354 [==============================] - 0s 195us/step - loss: 1.1228\n",
      "Epoch 75/100\n",
      "354/354 [==============================] - 0s 195us/step - loss: 1.1036\n",
      "Epoch 76/100\n",
      "354/354 [==============================] - 0s 186us/step - loss: 1.0905\n",
      "Epoch 77/100\n",
      "354/354 [==============================] - 0s 184us/step - loss: 1.0717\n",
      "Epoch 78/100\n",
      "354/354 [==============================] - 0s 189us/step - loss: 1.0572\n",
      "Epoch 79/100\n",
      "354/354 [==============================] - 0s 186us/step - loss: 1.0398\n",
      "Epoch 80/100\n",
      "354/354 [==============================] - 0s 195us/step - loss: 1.0230\n",
      "Epoch 81/100\n",
      "354/354 [==============================] - 0s 189us/step - loss: 1.0045\n",
      "Epoch 82/100\n",
      "354/354 [==============================] - 0s 184us/step - loss: 0.9902\n",
      "Epoch 83/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 0.9733\n",
      "Epoch 84/100\n",
      "354/354 [==============================] - 0s 181us/step - loss: 0.9648\n",
      "Epoch 85/100\n",
      "354/354 [==============================] - 0s 181us/step - loss: 0.9502\n",
      "Epoch 86/100\n",
      "354/354 [==============================] - 0s 195us/step - loss: 0.9342\n",
      "Epoch 87/100\n",
      "354/354 [==============================] - 0s 229us/step - loss: 0.9225\n",
      "Epoch 88/100\n",
      "354/354 [==============================] - 0s 220us/step - loss: 0.9093\n",
      "Epoch 89/100\n",
      "354/354 [==============================] - 0s 206us/step - loss: 0.8936\n",
      "Epoch 90/100\n",
      "354/354 [==============================] - 0s 184us/step - loss: 0.8802\n",
      "Epoch 91/100\n",
      "354/354 [==============================] - 0s 178us/step - loss: 0.8694\n",
      "Epoch 92/100\n",
      "354/354 [==============================] - 0s 186us/step - loss: 0.8576\n",
      "Epoch 93/100\n",
      "354/354 [==============================] - 0s 184us/step - loss: 0.8485\n",
      "Epoch 94/100\n",
      "354/354 [==============================] - 0s 175us/step - loss: 0.8469\n",
      "Epoch 95/100\n",
      "354/354 [==============================] - 0s 192us/step - loss: 0.8348\n",
      "Epoch 96/100\n",
      "354/354 [==============================] - 0s 195us/step - loss: 0.8172\n",
      "Epoch 97/100\n",
      "354/354 [==============================] - 0s 189us/step - loss: 0.8062\n",
      "Epoch 98/100\n",
      "354/354 [==============================] - 0s 195us/step - loss: 0.7932\n",
      "Epoch 99/100\n",
      "354/354 [==============================] - 0s 192us/step - loss: 0.7812\n",
      "Epoch 100/100\n",
      "354/354 [==============================] - 0s 184us/step - loss: 0.7647\n"
     ]
    }
   ],
   "source": [
    "# モデルの学習\n",
    "result = model.fit(\n",
    "    X_train_n,\n",
    "    y_train_n,\n",
    "    batch_size=32,   # ミニバッチ処理\n",
    "    epochs=100       # 学習回数                       \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[24.212746 ]\n",
      " [19.634438 ]\n",
      " [27.033175 ]\n",
      " [14.356748 ]\n",
      " [22.762873 ]\n",
      " [22.640215 ]\n",
      " [20.750237 ]\n",
      " [23.175983 ]\n",
      " [22.872631 ]\n",
      " [18.050533 ]\n",
      " [13.531417 ]\n",
      " [13.590123 ]\n",
      " [14.669274 ]\n",
      " [13.607997 ]\n",
      " [35.51657  ]\n",
      " [34.14609  ]\n",
      " [20.39646  ]\n",
      " [35.536682 ]\n",
      " [29.183088 ]\n",
      " [23.426207 ]\n",
      " [23.86742  ]\n",
      " [22.321863 ]\n",
      " [14.6737795]\n",
      " [25.022795 ]\n",
      " [23.365957 ]\n",
      " [13.686944 ]\n",
      " [15.664413 ]\n",
      " [17.972242 ]\n",
      " [35.55134  ]\n",
      " [17.317205 ]\n",
      " [16.989721 ]\n",
      " [18.276007 ]\n",
      " [22.3407   ]\n",
      " [22.634815 ]\n",
      " [28.792942 ]\n",
      " [21.376762 ]\n",
      " [13.842057 ]\n",
      " [22.013103 ]\n",
      " [13.910405 ]\n",
      " [14.175484 ]\n",
      " [23.717867 ]\n",
      " [23.25393  ]\n",
      " [23.34485  ]\n",
      " [15.140025 ]\n",
      " [24.40284  ]\n",
      " [25.972498 ]\n",
      " [22.626225 ]\n",
      " [15.483414 ]\n",
      " [17.487165 ]\n",
      " [22.6238   ]\n",
      " [16.704597 ]\n",
      " [23.00745  ]\n",
      " [23.015913 ]\n",
      " [35.482597 ]\n",
      " [15.570231 ]\n",
      " [22.741358 ]\n",
      " [22.72916  ]\n",
      " [22.522072 ]\n",
      " [13.644585 ]\n",
      " [22.806791 ]\n",
      " [22.736544 ]\n",
      " [22.97686  ]\n",
      " [33.874416 ]\n",
      " [28.523876 ]\n",
      " [20.095118 ]\n",
      " [30.749166 ]\n",
      " [15.793613 ]\n",
      " [14.2569   ]\n",
      " [14.129267 ]\n",
      " [23.496157 ]\n",
      " [22.526972 ]\n",
      " [23.2914   ]\n",
      " [24.144825 ]\n",
      " [25.178236 ]\n",
      " [20.3385   ]\n",
      " [13.629553 ]\n",
      " [35.5494   ]\n",
      " [23.476799 ]\n",
      " [26.835388 ]\n",
      " [22.348263 ]\n",
      " [26.161625 ]\n",
      " [19.257563 ]\n",
      " [17.077576 ]\n",
      " [35.551037 ]\n",
      " [35.555073 ]\n",
      " [23.618551 ]\n",
      " [24.746656 ]\n",
      " [14.478644 ]\n",
      " [22.469563 ]\n",
      " [16.811651 ]\n",
      " [22.381989 ]\n",
      " [13.547931 ]\n",
      " [22.58853  ]\n",
      " [30.630009 ]\n",
      " [22.599669 ]\n",
      " [22.807611 ]\n",
      " [13.508762 ]\n",
      " [22.763023 ]\n",
      " [13.595766 ]\n",
      " [22.388315 ]\n",
      " [23.777493 ]\n",
      " [14.361538 ]\n",
      " [35.051537 ]\n",
      " [23.339285 ]\n",
      " [27.880665 ]\n",
      " [22.62807  ]\n",
      " [13.549218 ]\n",
      " [15.654139 ]\n",
      " [22.667627 ]\n",
      " [24.721699 ]\n",
      " [32.902187 ]\n",
      " [13.812175 ]\n",
      " [13.643005 ]\n",
      " [20.016497 ]\n",
      " [16.858753 ]\n",
      " [23.721672 ]\n",
      " [13.527441 ]\n",
      " [19.252695 ]\n",
      " [13.794744 ]\n",
      " [35.555916 ]\n",
      " [29.089233 ]\n",
      " [13.946885 ]\n",
      " [22.583248 ]\n",
      " [22.582264 ]\n",
      " [22.843184 ]\n",
      " [22.372192 ]\n",
      " [35.501053 ]\n",
      " [13.567378 ]\n",
      " [22.705492 ]\n",
      " [35.418808 ]\n",
      " [16.940516 ]\n",
      " [13.540475 ]\n",
      " [18.232351 ]\n",
      " [16.671597 ]\n",
      " [13.575659 ]\n",
      " [34.82698  ]\n",
      " [23.38147  ]\n",
      " [18.636919 ]\n",
      " [23.442486 ]\n",
      " [13.52863  ]\n",
      " [14.856226 ]\n",
      " [23.110687 ]\n",
      " [35.38035  ]\n",
      " [25.990248 ]\n",
      " [23.706028 ]\n",
      " [16.52704  ]\n",
      " [29.76589  ]\n",
      " [35.333088 ]\n",
      " [13.648775 ]\n",
      " [13.641893 ]\n",
      " [26.420145 ]\n",
      " [29.133696 ]]\n"
     ]
    }
   ],
   "source": [
    "# 予測値の算出\n",
    "y_predict_n = model.predict(X_test_n)\n",
    "# 正規化の復元\n",
    "y_predict = scaler_y.inverse_transform(y_predict_n)\n",
    "print(y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.19742316824866749"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 乖離度の算出\n",
    "import numpy as np\n",
    "np.mean(np.abs(y_test-y_predict.flatten())/y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
